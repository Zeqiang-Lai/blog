<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Notes on Ze&#39;s Blog</title>
    <link>https://zeqiang-lai.github.io/blog/docs/notes/</link>
    <description>Recent content in Notes on Ze&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator><atom:link href="https://zeqiang-lai.github.io/blog/docs/notes/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Raft 阅读笔记</title>
      <link>https://zeqiang-lai.github.io/blog/docs/notes/md/raft/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/docs/notes/md/raft/</guid>
      <description>Created: August, 6, 2021 论文: RAFT: Recurrent All-Pairs Field Transforms for Optical Flow
Code: https://github.com/princeton-vl/RAFT
 这篇文章做的是光流估计，简单来说，任务就是输入两张图像$I_1,I_2$，我们需要估计出第二张图像$I_1$每个像素点$(u,v)$相对于第一张图像$I_1$的偏移量$(f^1(u), f^2(v))$。
$$ I_1 = I_2 + f $$
这篇文章的思路是这样的：
 首先使用一个feature encoder  求出flow feature：同时输入img1，img2，得到fmap1，fmap2 求出context feature：只输入img1，得到inp   求出fmap1和fmap2的相似度corr 使用一个RNN迭代的求出flow。  RNN的输入包括一个隐藏状态net，context feature inp，相似度corr，上一步的flow     这里的主要问题是每迭代一次，我们都得到了一个更接近img1的img2，这时候相似度需要重新计算。
 RAFT设计了一个查表的思路，只需要在最开始算一遍即可。它的方法是用新坐标周围的点的flow feature拉成一个向量作为新坐标点的flow特征。</description>
    </item>
    
  </channel>
</rss>
