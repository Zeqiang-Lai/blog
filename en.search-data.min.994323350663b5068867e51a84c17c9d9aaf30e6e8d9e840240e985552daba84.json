[{"id":0,"href":"/blog/en/posts/union-find/","title":"Union-Find","section":"Posts","content":"Union-Find is an algorithm that is used to solve a number of particular problems. The essentail one is Dynamic connectivity, many other problems are its variants.\nDynamic connectivity #  Given a set of N objects (could be anything), there are two types of operations.\n Union command: connect two objects Find/connected query: is there a path connecting the two objects?   Model #  We first model the problems into a mathmatical/algorithmic model.\nObjects #  First, we have to symbolize objects. When encountering problems in the real world, sometimes, it is hard to recognize them as \u0026ldquo;Dynamic connectivity\u0026rdquo; problems.\nSo it is important to refer some example of them:\n Pixels in a digital photo. Computer in a network. Friends in a social network.  When programming, it is convenient to name objects 0 to N-1.\n Use integers as array index. Suppress details not relevant to union-find. (could use symbol table)  Connections #  Then, we defined what \u0026ldquo;is connected to\u0026rdquo; means precisely. In this case, we assume it an equivalence relation:\n Reflexive: p is connective to p. Symmetric: if Transitive:  Connected components. Maximal set of objects that are mutually connected.\n Operations #  There are only two main operations:\n Find query. Check if two objects are in the same component. Union command. Replace components containing two objects with their union.   API #  Union-find data type (API) specify the requirements.\nData structure #  Goal. Design efficient data structure for union-find.\n Number of objects N can be huge. Number of operations M can be huge. Find queries and union commands may be intermixed.  Interface #     public class UF      UF(int N) initialize union-find data structure with N objects (0 to N – 1)   void union(int p, int q) add connection between p and q   boolean connected(int p, int q) are p and q in the same component?   int find(int p) component identifier for p (0 to N – 1)   int count() number of components    Client #  As we complete the design of the API, we can use them to write a client program. No matter which algorithm we choose to implement the API, the same client is used for test.\nHere is an example:\nThe origin one in the coursera did not test the operation find , the one mentioned below is modified to fix it.\nTODO: modified the example below\nCode:\npublic static void main(String[] args) { int N = StdIn.readInt(); UF uf = new UF(N); while (!StdIn.isEmpty()) { int p = StdIn.readInt(); int q = StdIn.readInt(); if (!uf.connected(p, q)) { uf.union(p, q); StdOut.println(p + \u0026#34; \u0026#34; + q); } } } Test data:\n% more tinyUF.txt 10 4 3 3 8 6 5 9 4 2 1 8 9 5 0 7 2 6 1 1 0 6 7 Alogrithms #  Quick Find #  Quick-find is an eager approach to the implementation of Union-Find.\nWhat does \u0026ldquo;Eager\u0026rdquo; mean?\n It process union operation as well as possible in order to make find operation much faster later.\n Data structure #   Integer array id[] of length N. Interpretation: p and q are connected iff they have the same id.  For example,\n Algorithms #  Here are the algorithms for Find and Union operations based on the data structure mentioned above.\nFind. Check if p and q have the same id.\n// Example: id[6] = 0;id[1] = 1 6 and 1 are not connected Union. To merge components containing p and q, change all entries whose id equals id[p] to id[q].\n Implementation in Java #  public class QuickFindUF { private int[] id; public QuickFindUF(int N) { id = new int[N]; // set id of each object to itself (N array accesses)  for (int i = 0; i \u0026lt; N; i++) id[i] = i; } // check whether p and q are in the same component (2 array accesses) \tpublic boolean connected(int p, int q) { return id[p] == id[q]; } public void union(int p, int q) { int pid = id[p]; int qid = id[q]; // change all entries with id[p] to id[q]  // (at most 2N + 2 array accesses)  for (int i = 0; i \u0026lt; id.length; i++) if (id[i] == pid) id[i] = qid; } } Complexity #  Cost model. Number of array accesses (for read or write).\n   algorithm initialize union find     quick-find N N 1    Analysis:\n Union is too expensive. It takes $N^2$ array accesses to process a sequence of N union commands on N objects.  Quick Union #  Quick-Union is a lazy approach to the implementation of Union-Find.\nWhat does \u0026ldquo;Lazy\u0026rdquo; mean?\n It won\u0026rsquo;t do too much when performing union command. Instead, more operations are needed in find command.\n Data structure #   Integer array id[] of length N. Interpretation: id[i] is parent of i. Root of i is id[id[id[\u0026hellip;id[i]\u0026hellip;]]]. (keep going until it doesn’t change)   Algorithm #  Find. Check if p and q have the same root.\nUnion. To merge components containing p and q, set the id of p\u0026rsquo;s root to the id of q\u0026rsquo;s root.\nImplementation in Java #  public class QuickUnionUF { private int[] id; public QuickUnionUF(int N) { id = new int[N]; // set id of each object to itself (N array accesses)  for (int i = 0; i \u0026lt; N; i++) id[i] = i; } private int root(int i) { // chase parent pointers until reach root  // (depth of i array accesses)  while (i != id[i]) i = id[i]; return i; } public boolean connected(int p, int q) { // check if p and q have same root  // (depth of p and q array accesses)  return root(p) == root(q); } public void union(int p, int q) {\t// change root of p to point to root of q  // (depth of p and q array accesses)  int i = root(p); int j = root(q); id[i] = j; } } Complexity #  Cost model. Number of array accesses (for read or write).\n   algorithm initialize union find     quick-find N N 1   quick-union N N† N    Quick-find defect.\n Union too expensive (N array accesses). Trees are flat, but too expensive to keep them flat.  Quick-union defect.\n Trees can get tall. Find too expensive (could be N array accesses).  Improvements #  Weighting #  For Quick-Union, the biggest problem is that trees can grow too tall to find root. If we can find a way to make the tree shorter, we can minimize the complexity of the algorithm.\nBased on the intuition mentioned above, we could develop a new version of Quick-Union, which calleed Weighted quick-union.\nThe baisc idea behind it is pretty simple.\n First, keep track of size of each tree (number of objects). Then, balance by linking root of smaller tree to root of larger tree.   Here, larger means that the tree has more nodes (ojbects).\n Data structure #  Same as quick-union, but maintain extra array sz[i] to count number of objects in the tree rooted at i.\nAlgorithm #  Find. Identical to quick-union.\nUnion. Modify quick-union to:\n Link root of smaller tree to root of larger tree. Update the sz[] array.  Implementation in Java #  // find return root(p) == root(q); // union int i = root(p); int j = root(q); if (i == j) return; if (sz[i] \u0026lt; sz[j]) { id[i] = j; sz[j] += sz[i]; } else { id[j] = i; sz[i] += sz[j]; } Analysis #  Running time.\n Find: takes time proportional to depth of p and q.   Because you have to find roots of two nodes.\n  Union: takes constant time, given roots.  Proposition. Depth of any node x is at most lg N.\nPf. When does depth of x increase? Increases by 1 when tree T1 containing x is merged into another tree T2.\n The size of the tree containing x at least doubles since | T2 | ≥ | T1 |. Size of tree containing x can double at most lg N times. Why?   Because there is only N nodes, if there is only one node in the tree initially, after doubling lg N times, there will be 2^(lg N) = N nodes, the same as the total number of nodes.\n Comparsion.\n   algorithm initialize union connected     quick-find N N 1   quick-union N N† N   weighted QU N lg N † lg N    Path compression #   Just after computing the root of p, set the id of each examined node to point to that root.\n No extra data structure is needed.\nImplementation in Java #  Two-pass implementation: add second loop to root() to set the id[] of each examined node to the root.\nSimpler one-pass variant: Make every other node in path point to its grandparent (thereby halving path length).\n In practice, the simpler one-pass variant is able to keep tree almost completely flat. So it is acceptable to use it.\n Analysis #  Proposition. [Hopcroft-Ulman, Tarjan] Starting from an empty data structure, any sequence of M union-find ops on N objects makes ≤ c ( N + M lg* N ) array accesses.\n Analysis can be improved to N + M α(M, N).  Linear-time algorithm for M union-find ops on N objects?\n  In theory, WQUPC is not quite linear.\n  In practice, WQUPC is linear.\n  WQUPC (weighted quick-union path compression)\nActually, there is no linear-time algorithm exists. [Fredman-Saks]\nSummary #  M union-find operations on a set of N objects\n   algorithm worst-case time     quick-find MN   quick-union MN   weighted QU N + M log N   QU + path compression N + M log N   weighted QU + path compression N + M lg* N    Appendix #  Why Quadratic algorithms won\u0026rsquo;t work? #  For now, computer can perform $10^9$ operations per second, and there are about $10^9$ words in the main memory, which means that computer can touch all words in approximately 1 second.\nSuppose we are using a single computer for Union-find, the biggest problem could contain $10^9$ objects and there could be $10^9$ union command on them.\nIn the worsts cases, every union cost $10^9$ times array accesses and there will be more than $10^{18}$ array access in total.\nUnder this circumstance, it will cost 30+ years of computer time.\nWhy the complexity of QU+path compression is N+MlogN? #  Suppose we use one-pass implementation.\nFor each examined node, we set its id to its grandparent. After one find operation, the height of the tree would reduce by half.\n"},{"id":1,"href":"/blog/en/posts/admm-2d-tv/","title":"2D TV Denosing with ADMM -- Mathematics \u0026\u0026 Implementation","section":"Posts","content":"In writing.  For 2D Total variation denosing, we have the following objective, where $x$ is the clean image we want to optimize, $y$ is the origin noisy image, and $D_r $and $D_c$ are doubly block circulant matrices for two 2D convolution.\nIn detail, both of $x$ and $y$ are vectorized into 1D vectors, and the total variation terms are expressed as two convolutions in Matrix-vector form.\n $$ \\operatorname{minimize} \\enspace \\frac{1}{2} \\|x-y\\|_{2}^{2} + \\lambda\\|D_r x\\|_{1} + \\lambda\\|D_c x\\|_{1} $$  With ADMM, we substitute$D_* x$ with$ z_*$, and add two constraints.\n $$ \\begin{array}{ll} \\operatorname{minimize} \u0026 \\frac{1}{2} \\|x-y\\|_{2}^{2} + \\lambda\\|z_r\\|_{1} + \\lambda\\|z_c\\|_{1} \\\\ \\text { subject to } \u0026 D_r x-z_r=0 \\\\ \\text { subject to } \u0026 D_c x-z_c=0 \\end{array} $$  Then, we use augmented lagrangian method to remove constraints：\n $$ \\begin{aligned} L_{\\rho}( x , z_r , \\nu_r, z_c, \\nu_c ) = \\frac{1}{2}\\|x-y\\|_{2}^{2} \u0026 + \\lambda\\|z_r\\|_{1}+ \\nu_r ^{ T }(D_r x-z_r)+\\frac{\\rho}{2}\\|D_r x -z_r\\|_{2}^{2} \\\\ \u0026 + \\lambda\\|z_c\\|_{1}+ \\nu_c ^{ T }(D_c x-z_c)+\\frac{\\rho}{2}\\|D_c x -z_c\\|_{2}^{2} \\end{aligned} $$  Let $\\mu_r = \\nu_r / \\rho$，$\\mu_c = \\nu_c / \\rho$，transform the above equation into the following one:\n $$ \\begin{aligned} L_{\\rho}( x , z_r , \\nu_r, z_c, \\nu_c )= \\frac{1}{2}\\|x-y\\|_{2}^{2} \u0026 + \\lambda\\|z_r\\|_{1}+ \\frac{\\rho}{2}\\|D_r x-z_r+ \\mu_r \\|_{2}^{2}-\\frac{\\rho}{2}\\| \\mu_r \\|_{2}^{2} \\\\ \u0026 + \\lambda\\|z_c\\|_{1}+ \\frac{\\rho}{2}\\|D_c x-z_c+ \\mu_c \\|_{2}^{2}-\\frac{\\rho}{2}\\| \\mu_c \\|_{2}^{2} \\end{aligned} $$  X subproblem #   For x subproblem, we need to optimize the following equation:\n $$ \\begin{aligned} x ^{(k+1)} =\\arg \\min _{ x } \\enspace \\|x^{(k)}-y\\|_{2}^{2} \u0026 + \\left\\|\\sqrt{\\rho}D_r x^{(k)}- \\sqrt{\\rho}(z_r ^{(k)}- \\mu_r ^{(k)})\\right\\|_{2}^{2} \\\\ \u0026 + \\left\\|\\sqrt{\\rho}D_c x^{(k)}- \\sqrt{\\rho}(z_c ^{(k)}- \\mu_c ^{(k)})\\right\\|_{2}^{2} \\end{aligned} $$  This is a least square problem\n $$ \\min _{x}\\left\\|\\left[\\begin{array}{c} I \\\\ \\sqrt{\\rho} D_r \\\\ \\sqrt{\\rho} D_c \\\\ \\end{array}\\right] x^{(k)} -\\left[\\begin{array}{c} y \\\\ \\sqrt{\\rho}\\left( z_r ^{(k)}- \\mu_r ^{(k)}\\right) \\\\ \\sqrt{\\rho}\\left( z_c ^{(k)}- \\mu_c ^{(k)}\\right) \\\\ \\end{array}\\right]\\right\\|_{2}^{2} $$  And we can solve it with the solution of least square $(X^TX)^{-1}X^TY$：\n $$ \\begin{aligned} x ^{(k+1)} \u0026=\\left( I +\\rho (D_r^TD_r + D_c^TD_c) \\right)^{-1}\\left[ I, \\sqrt{\\rho} D_r^T, \\sqrt{\\rho} D_c^T \\right]\\left[\\begin{array}{c} y \\\\ \\left.\\sqrt{\\rho}\\left( z_r ^{(k)}- \\mu_r ^{(k)}\\right)\\right] \\\\ \\left.\\sqrt{\\rho}\\left( z_c ^{(k)}- \\mu_c ^{(k)}\\right)\\right] \\\\ \\end{array}\\right] \\\\ \u0026=\\left( I +\\rho (D_r^TD_r + D_c^TF_c) \\right)^{-1} \\left( y + \\rho \\left[ D_r^T\\left( z_r ^{(k)}- \\mu_r ^{(k)}\\right) + D_c^T\\left( z_c ^{(k)}- \\mu_c ^{(k)}\\right) \\right] \\right) \\end{aligned} $$  DFT Speedup #  The inverse of matrix $I +\\rho (D_r^TD_r + D_c^TD_c)$ is computationally expensive. To see why, suppose there is a 200 * 300 image, then the shape of $D_r$ and $D_c$are both (200*300, 200*300), and it means we have to take inverse of a giant  (200*300, 200*300) matrix, which is impractical.\nThanks to convolution theorem, we could solve this equation purely in frequency domain.\nFor detail, we start with moving $(I +\\rho (D_r^TD_r + D_c^TD_c))^{-1}$ to the left hand side:\n $$ \\left( I +\\rho (D_r^TD_r + D_c^TF_c) \\right) x ^{(k+1)} = \\left( y + \\rho \\left[ D_r^T\\left( z_r ^{(k)}- \\mu_r ^{(k)}\\right) + D_c^T\\left( z_c ^{(k)}- \\mu_c ^{(k)}\\right) \\right] \\right) $$  Suppose $\\mathcal{F}$ is the Fourier matrix and $\\mathcal{F}^{-1}$ is the inverse Fourier matrix. Perform fourier transform on the both sides of above equation gives us the following result (using the linearity of Fourier transform):\n $$ \\left( \\mathcal{F}I +\\rho (\\mathcal{F}D_r^TD_r + \\mathcal{F}D_c^TF_c) \\right) x ^{(k+1)} = \\left( \\mathcal{F}y + \\rho \\left[ \\mathcal{F}D_r^T\\left( z_r ^{(k)}- \\mu_r ^{(k)}\\right) + \\mathcal{F}D_c^T\\left( z_c ^{(k)}- \\mu_c ^{(k)}\\right) \\right] \\right) $$  If we use the property of $\\mathcal{F}^{-1}F = \\mathcal{F}^H\\mathcal{F} = I$, we could get:\n $$ \\begin{aligned} \\left( \\mathcal{F}I +\\rho (\\mathcal{F}D_r^TD_r + \\mathcal{F}D_c^TF_c) \\right) \\mathcal{F}^H\\mathcal{F} x ^{(k+1)} = LHS \\\\ \\text{=} \\left( \\mathcal{F}I\\mathcal{F}^H +\\rho (\\mathcal{F}D_r^TD_r\\mathcal{F}^H + \\mathcal{F}D_c^TF_c\\mathcal{F}^H) \\right) \\mathcal{F} x ^{(k+1)} = LHS \\end{aligned} $$  From the facts below:\n $\\mathcal{F}I\\mathcal{F}^H = I$ Fourier matrix can diagonize any circulant matrix in the way of $\\mathcal{F}D\\mathcal{F}^H$, See [Link1], [Link2].  We could get:\n $$ \\left( I +\\rho (\\Lambda_r + \\Lambda_c) \\right) \\mathcal{F} x ^{(k+1)} = \\left( \\mathcal{F}y + \\rho \\left[ \\mathcal{F}D_r^T\\left( z_r ^{(k)}- \\mu_r ^{(k)}\\right) + \\mathcal{F}D_c^T\\left( z_c ^{(k)}- \\mu_c ^{(k)}\\right) \\right] \\right) $$  In frequency domain, convolution is element-wise multiplication, so the final result is:\n $$ x ^{(k+1)} = \\mathcal{F}^{-1} \\frac{\\left( \\mathcal{F}y + \\rho \\left[ \\mathcal{F}D_r^T\\left( z_r ^{(k)}- \\mu_r ^{(k)}\\right) + \\mathcal{F}D_c^T\\left( z_c ^{(k)}- \\mu_c ^{(k)}\\right) \\right] \\right)} {\\left( I +\\rho (\\Lambda_r + \\Lambda_c) \\right)} $$  Implementation #  Recall that any doubly block circulant matrices $D$ can be diagonized by Fourier matrix. The column of $F^H$ are the eigen vectors and the corresponding eigen values are the DFT values of the signal generating the circulant matrix.\nAnd with the following equations, we know the eigen value of $D^TD$ are just the multiplication of the eigen matrix of $D$ and its conjugate.\n $$ H = \\mathcal{F}^{H} D \\mathcal{F} \\\\ H^H = \\mathcal{F}^{H} D^T \\mathcal{F} \\\\ H^HH = \\mathcal{F}^{H} D^T \\mathcal{F}\\mathcal{F}^{H} D \\mathcal{F} = \\mathcal{F}^{H} D^T D \\mathcal{F} $$  Summarize all the fact above, we could caluclate $\\Lambda_r + \\Lambda_c$ with the following Python snippet.\neigDtD = np.abs(np.fft.fft2(np.array([[1, -1]]), (row, col))) ** 2 + \\ np.abs(np.fft.fft2(np.array([[1, -1]]).transpose(), (row, col))) ** 2 Note that we use the fact that $A^HA = ||A||_2^2$\nSince $\\Lambda_r + \\Lambda_c$ is diagonal, addition and multiplication of $I +\\rho (\\Lambda_r + \\Lambda_c)$ could be done in element-wise way.\nlhs = 1 + rho * eigDtD "}]