[{"id":0,"href":"/blog/docs/notes/concept/","title":"Concept","section":"Notes","content":"Concepts #  Deep Generative Models #   VAE #   再看变分自动编码器VAE: [ Note], [ Slide]  Flow-based #   Invertible Neural Network Normalizing Flow (Flow Neural Network) [Note] Denoising Normalizing Flow  Illustration   EM #    推导高斯混合模型的EM算法：[ Note] 从最小化自由能的角度推导高斯混合模型的EM算法：[ Note]  ADMM #    ADMM Tutorial: [ Note] ADMM各个任务推导: [ Note]  Others #    Denoising Autoencoder  朴素贝叶斯 #  朴素贝叶斯 用于求解分类问题，给定数据，每个数据点包含多列特征和一个类别。 任务是估计给定特征，各个类别出现的概率，即求： $$ p\\left(C \\mid F_{1}, \\ldots, F_{n}\\right) $$\n我们可以用频率估计概率的方法直接从数据中估计这个概率，但是当特征F的种类很多，取值也很多的情况下，我们需要很大量的数据才能做出准确估计。这在现实生活中往往是做不到的。\n因此，朴素贝叶斯首先用贝叶斯公式改写求解目标： $$ p\\left(C \\mid F_{1}, \\ldots, F_{n}\\right)=\\frac{p(C) p\\left(F_{1}, \\ldots, F_{n} \\mid C\\right)}{p\\left(F_{1}, \\ldots, F_{n}\\right)} $$\n分母是每个特征出现的联合概率，与类别无关，可以看作某个未知的定值。对于分子，$p(C)$是比较容易通过频率估计的，而$p\\left(F_{1}, \\ldots, F_{n} \\mid C\\right)$则不好估计，因为当特征F很多的时候，数据一般比较稀疏，给定$C$，$F_{1}, \\ldots, F_{n}$出现的概率可能为0，因为数据集中不存在这种情况（但不代表真的出现概率为0）。\n因此，朴素贝叶斯做了个朴素的假设，即各个特征相互独立。基于此，则有：\n $$ \\begin{equation} \\begin{aligned} p\\left(F_{1}, \\ldots, F_{n} \\mid C\\right) \u0026 \\propto p\\left(F_{1} \\mid C\\right) p\\left(F_{2} \\mid C\\right) p\\left(F_{3} \\mid C\\right) \\ldots \\\\ \u0026 \\propto \\prod_{i=1}^{n} p\\left(F_{i} \\mid C\\right) \\end{aligned} \\end{equation} $$  显然，基于频率统计概率$p\\left(F_{i} \\mid C\\right)$会更加容易得多。\n  "},{"id":1,"href":"/blog/docs/notes/paper/","title":"Paper","section":"Notes","content":"Paper Notes #  一些论文阅读笔记\n  [PDF] Tuning-free Plug-and-Play Proximal Algorithm for Inverse Imaging Problems  [PDF] Effective Snapshot Compressive-spectral Imaging via Deep Denoising and Total Varia-tion Priors  [Draft] RAFT: Recurrent All-Pairs Field Transforms for Optical Flow  [Draft] PatchMatch: A Randomized Correspondence Algorithm for Structural Image Editing  Simple Review #   Vision Transformer for Small-Size Datasets #   提出了一个针对小数据集的Transformer。 主要模块：Shifted Patch Tokenization, Locality Self-Attention。细节没看。  Functional Neural Networks for Parametric Image Restoration Problems #   对于超分，去噪，JPEG Decompression，有不同的parameter（scale factor，noise level等），现有方法针对不同parameter单独训练模型，或不考虑不同parameter的差异，一起训练一个统一的模型。 作者提出学习一个函数，输入paramter，输出针对这个parameter的模型参数。主要用点是不用单独训练每个parameter的模型，而是训练一个函数，输入parameter，输出模型参数。  Variational Image Restoration Network #   用了Generative Model和Variational inference做Image Restoration。太长公式太多，没细看。  Designing a Practical Degradation Model for Deep Blind Image Super-Resolution #   Github\n 提出了一个超分的Degradation Model用于真实图像超分。 其实就是总结了常见的Blur，Downsample，Noise的种类，然后degradation就是这些的排列组合。  Revisiting RCAN: Improved Training for Image Super-Resolution #   提出了一些训练策略，让RCAN的性能进一步提升。 策略简单说：多GPU大Batch Size，SiLu替换ReLu，训练更长时间，Lamb Optimizer，48*48 patch训练，64*64 finetune，FP16加速训练，不要regularization，先训练x2，然后用x2参数训练x3，以此类推。  Enhancing Low-Light Images in Real World via Cross-Image Disentanglement #  arxiv 2022 | CIDN\n 不需要配对数据训练的暗光增强网络 核心思想，将一张图分成 content feature 和 brightness feature。使用低光图像的content feature，和正常光图像的brightness feature，然后使用normal-light decoder重构出来。正常光参考图像不必与低光图像对齐。  结构图   训练数据是参考图像粗对齐的正常光图，测试数据参考图像可以完全不一样。 几个Loss：（1）低光和正常光的content feature应该类似。(2) 低光的content feature和brightness feature应该能够重构出低光图像。（3）正常光图像没有gt。（4）令光照特征符合正态分布，与结构无关。（5）VGG perceptual loss。    Disentangling Noise from Images: A Flow-Based Image Denoising Neural Network #  arxiv 2021 | Github\n Invertible Denoising Network: A Light Solution for Real Noise Removal的期刊扩展。  Denoising Normalizing Flow #  NeurIPS 2021\n 本文并不是用来去噪的Normalizing Flow。类似Denoising Autoencoder。  DeFlow: Learning Complex Image Degradations from Unpaired Data with Conditional Flows #  CVPR 2021 | Github | Blog:Normalizing Flow\n 提出了一个不需要配对数据训练的conditional flow网络用于合成训练数据。 具体做法简介：需要先了解Normalizing Flow。TODO  Invertible Denoising Network: A Light Solution for Real Noise Removal #   Github | Blog:Invertible Network\n 提出使用Invertible Network做真实噪声去噪。 网络将noisy image编码成low resolution clean image和一个high frequency和noise信息的latent vector。 逆过程把latent vector换成一个从标准正态分布取样的vector，然后逆回去，得到clean image。  问题（比较疑惑的地方）：为什么是随机取样，取出来的latent vector起的作用是什么，不同的vector，恢复出来的clean image不是是不一样的？\nAdaDM: Enabling Normalization for Image Super-Resolution #   传统超分网络一般不加Normalization，因为这会使得特征方差变小，对性能有很大影响。 这篇文章文章提出了 Adaptive Deviation Modulator (AdaDM)，可以放大方差，使得Normalization又能加了。并且有性能提升。  IDR: Self-Supervised Image Denoising via Iterative Data Refinement #   Github\n 提出了一个unsupervised denoising method，不用配对数据训练。 基于在带噪图像上加noise model的合成噪声训练的网络，能够一定程度地对带噪图像降噪。noiser-noisy数据集和noisy-clean的domain gap越小，网络降噪性能越好。 本文提出用noiser-noisy数据集训练一个网络，然后用网络去噪得到更干净的noisy图像，再合成noiser-nosiy数据集。迭代进行训练，不断缩小noiser-noisy数据集和noisy-clean的domain gap。  Rethinking Noise Synthesis and Modeling in Raw Denoising #   Github\n 物理噪声模型对于真实场景去噪比DNN的好使，但是需要对不同相机，光照条件单独建模或者标定，毕竟麻烦。 本文提出从相机噪声中随机取样作为合成噪声，因此不需要噪声模型，只需要拍摄多张带噪图像作为database即可。 作者将噪声分为信号相关和信号无关的，信号无关采用随机取样，信号相关部分只考虑photo shot noise，从泊松分布采样使用，仍然需要标定。  On Efficient Transformer and Image Pre-training for Low-level Vision #   Github\n 提出了一个Encoder-Decoder结构的Transformer。比IPT小10倍，只用200k（15.6%的ImageNet）数据预训练。GFLOPS只有SwinIR的8.4%, 38 vs 451。 研究了预训练策略，发现多任务预训练比单任务和单纯增加数据量好。simply increasing the data scale may not be the op- timal option, and in contrast, multi-related-task pre-training is more effective and data-efficient.  TransWeather: Transformer-based Restoration of Images Degraded by Adverse Weather Conditions #   Github\n Transformer结构，不同任务相同encoder，decoder，但是decoder，把任务类型作为query传进decoder。  Quick Review   All in One Bad Weather Removal using Architectural Search #   用多个Encoder，一个Decoder做Image Restoration，具体是Bad Weather Removal。 Encoder后面接了一个NAS搜的网络，其他没有特别的设计。Feature Space也没什么约束。在去噪等传统领域效果感觉不一定好，很可能不好。  Quick Review   PatchMatch: A Randomized Correspondence Algorithm for Structural Image Editing #   Sample Impl ｜ 知乎解读 | 本站 🌟\n 图像匹配的典中典，基于匹配块周围的匹配也近似匹配的先验知识的随机化算法。 原论文挺好读的，但是建议先看解读有一个insight之后再读。  Quick Review  随机初始化匹配关系。 基于正确的匹配关系进行修正，即正确匹配的Patch Pair周围的patch应该是匹配的。 加入扰动，在修正后匹配的匹配对周围搜索是否有更加匹配的patch。     A ConvNet for the 2020s #   Offical Impl\n CNN的大型Ablation Study，研究各种已有模块和训练技巧的有效性，基于此构建了一个超越现有Transformer的纯CNN模型。  Masked Autoencoders Are Scalable Vision Learners #   Offical Impl\n 基于Transformer的（高层）视觉预训练模型，只用重构任务。  "},{"id":2,"href":"/blog/docs/gen/","title":"AIGC","section":"Docs","content":"Generated Space #  Denoising is all we need.  Getting Started\n  Introduction  Diffusion Models\nTBD\nScore-based Generative Modelling\n  Reverse Time Stochastic Differential Equations for Generative Modelling  Stochastic Differential Equations  "},{"id":3,"href":"/blog/docs/matrix/","title":"Matrix","section":"Docs","content":"Matrix #  正在努力编写中✍️  矩阵分析速查表: [ PDF]\n  如何将各个知识点串起来？  杂七杂八: 一些无法分类的小知识  线性空间  各种矩阵\n  对称矩阵  正定矩阵  正交矩阵  相似矩阵 : ⚠️ 相似矩阵是指一系列互相相似的矩阵。  特征值/特征向量\n  基础知识  矩阵对角化 : 利用特征值，特征向量进行。  Jordan Form  矩阵分解\n  特征值分解(矩阵对角化) : 对角化也算是一种分解。  奇异值分解 : 特征值分解(eigen decomposition)的扩展  谱分解 : 特征值分解的另一种表达形式。  "},{"id":4,"href":"/blog/posts/ai/dmd/","title":"Distribution Matching Distillation","section":"Posts","content":"Regression Loss #  Distribution Matching Loss #  # "},{"id":5,"href":"/blog/posts/ai/consistency_model/","title":"扩散模型蒸馏之一致性模型","section":"Posts","content":"Latent Consistency Model（LCM）是近期非常流行的扩散模型蒸馏方法。本文将介绍其背后的基础模型 Consistency Model 以及 LCM 的原理。\n 图片取自 Latent Consistency Model 论文   🤗 写在前面 #  扩散模型的蒸馏研究事实上在去年就已经开始了，当时的 On Distillation of Guided Diffusion Models 还拿了CVPR 2023 的 Best Paper Nomination。 后续其实也有蛮多蒸馏工作出现，例如：\n SnapFusion: Text-to-Image Diffusion Model on Mobile Devices within Two Seconds  【没开源】   BOOT: Data-free Distillation of Denoising Diffusion Models with Bootstrapping  【coming soon半年了】   InstaFlow: One Step is Enough for High-Quality Diffusion-Based Text-to-Image Generation  【严格来说，这个和 LCM 算同期，一开始没有 code，后面开源了模型，没有训练 code】    不过遗憾的是，这些工作都没有获得广泛的关注，直到 Latent Consistency Model 出现。事实上，LCM 刚出现的时候我还在吐槽，怎么他就比了 Guided-Distill 一个方法。 后面转念一想，前面那么多工作其实都没有开源，甚至 Guided-Distill 也是作者自己尝试复现的。因此那些工作没有受到关注也就可以理解了。\n总的来说，LCM 可以说是第一个完全开源的扩散模型蒸馏方法（据我所知），而且因为训练速度非常快，可以在 64 batch size上训几百个 step 就可以看出显著效果， 所以它瞬间就席卷了 Stable Diffusion 社区。\nConsistency Model (CM) #  在了解 LCM 之前，我们可以先了解一下他的基底模型，也就是 Consistency Model（CM）的原理。 事实上，在了解完 CM 之后，我们就会发现 LCM 其实非常自然，基本上可以看作是 CM 在 text-to-image 的直接扩展。\n那么，consistency model 是什么呢？简单来说，\n 它是 song yang 博士提出的一类新的生成模型。 它是扩散模型的一种，但与 DDPM 不同。 它可以通过蒸馏的方式从 DDPM 的模型提取而来，也可以从零开始训练。 它具有快速采样的特点，因此可以用来蒸馏 DDPM 训练得到的模型，例如 Stable Diffusion 模型，从而实现加速的目的。  理解 Motivation #  在阅读 consistency model 的论文的时候，我们一上来会看到这么一个定义（右上角的 teaser）\n 这个定义对于对 score matching 那一套不熟悉的人，可能会感觉有点绕。用扩散模型的概念来说，PF-ODE 对应的是 DDIM 这类确定性的采样过程。 而 consistency model 就是要求我们的扩散模型在一个采样路径上的每一个 noisy sample 预测的 x0 都是一样的。\n 可能有人要问，我自己一开始也问了，DDPM 的训练目标不就是这个吗，随机采样一个 timestep，然后预测 x0，希望和 gt 的 x0 一致。\n 答案当时是不一样的，不然 consistency model 还提出来干什么？关键点在于 consistency model 要求训练出来的模型 对于一个采样路径上的每个点都保持 consistency，即预测结果保持一致。\n🙋‍♂️ 提问：那么怎么理解这个一致性呢，它为什么能帮助提升采样速度？  回忆 DDPM 的训练目标，是下面所展示的一个 KL 散度：\n $$ \\mathbb{E}_q[\\underbrace{D_{\\mathrm{KL}}\\left(q\\left(\\mathbf{x}_T \\mid \\mathbf{x}_0\\right) \\| p\\left(\\mathbf{x}_T\\right)\\right)}_{L_T}+\\sum_{t1} \\underbrace{D_{\\mathrm{KL}}\\left(q\\left(\\mathbf{x}_{t-1} \\mid \\mathbf{x}_t, \\mathbf{x}_0\\right) \\| p_\\theta\\left(\\mathbf{x}_{t-1} \\mid \\mathbf{x}_t\\right)\\right)}_{L_{t-1}} \\underbrace{-\\log p_\\theta\\left(\\mathbf{x}_0 \\mid \\mathbf{x}_1\\right)}_{L_0}] $$  它包含 T 项，对应 DDPM 一个完整的去噪路径，但DDPM 实际训练的时候并不是采样一个完整的路径，然后算这个 loss 训练的，它是随机采样的时刻，然后只算这个时刻的 loss 部分，然后通过蒙特卡洛估计去算这个 loss 的期望。\n 😯 那么很明显，这里有一个问题，DDPM 采样的时候不同时刻对应的 x0 是不一样的，所以这里的 loss 并不能很好的估计出这个 KL 散度的期望。 这么训出来的模型，对于同一个采样路径上的 noisy sample 是没有 “映射到同一个 x0” 的约束的。\n 没有这个约束的话，那么我们的采样过程可能就会打架，第10 个 step 可能预测的是一个 x0，下一步预测的 x0 就变了，这导致采样路径很不稳定，做了很多无用功。与之相反，consistency model 因为有了一致性，所以可以步子迈的大一些，采样速度也就快了。\n那么为什么 DDPM 步子不能太大呢？因为 DDPM 没有一致性，第一步步子迈的大了，虽然你更接近第一步对应的 x0 了，但从第一步的终点出发，并不一定是往第一步的 x0 走，所以得一小步一小步走，利用“函数的平滑性“，相近的点预测的 x0 应该是比较接近的。\n🤖《此处应该有一个配图》\n原理 🌧️ 细节 #  理解了consistency model 的 motivation 之后，下一步就是如何实现这个约束了。对于此，consistency model 支持两种训练方式：\n 从训练好的模型蒸馏得到 从头开始训练  对于前者，我们的训练 loss 就是约束一个采样路径上的相邻点的输出保持一致。实现起来很简单，采样一个 noisy sample, $x_t$ 然后可以预测一个 $x_0$，接着通过一个 Diffusion ODE Solver（比如 DDIM），得到$x_{t-1}$，再预测一个$\\hat{x}_0$，然后就可以算 loss 了, $loss=(x_0- \\hat{x}_0)^2$\nConsistency Model 的数学定义\nConsistency model 就是一个函数（用神经网络拟合），它可以用来求解 PF ODE（即扩散模型的采样过程）。对于一个采样过程里的所有样本点, ${x_t}_{t\\in[\\epsilon, T]}$，Song Yang 把 Consistency function 定义为:\n $$ \\boldsymbol{f}:\\left(\\mathbf{x}_t, t\\right) \\mapsto \\mathbf{x}_\\epsilon $$  这个定义包含两个含义  一个是所有输入的输出都一致，即 \u0026ldquo;its outputs are consistent for arbitrary pairs \u0026hellip;\u0026rdquo; 所有输入都映射到了采样过程的初始位置 $x_\\epsilon$。     Boundary Condition\n对于上述定义，我们知道 consistency model 有一个边界条件：\n $$ \\boldsymbol{f}\\left(\\mathbf{x}_\\epsilon, t\\right) = \\mathbf{x}_\\epsilon $$  对于这个边界条件，如果 consistency model 是个神经网络的话，我们可以直接通过合理定义 consistency function 的参数化方法进行约束。如右图公式 4和公式 5。\n在这里，作者采用的是公式 5 的方式。\n Tips: 不过实际实验下来，直接用朴素的参数方法也没什么影响，即 $t=\\epsilon$ 也用网络的输出，而不是像公式 4 一样，直接置为输入。\n    EMA \u0026amp; Target Network\n回忆，consistency model 蒸馏的训练方法，我们需要预测两个 $x_0$，朴素的做法就是用 teacher model 初始化 student model，然后算 loss，不断优化即可。\n事实上，我们的优化目标可以看作一种 bootstrapping 方法，类似强化学习里的 time difference 算法，第二步预测的 x0 可以看作是对 x0 的更准确的估计，因此我们希望第一步的 x0 和第二步的 x0 保持一致。\n   另一方面，如果我们第一步第二步都用同一个网络的话会产生累计误差。怎么理解？因为我们是用同一个模型输出 GT（第二步的 x0） 和 Prediction（第一步的 x0），如果优化一次学偏了，那么我们的 GT 就会被带偏，这样累计下来就会越来越偏。\n因此，作者在这里使用两个不同的模型（都用 teacher model 初始化），分别预测 GT 和 Prediction，其中预测 GT 的用 EMA 的方式更新，预测 prediction 的网络正常用梯度下降更新。\n用强化学习的术语来说，预测 GT 的网络称为 target network（因为它预测是 target），预测 prediction 的网络称为 online network（因为它是 online更新的，使用 loss，target network 的 EMA更新是 offline ）。\n对应公式的话，$\\theta$ 就是 online network，另一个 $\\theta -$ 是 target network。\n一些不那么重要的点 #  证明 #  凭什么上面提到的蒸馏方法训练出来的模型能够满足 consistency model 的定义？  作者在论文里给出了证明。\n从零开始训练 Consistency Model #  TODO\nLatent Consistency Model (LCM) #  理解了consistency model 之后，将其应用到 stable diffusion 只需要解决一个问题，怎么处理 classifier free guidance，其他都是一模一样的。\n实现细节 #  Classifier free guidance #  在 LCM 中，作者的做法就是将 guidance scale 作为一个参数加入到 Student model 里，具体实现是调制进 timestep embedding。然后 target network 预测的 GT 改成加了 classifier free guidance 的 model out。\n训练的时候，guidance scale 就是随机取的。\nSkip Timestep #  朴素的 consistency model 可能是直接蒸馏 1000 步的模型，通过 1000 步的采样序列，但事实上 consistency model 并没有要求一定要这样，因此作者在这里使用更高阶的 sampler 采样了 50 步的序列，用于训练。 实现了加速训练的效果。\nLCM-LoRA #  LCM-LoRA 就是用 LoRA 训练 UNet 网络，作者发现这么训出来的 LoRA 具有一定的迁移能力，套到别的模型也能产生加速效果，并且可以和其他 LoRA 组合。\n除此之外，可能作者发现即使训练的时候把 guidance scale 喂给网络，但是 inference 的时候改变 guidance scale 也没啥用，然后 LCM-LoRA 就没有这个 condition 了。\n另外，EMA作者发现没啥用也去掉了。\n讨论和 Note #   LCM 训练非常快，64 batch size，每训练 10 个 step 都可以看到显著变化，训练 100 个 step，4 个 step 的图已经能看了。 LCM-LoRA 学习率要大一点（比如1e-4），太小训了没变化。 数据集的分辨率和 teacher model 一致，不一致可能训不出来。 "},{"id":6,"href":"/blog/posts/ai/analytic_dpm/","title":"Analytic-DPM 速览","section":"Posts","content":"Analytic-DPM 是 ICLR 2022 的最佳论文，作者是清华的 Fan Bao。这是一篇理论性很强的论文，因此这里不会给出详细的推导解释，只阐述这篇论文究竟做了一件什么事情。\n关于这篇论文，这里我们还拿到了来自 Fan Bao 的 Presentation Slide，大家可以参考阅读一下。\n TL \u0026amp; DR #  为了阐述论文到底在做什么，我们需要首先回忆一下，DDPM 的推导过程\n 定义一个加噪过程 $p(x_t|x_{t-1})$，由 $\\beta$ 序列决定 根据这个加噪过程推导出 $p(x_t|x_0)$ 和 $q(x_{t-1}|x_0, x_t)$，前者直接展开就可以了，后者利用贝叶斯公式推导 $$ q(x_{t-1} \\vert x_t, x_0) = q(x_t \\vert x_{t-1}, x_0) \\frac{ q(x_{t-1} \\vert x_0) }{ q(x_t \\vert x_0) } $$ 反向去噪需要用到 $p(x_{t-1}|x_t)$, 我们需要估计这个分布的均值和方差，这个可以用网络来估计。 网络训练的话通过 ELBO 训练 通过推导可以发现，我们约束均值需要和 $q(x_{t-1}|x_0, x_t)$ 的均值一致，因此可以直接采用其均值，预测未知部分。 对于 DDPM 来说，方差不训练，直接采用固定的值，DDPM 测试了取 $p(x_t|x_{t-1})$ 的方差 或者 $q(x_{t-1}|x_0, x_t)$ 的方差，结果差不多。DDIM 则是使用了 0 方差，不过对应均值的表达式也变了。  可以看出，这里面方差的选取是一个仍然可以调整的变量，最优的方差是什么我们还不知道（何为最优呢？对于 Analytic-DPM 来说，选取这个方差我们得到的是 Loss 的最优解）。\nAnalytic-DPM 这篇论文的贡献就是，他们发现这个最优的方差是可以解析的算出来的。  他们的结论是：\n $$ \\begin{aligned} \u0026 \\boldsymbol{\\mu}_n^*\\left(\\boldsymbol{x}_n\\right)=\\tilde{\\boldsymbol{\\mu}}_n\\left(\\boldsymbol{x}_n, \\frac{1}{\\sqrt{\\bar{\\alpha}_n}}\\left(\\boldsymbol{x}_n+\\bar{\\beta}_n \\nabla_{\\boldsymbol{x}_n} \\log q_n\\left(\\boldsymbol{x}_n\\right)\\right)\\right) \\\\ \u0026 \\sigma_n^{* 2}=\\lambda_n^2+\\left(\\sqrt{\\frac{\\bar{\\beta}_n}{\\alpha_n}}-\\sqrt{\\bar{\\beta}_{n-1}-\\lambda_n^2}\\right)^2\\left(1-\\bar{\\beta}_n \\mathbb{E}_{q_n\\left(\\boldsymbol{x}_n\\right)} \\frac{\\left\\|\\nabla_{\\boldsymbol{x}_n} \\log q_n\\left(\\boldsymbol{x}_n\\right)\\right\\|^2}{d}\\right), \\end{aligned} $$  课代表总结：最优均值和 DDPM 的一致，保持不变。方差不一样了。\n 这里用了 Score-based 的表示，实际使用时，需要转换一下变成DDPM的$\\epsilon$表示。\n  $\\lambda_n^2$ 是论文里对方差的一个通用表示，对于 DDPM 直接取 $\\bar{\\beta_n}$ 即可。 公式里的数学期望，可以通过蒙特卡洛估计计算，抽样的分布是$q_n(x_n)$，即$x_n$的数据分布，因此，可以直接用整个数据集的数据，每个样本加噪得到$x_n$即可。 "},{"id":7,"href":"/blog/posts/ai/dpm_solver/","title":"DPM-Solver 解析","section":"Posts","content":"DPM-Solver 可能是目前采用最为广泛的快速采样算法之一了吧。该论文发表于 NeurIPS 2022。作者 Cheng Lu 和 Analytic DPM 的作者 Fan Bao 是同门，都是清华 Jun Zhu 的学生。\n 值得注意的是，Yang Song 和 Jiaming Song 本科的时候也跟着 Jun Zhu 做科研。这传承，可真是绝了。\n 按照惯例，先上作者的 Presentation Slide。\n How it work? #  PPT 里其实讲的很清楚了，就是把积分里能拿出来的东西全拿出来解析的算。\n一些有意思的点\n DDIM 是一阶的 DPM-Solver（没错，二者是一模一样的）  DPM-Solver++ #  DPM-Solver++ 负责将 DPM-Solver 扩展到 Guided Sampling 的情况，但其实没啥改动\n 改成了 $x_0$ 的 formulation，这样可以对 $x_0$ 做 clipping，因为作者分析 guided sampling 的 large cfg scale 会导致预测的 $x_0$ out-of-bound。 提出了一个 multi-step 的小改进，利用前面计算的 $x$ 计算 numerical gradient。  详细对比可以看 Open Review\n"},{"id":8,"href":"/blog/posts/ai/ggdm/","title":"GGDM: Learnable Diffusion Model Sampler ","section":"Posts","content":"这篇是 Google 发表在 ICLR 2022 的一篇论文，它讨论了如何构造一个可学习的 Sampler 用于提升采样质量。\n文章主要解决三个问题：\n 如何选取待优化的参数？ 损失函数怎么定义？ 怎么优化？   GGDM #  1. 如何选取待优化的参数？\n主要是各个分布的均值方差，具体不看了，这个 sampler 后面也没什么人用了。\n2. 损失函数怎么定义？\n使用 Kernel Inception Distance (KID)，不能用 pixel wise 的 loss，会让结果变差。\n3. 怎么优化？\n优化的要必须过完整个 inference process，因此显存问题必须解决，作者在这里使用了 JAX 的 Gradient Rematerialization，应该就是 Gradient Checkpointing 吧。除此之外，inference process 过程分布采样的操作可以用重参数化解决。\n"},{"id":9,"href":"/blog/posts/ai/pndm/","title":"扩散模型中的 PNDM 采样","section":"Posts","content":"PNDM 采样算法是一个发表于 ICLR 2022 的工作，最早公开的时间是 2022 年的 2 月份。作者是来自浙江大学的 Luping Liu （DPM-Solver 的作者是清华的 Cheng Lu，别搞混了 hh）。\n这篇论文一开始看的时候感觉好多公式，还挺复杂的，但是当理解 DDIM 之后就会发现，这篇论文其实 DDIM 非常简单的一个扩展，论文中的理论部分其实并没有特多新的东西，不过比较惊喜的是，效果却非常好。\n 关于 DDIM 采样算法的推导 可以查看上一篇 博客 的介绍。\n 另一方面，DDIM 2020年 10月就公开了，这么简单的扩展居然到了 2022年 2 月份才出现，可见 DDIM 的超前程度，orz。\n Background #  我们知道扩散模型的采样过程可以视作一个梯度下降的过程，其中梯度可以用 DDPM 训练出来的 UNet 进行求解，下降的过程就是往 data density 越高的地方走，因此可以实现一个 generation 的效果。\n另一方面，Song Yang 大神在 Score-Based Generative Modeling through Stochastic Differential Equations 中证明了这个采样过程可以用随机微分方程（SDE）或者常微分方程（ODE）进行建模。\n这意味着，当我们写出扩散模型的微分方程后，我们就可以用发展了几十年的求解微分方程的数值方法对其进行求解。虽然我已经把本科《数值分析》课学的全还给老师了，但是从直觉上求解常微分方程是更容易的（事实也是如此），因此后续用于加速扩散模型采样的算法大部分都是基于 ODE 来做的，并且他们算法的设计大量参考了诸如 forward Euler method, Runge-Kutta method, linear multi-step method, predictor–corrector method 等数值算法。\n首先，让我们来回忆一下微分方程\n《不要紧张\u0026hellip;》\n微分方程就是一个包含了一个函数 $f$ 和其各阶导数的 $f'$, $f''$ \u0026hellip; $f^n$ 的一个方程。例如 $f'(x)= xf(x)$\n如果微分方程里包含随机变量，那么它就是随机微分方程，如果没有，那它就是常微分方程。随机微分方程比较复杂，非数学系应该都不太学，不过常微分方程高数里是有的。在扩散模型的加速采样中，我们大部分情况都只考虑常微分方程，也就是 ODE。\n特别地，在扩散模型里，我们只需要考虑ODE一个更简单的形式，也就是 linear differential equation，在这里微分方程里的所有函数/导函数，都是线性组合的，不会出现诸如 $f'(x) = e^{f(x)}$ 这种非线性的情况。具体地，这类 ODE 可以写成下面这样：\n$$ a_0(x) y+a_1(x) y^{\\prime}+a_2(x) y^{\\prime \\prime}+\\cdots+a_n(x) y^{(n)}+b(x)=0 $$\n 对于扩散模型来说，从 DDPM 的角度来看，我们是一个通过定义一个固定的加噪过程，然后通过这个固定加噪过程去推导去噪过程，这个加噪过程可以描述为：\n$$ x_t = \\sqrt{1-\\beta_t} x_{t-1} + \\sqrt{\\beta_t} \\epsilon $$\n如果把加噪的时间步变成无穷大，那么这就变成了一个连续的加噪过程，并且从上述加噪过程，我们也可以看出数据 x 随时间 t 的变化（也就是导数）应该满足：\n 与当前的数据 x 有关 要再加上一个高斯噪声  这用公式写下来就是，\n$$ \\frac{dx}{dt} = f(x,t) + g(t) \\epsilon $$\n其中 $\\epsilon$ 在微分方程里可以写成 $dw/dt$，其中w 是一个 standard Wiener process (a.k.a., Brownian motion)。因此我们就得到了扩散模型的 SDE 形式\n$$ dx = f(x,t)dt + g(t) dw $$\n类似的，如果我们把噪声项去掉，我们就可以得到 ODE 形式，可以证明这两种形式的 reverse SDE/ODE 具有相同的边缘分布 $q(x_t|x_0)$，回忆 DDIM 中我们提到 DDPM 的训练只有边缘分布有关，只要保证边缘分布一直，则采样过程可以复用用一个预训练模型。\n$$ dx = f(x,t)dt $$\nPNDM #  好了，逐渐超纲.. 说这么多，其实只是想灌输一个概念，就是扩散模型的采样过程可以用 ODE 的数值方法求解，那么最简单的 ODE 数值方法是什么呢？\n 现在有请欧拉同志 (此处应有掌声 👏)\n 欧拉法特别简单，其实就是一个梯度下降法，利用当前步的 x 和微分方程估计当前步的梯度，然后做一步梯度下降\n$$ x_{t+1} = x_{t} + h \\frac{dx}{dt}_{t=t} $$\n其中 $h$ 是步长。提问为什么一定能估计出梯度呢？其实上面也提到了扩散模型的 ODE 方程，方程是线性的，并且还是一阶的，我们自然可以解出导数。\n事实上，不管是复杂的进阶算法，例如Runge-Kutta, linear multi-step，还是欧拉法，他们都共享了一个统一的更新过程，即\n$$ x_{t+1} = x_{t} + h f(x_{t}, t) $$\n不同算法的主要区别就在于这个“梯度”的估计方法$f(x_{t}, t)$，PNDM 的作者把更新过程称作《transfer part》，梯度计算过程则成为《gradient part》。\n在理解这个之后，PNDM 就非常简单了，首先 DDIM 可以视作求解一个 ODE 的离散形式（参见原论文的章节 3.1），它的 transfer part 可以写成（原论文的公式 11）\n $$ x_{t-\\delta}=\\frac{\\sqrt{\\bar{\\alpha}_{t-\\delta}}}{\\sqrt{\\bar{\\alpha}_t}} x_t-\\frac{\\left(\\bar{\\alpha}_{t-\\delta}-\\bar{\\alpha}_t\\right)}{\\sqrt{\\bar{\\alpha}_t}\\left(\\sqrt{\\left(1-\\bar{\\alpha}_{t-\\delta}\\right) \\bar{\\alpha}_t}+\\sqrt{\\left(1-\\bar{\\alpha}_t\\right) \\bar{\\alpha}_{t-\\delta}}\\right)} \\epsilon_t $$  其中 $\\epsilon_t$ 就是 gradient part。\nPNDM 的改进就是把这个 gradient part 替换成了进阶算法使用的 gradient part。如 Runge-Kutta, linear multi-step。\n算法总结 #  如下所示（原论文 3.4章）\n 公式 12是 linear multi-step method 的 gradient part，其中 $e_t'$ 对应 $\\epsilon_t$ ，$\\phi$ 对应上面的 transfer part。 算法 1 是 DDIM 的算法，算法 2 是 PNDM 的算法。 因为公式 12的 gradient part 需要连续 4 个 step 的 $e_t$，因此一开始不能用这个 gradient part，所以作者在前三步用了 Runge-Kutta 的 gradient step（不过使用 Runge-Kutta不是必须的，任何不需要连续 4 个 step的 gradient step 都可以）。   性能 #   PNDM 的结果是 S-PNDM 和 F-PNDM 那几行。FID 越低越好，应该不需要解释了吧，牛逼就完事了。\n3.1 章的推导 #   公式 8 到公式 9 利用了 $(a-b)(a+b) = a^2 - b^2$。 公式 9 到那个极限，只需要把 $\\delta = 0$ 代进去就有了。  后记 #  关于 transfer part\n标准的 transfer part 应该是利用原论文的公式 10 得到的$dx/dt$，使用欧拉法的话，是通过$x_{t-\\delta} = x_t + h dx/dt$ 进行求解，但如果我们把步长$h$ 设置为1，推导出来这个公式正好就是公式 9，或者说公式 11。\n换言之，DDIM 其实就是扩散模型 ODE 形式的步长为 1 的欧法求解方法。\n 不确定是否严谨，因为这个 ODE 在这篇论文里本身是由 DDIM 导出来的，可能还有其他 ODE 的形式。\n 关于 gradient part\n严格来说，gradient part 部分应该是梯度，但是 $\\epsilon_\\theta$ 给出的并不是完全是梯度，那为什么它可以视作 gradient part 呢？ 关于这一点，作者在 Property 3.1 下面给的解释是\n That if $\\epsilon_\\theta$ is precise, the result of $x_{t-\\delta}$ also precise, which means that $\\epsilon_\\theta$ can determine the direction of the denoising process to generate the ﬁnal results. Therefore, such a choice also satisﬁes the deﬁnition of a gradient part. Now, we have our gradient part $\\epsilon_\\theta$ and transfer part $\\phi$.\n 因为 $\\epsilon_\\theta$ 和 $dx/dt$ 是线性相关的，如下：\n$$ \\frac{d x}{d t}=-\\bar{\\alpha}^{\\prime}(t)\\left(\\frac{x(t)}{2 \\bar{\\alpha}(t)}-\\frac{\\epsilon_\\theta(x(t), t)}{2 \\bar{\\alpha}(t) \\sqrt{1-\\bar{\\alpha}(t)}}\\right) $$\n所以对于 linear multi-step 的 gradient part 来说，对 $dx/dt$ 的任何操作的，等价于对 $\\epsilon_\\theta$ 操作。\n对于 Runge-Kutta 法的来说，我们本质上是利用一个离 $x_{t+\\delta}$ 更近的 $x$ 去估计梯度，那么我们可以把下面的写法改一下，改成 $x_1 = .., x_2 = .., x3=..$，每一步都利用之前的 x 就是，这样就绕过了每一步 $f$ 是算梯度的问题，因为本质上 $f$ 是为了求 x 服务的，如果我们可以直接求 x，那就不用管 f 怎么来的了。\n"},{"id":10,"href":"/blog/posts/ai/ddim/","title":"关于 DDIM 采样算法的推导","section":"Posts","content":"作者: 赖泽强 写在前面 #  DDIM 全称 【Denoising Diffusion Implict Model】，是一篇发表于 ICLR 2021 的论文，不过实际时间也就比 DDPM 晚几个月（2020 年 10 月）就挂在 arXiv 上了。作者呢，则是 Yang Song 博士（也就是 Score-based Diffusion Model 的奠基人）的同门，Jiaming Song 博士， Chenlin Meng 博士（她在Guided Diffusion 蒸馏领域的早期工作获得了 CVPR2023 的 Award Candidate），以及 Stefano Ermon 教授。\n老实说，这是一篇比较难懂的论文，一方面是里面涉及大量的推导以及概率论等相关背景知识，另一方面也是推导过程不太直观，以及刚接触的人难以获取到的 intutition，其他也包括一些 notation 的差异和 typo。\n以下是个人对 DDIM 的一些理解（数学不好，记性也不行，也当是方便以后查阅的笔记），如果有理解上的错误，还请大佬们批评指正。\n撰写过程不仅参考了原论文，还包括了\n  苏剑林老师的 《生成扩散模型漫谈（四）：DDIM = 高观点DDPM》\n  张振虎的博客 《去噪扩散隐式模型（Denoising Diffusion Implicit Models,DDIM）》\n  在此向互联网上热心分享的同僚表示敬意。\n DDIM 出发点 #  DDIM 虽然是一个比较难的算法，但这并不意味着每一个从事扩散模型研究的人员都需要知道其具体的原理。对于大部分人来说，其实只需要知道\n DDIM 是 DDPM 的一种加速采样算法，它可以进行确定性采样（也即给定一个初始的随机噪声，通过DDIM 进行采样，不管采样多少次，最终的结果是一样的，而原始的 DDPM 采样是随机采样，即便初始噪声一致，最终结果也可能不一致），除此之外，DDIM 采样可以在 50 步左右达到 DDPM 1000 步的性能/图片质量。\n 不过如果想要基于 DDIM 做一些进一步的研究，我们则必须更进一步：\n因为不是作者本人，所以我们也无从得知，DDIM 一开始怎么被想出来的。但是从论文以及个人理解来看，DDIM 的推导基石应该是发现了 DDPM 的训练目标实际上只跟 $q(x_t|x_0)$ 这个边缘分布有关，这意味着我们有一簇不同的生成模型可以与之对应，换言之，通过这个训练目标训练出来的模型可以用于不同生成模型的采样过程，如果我们能找到一个收敛更快的生成模型，那么我们实际上变相的加速了 DDPM 的采样（为什么说是变相呢，因为严格来说，这时候的生成模型应该不算是 DDPM 了）。\n那么为什么说 DDPM 的训练目标实际上只跟 $q(x_t|x_0)$ 这个边缘分布有关 呢 ？ 如果我们从 Latent variable model 的角度考虑 Diffusion Model，我们的隐变量是一个集合 $x_{1:T}$，我们在优化的时候，实际上是在优化下面的 变分下界（ELBO）：\n $$ \\begin{aligned} log P(x) \u0026 = log\\int P(x_0|x_{1:T})P(x_{1:T})dx_{1:T} \\\\ \u0026 \\geq E_{x\\sim Q}[log\\frac{ P(x_0|x_{1:T})P(x_{1:T})}{Q(x_{1:T}|x_0)}] \\\\ \u0026 = E_{x\\sim Q}[log\\frac{ P(x_{0:T})}{Q(x_{1:T}|x_0)}] \\end{aligned} $$  乍一看，这个优化目标和联合分布 $P(x_{0:T})$ 和 $Q(x_{1:T}|x_0)$ 有关。\n但是如果我们把这个优化目标展开，参考 DDPM 原始论文，我们可以得到这么一个优化目标\n $$ \\mathbb{E}_q[\\underbrace{D_{\\mathrm{KL}}\\left(q\\left(\\mathbf{x}_T \\mid \\mathbf{x}_0\\right) \\| p\\left(\\mathbf{x}_T\\right)\\right)}_{L_T}+\\sum_{t1} \\underbrace{D_{\\mathrm{KL}}\\left(q\\left(\\mathbf{x}_{t-1} \\mid \\mathbf{x}_t, \\mathbf{x}_0\\right) \\| p_\\theta\\left(\\mathbf{x}_{t-1} \\mid \\mathbf{x}_t\\right)\\right)}_{L_{t-1}} \\underbrace{-\\log p_\\theta\\left(\\mathbf{x}_0 \\mid \\mathbf{x}_1\\right)}_{L_0}] $$  其中 $L_0$ 和 $L_T$ 都是不训练的，所以实际 loss 里没有他们，对于 $L_{t-1}$，DDPM 的 formulation 是\n $$ \\mathbb{E}_{\\mathbf{x}_0, \\boldsymbol{\\epsilon}}\\left[\\frac{\\beta_t^2}{2 \\sigma_t^2 \\alpha_t\\left(1-\\bar{\\alpha}_t\\right)}\\left\\|\\boldsymbol{\\epsilon}-\\boldsymbol{\\epsilon}_\\theta\\left(\\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_0+\\sqrt{1-\\bar{\\alpha}_t} \\boldsymbol{\\epsilon}, t\\right)\\right\\|^2\\right] $$  而 $\\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_0+\\sqrt{1-\\bar{\\alpha}_t} \\boldsymbol{\\epsilon}$ 对应的是 $q(x_t|x_0)$ 的采样过程。\n所以，实际上 DDPM 的优化目标实际上只与 $q(x_t|x_0)$ 有关，因此，通过这个优化目标训练出来的模型，可以用到任何具有相同 $q(x_t|x_0)$ 的生成模型。\n  DDIM 推导 #  在理解出发点之后，我们的目标就很明确了，怎么找一个具有相同 $q(x_t|x_0)$ 的生成模型（论文里称之为 generative process）。这部分就是 DDIM 原论文第三章《Variational Inference for Non-Markovian Forward Processes》的内容。\n这一章作者提到他们使用了一个 non-Markovian 的 inference process 去替代 DDPM 的 Markovian inference process，至于二者的区别可以在后面再细究。\n马尔科夫过程\n每个状态转移到下一个状态的概率只与当前状态有关。\n 原论文里 3.1 节是比较魔幻，容易让人莫名其妙的，因为作者这里直接给出来他们推导出来的结果，然后在附录里附上了证明过程，证明该 generative process 和 DDPM 具有相同的 $q(x_t|x_0)$，但这个结果肯定不是拍脑袋出来的，在苏剑林老师的博客里，他通过待定系数法，从约束出发呈现了该结果的推导过程，虽然这不一定是原作者的真实推导过程，但一定程度上也可以供参考：\n首先我们回顾一下 DDPM 的推导过程\n $$ p(\\boldsymbol{x}_t|\\boldsymbol{x}_{t-1})\\xrightarrow{\\text{推导}}p(\\boldsymbol{x}_t|\\boldsymbol{x}_0)\\xrightarrow{\\text{推导}}q(\\boldsymbol{x}_{t-1}|\\boldsymbol{x}_t, \\boldsymbol{x}_0)\\xrightarrow{\\text{近似}}p(\\boldsymbol{x}_{t-1}|\\boldsymbol{x}_t) $$  其中采样过程理论上需要用到 $p(x_{t-1}|x_t)$, 但实际上采用 $q(x_{t-1}|x_t, x_0)$ 做近似，因此我们需要做的就是推导一个不一样的 $q(x_{t-1}|x_t, x_0)$，在原论文里，作者直接写出了这个公式（原论文的公式 7）：\n $$ q_\\sigma\\left(\\boldsymbol{x}_{t-1} \\mid \\boldsymbol{x}_t, \\boldsymbol{x}_0\\right)=\\mathcal{N}\\left(\\sqrt{\\alpha_{t-1}} \\boldsymbol{x}_0+\\sqrt{1-\\alpha_{t-1}-\\sigma_t^2} \\cdot \\frac{\\boldsymbol{x}_t-\\sqrt{\\alpha_t} \\boldsymbol{x}_0}{\\sqrt{1-\\alpha_t}}, \\sigma_t^2 \\boldsymbol{I}\\right) . $$  那么怎么推导呢？在 DDPM 的论文里，我们有\n $$ \\begin{aligned} q\\left(\\mathbf{x}_{t-1} \\mid \\mathbf{x}_t, \\mathbf{x}_0\\right) \u0026 =\\mathcal{N}\\left(\\mathbf{x}_{t-1} ; \\tilde{\\boldsymbol{\\mu}}_t\\left(\\mathbf{x}_t, \\mathbf{x}_0\\right), \\tilde{\\beta}_t \\mathbf{I}\\right) \\\\ \\text { where } \\quad \\tilde{\\boldsymbol{\\mu}}_t\\left(\\mathbf{x}_t, \\mathbf{x}_0\\right) \u0026 :=\\frac{\\sqrt{\\bar{\\alpha}_{t-1}} \\beta_t}{1-\\bar{\\alpha}_t} \\mathbf{x}_0+\\frac{\\sqrt{\\alpha_t}\\left(1-\\bar{\\alpha}_{t-1}\\right)}{1-\\bar{\\alpha}_t} \\mathbf{x}_t \\quad \\text { and } \\quad \\tilde{\\beta}_t:=\\frac{1-\\bar{\\alpha}_{t-1}}{1-\\bar{\\alpha}_t} \\beta_t \\end{aligned} $$  可以看到 $q(x_{t-1}|x_t, x_0)$ 这里是一个正态分布，基于此，我们可以假设一个更general的形式，我们假设：\n $$ q(\\boldsymbol{x}_{t-1}|\\boldsymbol{x}_t, \\boldsymbol{x}_0) = \\mathcal{N}(\\boldsymbol{x}_{t-1}; \\kappa_t \\boldsymbol{x}_t + \\lambda_t \\boldsymbol{x}_0, \\sigma_t^2 \\boldsymbol{I}) $$  回忆\n 以下推导基于苏剑林的博客和原论文附录 B\n 我们的约束是和 DDPM 具有相同的 $q(x_t|x_0)$，那么根据归纳法，这等价于约束和 DDPM 具有相同的 $q(x_{t-1}|x_0)$。\n为什么要做这个转换呢？ 因为如果我们想要约束 $q(x_t|x_0)$，那么直觉上第一步是建立 $q(x_t|x_0)$ 和 $q(x_{t-1}|x_t, x_0)$ 的联系，这可以通过贝叶斯公式实现：\n $$ q(\\boldsymbol{x}_{t-1}|\\boldsymbol{x}_t, \\boldsymbol{x}_0) \\sim p(\\boldsymbol{x}_{t-1}|\\boldsymbol{x}_t, \\boldsymbol{x}_0) = \\frac{p(\\boldsymbol{x}_t|\\boldsymbol{x}_{t-1})p(\\boldsymbol{x}_{t-1}|\\boldsymbol{x}_0)}{p(\\boldsymbol{x}_t|\\boldsymbol{x}_0)} $$   因为 q 分布是对 p 分布的等价近似，下面使用 p 分布进行推导。\n 首先进行一个等价变换\n $$ p(\\boldsymbol{x}_{t-1}|\\boldsymbol{x}_t, \\boldsymbol{x}_0) p(\\boldsymbol{x}_t|\\boldsymbol{x}_0) = p(\\boldsymbol{x}_t|\\boldsymbol{x}_{t-1}) p(\\boldsymbol{x}_{t-1}|\\boldsymbol{x}_0) $$  左右两边同时积分消掉 $p(x_t|x_{t-1})$ 得到\n $$ \\int p(\\boldsymbol{x}_{t-1}|\\boldsymbol{x}_t, \\boldsymbol{x}_0) p(\\boldsymbol{x}_t|\\boldsymbol{x}_0) d\\boldsymbol{x}_t = p(\\boldsymbol{x}_{t-1}|\\boldsymbol{x}_0)\\label{eq:margin} $$  关于这个转换，概率论小白一开始表示非常难以理解，不过仔细想想，右边之所以能消掉是因为 $p(x_{t-1}|x_0)$ 跟 $x_t$ 无关，所以对右边积分，等价于 $p(x_{t-1}|x_0) \\int p(x_t|x_{t-1}) dx_t = p(x_{t-1}|x_0) \\times 1$。\n 另外，其实这玩意也怪怪的 $\\int p(x_t|x_{t-1}) dx_t = 1$，因为我们一般见到的是边缘概率的形式 $\\int p(x_t) dx_t = 1$，而非前面那种条件概率。不过等式左边积分实际上 $x_t$ 每个取值的和，但$x_t$ 本身是关于 $x_{t-1}$ 的函数，不过因为是概率密度函数，所以和自然也还是 1 。\n 回到刚刚的积分，等式左边都包含有 $x_t$，自然是没法像右边一样消掉。\n可以看到，我们至此得到了 $p(x_{t-1}|x_0)$ 的表达式，我们只要把前面假设的更 general 的 $q(x_{t-1}|x_t, x_0)$（如下） 的代入等式，用待定系数法求解即可得到 $q(x_{t-1}|x_t, x_0)$ 的表达式。\n $$ q(\\boldsymbol{x}_{t-1}|\\boldsymbol{x}_t, \\boldsymbol{x}_0) = \\mathcal{N}(\\boldsymbol{x}_{t-1}; \\kappa_t \\boldsymbol{x}_t + \\lambda_t \\boldsymbol{x}_0, \\sigma_t^2 \\boldsymbol{I}) $$    待定系数法求解\n那么问题来了，我们知道 $p(x_{t-1}|x_0) = N(\\sqrt{\\alpha_{t-1}}x_0, (1-\\alpha_{t-1}) I)$，但等式里的积分怎么办？\n注意\n这里的 $\\alpha_{t-1}$ 等价于 DDPM 里的 $\\bar{\\alpha_{t-1}}$，作者在附录里有专门讲为什么他要用这套 notation。\n DDIM 里的原论文是先给出了 $p(x_{t-1}|x_t, x_0)$，然后基于条件 $p(x_{t}|x_0) = N(\\sqrt{\\alpha_{t}}, (1-\\alpha_{t}) I)$，通过 Bishop (2006) (2.115), 证明等式成立。\n Bishop(2006): Christopher M Bishop. Pattern recognition and machine learning. springer, 2006.\n 那 Bishop(2006) 2.115 究竟讲了个什么呢，没有书的看 这里。\n Bishop(2006) 2.115\n  这里直接截图了，其实讲的就是当给定一个高斯的边缘分布 $p(x)$ 和条件高斯分布$p(y|x)$时，另一个边缘分布是 $p(y)$ 是怎么样的。利用这个性质(2.115)，我们可以把它套到之前的等式里。\n $$ \\int p(\\boldsymbol{x}_{t-1}|\\boldsymbol{x}_t, \\boldsymbol{x}_0) p(\\boldsymbol{x}_t|\\boldsymbol{x}_0) d\\boldsymbol{x}_t = p(\\boldsymbol{x}_{t-1}|\\boldsymbol{x}_0) $$  不过直接套，还是有一些心理障碍，因为这个 $x_0$ 摆在上面看着实在憋屈，没法直接对应过来。直觉上，把 $x_0$ 直接去掉等式应该也是成立的，不过我不知道这种做法的出处是什么，如果有佬知道，还请麻烦留个言，不胜感激。\n当我们去掉$x_0$之后，那就简单了（第一个等号利用了全概率公式）\n $$ \\int p(\\boldsymbol{x}_{t-1}|\\boldsymbol{x}_t) p(\\boldsymbol{x}_t) d\\boldsymbol{x}_t = p(\\boldsymbol{x}_{t-1}) = p(\\boldsymbol{x}_{t-1}) $$  还原回来\n $$ \\int p(\\boldsymbol{x}_{t-1}|\\boldsymbol{x}_t, \\boldsymbol{x}_0) p(\\boldsymbol{x}_t| \\boldsymbol{x}_0) d\\boldsymbol{x}_t = p(\\boldsymbol{x}_{t-1}| \\boldsymbol{x}_0) = p(\\boldsymbol{x}_{t-1}|\\boldsymbol{x}_0) $$  结合 Bishop(2006) 2.115，以及\n $$ p(\\boldsymbol{x}_{t-1}|\\boldsymbol{x}_t, \\boldsymbol{x}_0) = \\mathcal{N}(\\boldsymbol{x}_{t-1}; \\kappa_t \\boldsymbol{x}_t + \\lambda_t \\boldsymbol{x}_0, \\sigma_t^2 \\boldsymbol{I}) $$   $$ p(\\boldsymbol{x}_{t}|\\boldsymbol{x}_0) = \\mathcal{N}(\\sqrt{\\alpha_{t}}x_0, (1-\\alpha_{t}) \\boldsymbol{I}) $$  其中 $A = \\kappa_t$, $b=\\lambda_t x_0$, $\\mu=\\sqrt{\\alpha_{t}}x_0$  我们可以推导出等式左边，也即 $p(x_{t-1}|x_0)$ 的均值为:\n $$ A\\mu + b = \\kappa_t \\sqrt{\\alpha_{t}}x_0 + \\lambda_t x_0 $$  方差为:\n $$ \\mathbf{L}^{-1}+\\mathbf{A} \\mathbf{\\Lambda}^{-1} \\mathbf{A}^{\\mathrm{T}} = \\sigma^2_t \\boldsymbol{I} + \\kappa_t (1-\\alpha_{t}) \\boldsymbol{I} \\kappa_t^T $$  讲了半天终于把等式两边都求出来了，这下可以列方程求解了，回顾等式右边是 $p(x_{t-1}|x_0) = N(\\sqrt{\\alpha_{t-1}}x_0, (1-\\alpha_{t-1}) I)$，那么我们有两个方程：\n $$ \\sqrt{\\alpha_{t-1}}x_0 = \\kappa_t \\sqrt{\\alpha_{t}}x_0 + \\lambda_t x_0 $$   $$ (1-\\alpha_{t-1}) \\boldsymbol{I} = \\sigma^2_t \\boldsymbol{I} + \\kappa_t (1-\\alpha_{t}) \\boldsymbol{I} \\kappa_t^T $$  由第二个方程，我们可以解出:\n $$ \\kappa_t = \\sqrt{\\frac{1-\\alpha_{t-1} - \\sigma^2_t}{1-\\alpha_{t}}} $$  结合上述结果和第一个方程，我们可以解出：\n $$ \\lambda_t = \\sqrt{\\alpha_{t-1}} - \\sqrt{\\frac{1-\\alpha_{t-1} - \\sigma^2_t}{1-\\alpha_{t}}} \\sqrt{\\alpha_{t}} $$  代回\n $$ p(\\boldsymbol{x}_{t-1}|\\boldsymbol{x}_t, \\boldsymbol{x}_0) = \\mathcal{N}(\\boldsymbol{x}_{t-1}; \\kappa_t \\boldsymbol{x}_t + \\lambda_t \\boldsymbol{x}_0, \\sigma_t^2 \\boldsymbol{I}) $$  我们就可以得到\n \\begin{aligned} p(\\boldsymbol{x}_{t-1}|\\boldsymbol{x}_t, \\boldsymbol{x}_0) \u0026= \\mathcal{N}(\\boldsymbol{x}_{t-1}; \\kappa_t \\boldsymbol{x}_t + (\\sqrt{\\alpha_{t-1}}- \\kappa_t \\sqrt{\\alpha_{t}}) \\boldsymbol{x}_0, \\sigma_t^2 \\boldsymbol{I}) \\\\ \u0026=\\mathcal{N}(\\boldsymbol{x}_{t-1}; \\sqrt{\\alpha_{t-1}} \\boldsymbol{x}_0 + \\kappa_t (\\boldsymbol{x}_t - \\sqrt{\\alpha_{t}} \\boldsymbol{x}_0), \\sigma_t^2 \\boldsymbol{I}) \\\\ \u0026=\\mathcal{N}(\\boldsymbol{x}_{t-1}; \\sqrt{\\alpha_{t-1}} \\boldsymbol{x}_0 + \\sqrt{\\frac{1-\\alpha_{t-1} - \\sigma^2_t}{1-\\alpha_{t}}} (\\boldsymbol{x}_t - \\sqrt{\\alpha_{t}} \\boldsymbol{x}_0), \\sigma_t^2 \\boldsymbol{I}) \\end{aligned}  🤗 至此我们就得到了 DDIM 论文里的直接给出的公式 7 了。\nDDIM 论文的一些 typo #  附录 B 里的公式 22 和 23 应该是打错了, 方差不应该带根号，原论文多了个根号，应该是下面这个公式\n $$ p(x_{t}|x_0) = N(\\sqrt{\\alpha_{t}}x_0, (1-\\alpha_{t}) I) $$  DDIM 采样 #  基于推导出来的 $p(x_{t-1}|x_t, x_0)$，我们可以很容易写出下面的采样公式（利用重参数化技巧）：\n $$ x_{t-1} = \\sqrt{\\alpha_{t-1}} \\boldsymbol{x}_0 + \\sqrt{\\frac{1-\\alpha_{t-1} - \\sigma^2_t}{1-\\alpha_{t}}} (\\boldsymbol{x}_t - \\sqrt{\\alpha_{t}} \\boldsymbol{x}_0) + \\sigma_t^2 \\epsilon_t $$  然后，我们需要用网络预测的 $x_0$ 替代上面的 $x_0$。对于 epsilon 参数化的网络 $ \\epsilon_{\\theta}^{(t)}$，即网络预测的是\n $$ x_t = \\sqrt{\\alpha_{t}}x_0 + \\sqrt{(1-\\alpha_{t})} \\epsilon_{\\theta}^{(t)}(x_t) $$  我们有\n $$ x_0 = \\frac{x_t - \\sqrt{(1-\\alpha_{t})} \\epsilon_{\\theta}^{(t)}(x_t)}{\\sqrt{\\alpha_{t}}} $$  把这个式子往回代，我们就得到了最终的采样公式（对应原论文的公式 12）\n $$ \\boldsymbol{x}_{t-1}=\\sqrt{\\alpha_{t-1}} \\underbrace{\\left(\\frac{\\boldsymbol{x}_{t}-\\sqrt{1-\\alpha_{t}} \\epsilon_{\\theta}^{(t)}\\left(\\boldsymbol{x}_{t}\\right)}{\\sqrt{\\alpha_{t}}}\\right)}_{\\text {\"predicted } \\boldsymbol{x}_{0} \"}+\\underbrace{\\sqrt{1-\\alpha_{t-1}-\\sigma_{t}^{2}} \\cdot \\epsilon_{\\theta}^{(t)}\\left(\\boldsymbol{x}_{t}\\right)}_{\\text {\"direction pointing to } \\boldsymbol{x}_{t} \\text { \" }}+\\underbrace{\\sigma_{t} \\epsilon_{t}}_{\\text {random noise }} $$  快速采样 #  事实上，DDIM 本身并不能带来加速效果，DDIM 快速采样的原理本质上就是 Stride Sampling，即间隔采样。而间隔采样的基石则是\n DDPM的训练结果实质上包含了它的任意子序列参数的训练结果。\n 具体地，DDPM 的训练过程可以用一个 $\\alpha_t$ 的序列定义，每个 step 都是随机采样一个 $\\alpha_t$ 对样本进行加噪，然后训练一个去噪模型预测噪声。在训练阶段，t 最大取值为 T，一般为 1000。 朴素的采样方式是 1000,999,998,997 一步一步采样。\n间隔采样则是取1000,980,960,940 一步一步采样（采样总步数为 50）。\n讨论 #  事实上，通过 DDIM 的推导，我们得到了一个更加 general 的采样过程 $q(x_{t-1}|x_t, x_0)$，这个采样过程包含一个可以调节的参数 $\\sigma_t$，通过选取的不同的值，我们可以得到一簇不同的采样过程。\n例如，如果选取 $\\sigma_t = 0$，那么我们就得了一个确定性的采样过程。\n除此之外，我们还可以选取一个特殊的 $\\sigma_t$ 得到 DDPM 的 $q(x_{t-1}|x_t, x_0)$，也就是说 DDPM 是 DDIM 的一个特例。事实上，这个也很好理解，因为我们在推导的时候是根据 DDPM 的形式，撰写了一个更 general 的表达式，那么推导出来必然有这个结果。\n那么怎么选取$\\sigma_t$才能获得最佳的加速效果呢？\n为此，作者做了一些实验，作者选取的$\\sigma_t$为，通过控制$\\eta$可以控制其大小。\n $$ \\sigma_{\\tau_i}(\\eta)=\\eta \\sqrt{\\left(1-\\alpha_{\\tau_{i-1}}\\right) /\\left(1-\\alpha_{\\tau_i}\\right)} \\sqrt{1-\\alpha_{\\tau_i} / \\alpha_{\\tau_{i-1}}} $$  事实上，当$\\eta=1$ 的时候我们就变成 DDPM 了，这也对应上我们刚刚提到的特殊的 $\\sigma_t$。\n 可以看到当 $\\eta = 0$ 的时候，快速采样效果是最好的。\n一个有趣的性质\n对于加噪过程，我们有\n $$ x_t = \\sqrt{\\alpha_{t}}x_0 + \\sqrt{(1-\\alpha_{t})} \\epsilon_{\\theta}^{(t)}(x_t) $$   $$ x_{t-1} = \\sqrt{\\alpha_{t-1}}x_0 + \\sqrt{(1-\\alpha_{t-1})} \\epsilon_{\\theta}^{(t-1)}(x_{t-1}) $$  而当 $\\sigma_t = 0$ 时，我们有\n $$ x_{t-1} = \\sqrt{\\alpha_{t-1}}x_0 + \\sqrt{(1-\\alpha_{t-1})} \\epsilon_{\\theta}^{(t)}(x_t) $$  所以可以看出 DDIM $\\eta = 0$ 实际上用 $\\epsilon_{\\theta}^{(t)}(x_t)$ 去近似 $\\epsilon_{\\theta}^{(t-1)}(x_{t-1})$ 。不过因为 $x_0$ 也是预测出来的，所以这里面还会有一个误差。\n进一步思考，DDIM 的性能应该取决于相邻两个时间步预测结果的一致性，这也意味着，如果我们用相邻步数的结果去 finetune 一下 SD，即用噪声小的，也就是 t 更小的步数去监督 t+1 步，这样应该可以让性能更好。很好，然后我们就得到了 Consistency Model？\nConsistency: If we start with the same initial latent variable and generate several samples with Markov chains of various lengths, these samples would have similar high-level features. Consistency 意味着迭代不同总步数，结果类似。 -- "},{"id":11,"href":"/blog/posts/ai/drag_gan/","title":"DragGAN 抢先体验与本地部署教程","section":"Posts","content":"最近风靡全网的DragGAN, 官方代码尚未放出。不过现在已经可以抢先体验啦。\n项目地址\n  Zeqiang-Lai/DragGAN: 相关代码模型，支持本地部署，Colab在线体验。  OpenGVLab/InternGPT: 可以免费在线体验  在线体验 #   InternGPT  Google Colab  CodewithGPU   ⚠️ 注意 Google Colab 记得通过代码执行程序/更改运行时类型 选择一块GPU。\n Your browser doesn't support embedded videos, but don't worry, you can download it and watch it with your favorite video player!  Your browser doesn't support embedded videos, but don't worry, you can download it and watch it with your favorite video player!  本地部署 - Pip Install 方式 #  接来下的图片展示以Windows下的部署为例，Linux下的部署也是相同的\n目前， Zeqiang-Lai/DragGAN 的实现已经上传到 PyPI 源上了，因此，我们无需下载代码，只需要使用 pip install 即可进行安装。\n安装 Conda #  为了避免依赖冲突，我们首先使用Conda创建一个虚拟环境，如果你还没有安装Conda，可以在 这里下载一个Miniconda。\n 下载完成后，点击安装包一直下一步就可以了。\n 创建 Conda 虚拟环境 #  接下来从 Windows 菜单栏选择 Anaconda Powershell Prompt (miniconda3) 进入Conda 的命令行。\n 进入之后，输入以下指令创建一个名为 draggan 的环境，python 版本为3.7。提示是否继续的时候输入 y 即可继续。\nconda create -n draggan python=3.7  因为我这把已经有一个环境叫draggan了，所以图片里用的是draggan2\n  安装 PyTorch #  我们首先激活一下刚刚创建的环境，输入以下指令即可\nconda activate draggan  接着，参考PyTorch的 官方安装教程，\n 我们可以使用以下指令安装PyTorch，二选一即可，具体选哪个按下载速度自行选择，\npip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117 conda install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia 没有GPU的用户用这个指令安装\npip3 install torch torchvision torchaudio  当出现 Successfully installed 就说明安装成功啦，其他 WARNING 都不用管。\n安装 DragGAN #  安装完成之后，我们安装DragGAN，这可以通过以下指令进行\npip install draggan 因为一些我也不知道的原因，清华pip源没有同步draggan 这个包，如果你的 pip 配置过清华或国内的pip源，你可能会遇到包找不到的问题\n 这时候你可以使用这个指令，临时使用官方源进行安装\npip install draggan -i https://pypi.org/simple/  与PyTorch安装类似，当出现 Successfully installed 就说明安装成功了，其他 WARNING 都不用管。\n 至此，所有依赖安装完成，接下来可以开始运行了。\n运行 DragGAN Demo #  你可以通过以下指令运行 DragGAN 的 Demo\npython -m draggan.web 如果你不小心关掉了命令行，也不用重新安装，通过 Anaconda Powershell Prompt (miniconda3) 重新进入Conda 的命令行，激活环境，运行即可。\nconda activate draggan python -m draggan.web 没有GPU的用户，使用\npython -m draggan.web --device cpu 当出现这个网址的时候 http://127.0.0.1:7860 ，说明程序已经成功运行\n 将这个网址输入到浏览器里就可以访问到 DragGAN 的 Demo 了\n 功能介绍 #  界面功能介绍如下\n  选择模型：目前我们提供了10个模型（在web界面选择后会自动下载），不同模型输出图片分辨率，和对显存要求不一样，具体如下  模型信息汇总    名称 分辨率 显存占用 (MB)     stylegan2-ffhq-config-f.pt 1024 7987   stylegan2-cat-config-f.pt 256 4085   stylegan2-church-config-f.pt 256 4085   stylegan2-horse-config-f.pt 256 4085   ada/ffhq.pt 1024 7987   ada/afhqcat.pt 512 4473   ada/afhqdog.pt 512 4473   ada/afhqwild.pt 512 4473   ada/brecahad.pt 512 4473   ada/metfaces.pt 512 4473         最大迭代步数：有些比较困难的拖拽，需要增大迭代次数，当然简单的也可以减少。\n  设置拖拽点对，模型会将蓝色的点拖拽到红色点位置。记住需要在 Setup handle points 设置拖拽点对。\n  设置可变化区域（可选）：这部分是可选的，你只需要设置拖拽点对就可以正常允许。如果你想的话， 你可以在 Draw a mask 这个面板画出你允许模型改变的区域。注意这是一个软约束，即使你加了这个mask，模型还是有可能会改变超出许可范围的区域。\n  视频教程 #  敬请期待\n"},{"id":12,"href":"/blog/posts/ai/detr/","title":"Detr Family for End-to-End Detection","section":"Posts","content":"Detr（Detection Transformer）是 facebook 在 2020 年提出的第一个端到端的目标检测模型， 它改变了现有基于 Fast-RCNN 和 YOLO 的目标检测范式，后续有许多工作，基于 Detr 提出了各种个样的改进。\nTimeline #   Detr (ECCV 2020): End-to-End Object Detection with Transformers Deformable Detr (ICLR 2021): Deformable DETR: Deformable Transformers for End-to-End Object Detection Conditional Detr (ICCV 2021): Conditional DETR for Fast Training Convergence Anchor Detr (AAAI 2021): Anchor DETR: Query Design for Transformer-Based Object Detection DAB Detr (ICLR 2022): DAB-DETR: Dynamic Anchor Boxes are Better Queries for DETR DN Detr (CVPR 2022): DN-DETR: Accelerate DETR Training by Introducing Query DeNoising  1. Detr #  Detr (Citation: Carion,\u0026#32;Massa \u0026amp; al.,\u0026#32;2020Carion,\u0026#32; N.,\u0026#32; Massa,\u0026#32; F.,\u0026#32; Synnaeve,\u0026#32; G.,\u0026#32; Usunier,\u0026#32; N.,\u0026#32; Kirillov,\u0026#32; A.\u0026#32;\u0026amp;\u0026#32;Zagoruyko,\u0026#32; S. \u0026#32; (2020). \u0026#32;End-to-End Object Detection with Transformers.\u0026#32;Retrieved from\u0026#32; http://arxiv.org/abs/2005.12872 ) 是第一个端到端的目标检测模型，它直接定义了 N1 个目标框的 slot，这里 Detr 称其为 object query。\n在优化的时候，这 N 个 slot 将会通过 transformer 进行 self attention ，以及和输入图像进行 cross attention。 通过这个方式，每个 slot 将会逐步进化成可以预测目标框及其类别的一个特征向量。最终通过两个FFN，即可回归出目标框的位置和类别。\n Detr总体结构\n  Encoder #  Transformer 的 Encoder 如果去掉的话，会掉点：\n overall AP drops by 3.9 points, with a more signiﬁcant drop of 6.0 AP on large objects.\n 一个解释是，transformer 的 self attention 可以提取全局特征。\n 从可视化的 attention map 来看，一个物体上的某个点的 attention map 都聚集在这个物体的其他部分。 但这其实很 trivial，attention map 本身是两个 token 的相似度，同一个物体不同区域的相似度自然大，对于这个示意图更是，同一个物体，具有明显相似的颜色和纹理特征。 所以，这个 attention map 能这么明显的区分物体，有没有可能只是因为颜色相近呢？如果有两只很像的牛，距离也比较近，那么此时的 attention map 会是什么样呢？  进一步的，既然 encoder 的特征就已经很有区分度了，同一个物体的特征比较像了，那么我们能不能通过聚类的方式，提取出每个物体的特征，然后通过两个 FFN 预测 bbox 和 class 呢？\n Position Embedding #    不难想到，detr 使用 transformer，如果不加 positional encoding 的话，feature 是不带位置信息的，这样应该是很难预测 bbox 的位置的。 论文实验结果也体现了这一点，去掉 encoder 和 decoder 的 positional encoding 直接掉了 7 个点。\n  但是，即便如此，还是能取得 30 多的 AP， 这说明只用 object query 我们也能学到位置信息。我们可以想象 object query 学到了关注某些特定区域， 即某些坐标区域，然后通过 cross attention 来判断，这个 slot 里有没有物体。然而，encoder feature 并没有任何位置信息，cross attention 怎么知道，这个 slot 对应的 feature 在哪呢？ 因此，我们有理由怀疑，这里可能有隐藏的位置信息泄漏，每个 slot 可能会关注固定位置的 encoder feature token。\n   Object Query #  理解 Object Query 是理解 Detr 设计的核心。Object query 其实就是预设的检测框的一系列 slot，对于某个 slot，transformer decode 的过程，其实就相当于，我们用这个 slot 去查询 encoder feature，然后把与这个 slot 相关的 slot 提取出来，存到 decoder embedding 里。\nDetr 的做法和这个 idea 类似，但是它每一步在优化的其实是 transformer 的 query，每次的 output value 仍然是 encoder feature 的加权。所以，我们能不能直接优化 value，每次的 output value 相当于是 value 的一个 residual refinement 呢？\n关于 Object query，论文还做了一些可视化的分析，\n 首先，每个 object query 都会倾向于关注这个 query 负责物体的边界区域。 其次，object query 对于物体类别并没有特别的倾向性。 最后，object query 似乎对于不同位置的物体具有一定倾向性，这也是后续很多文章改进的基石。  为了证明【2】这一点，作者做了一个实验，作者合成了一张有 24 个长颈鹿的图，在数据集里， 没有一张图是有超过 24 只长颈鹿的，如果 object query 对物体类别有倾向性的话，那么就分不出来 24 个长颈鹿，因为训练数据不足以训练出 24 个对长颈鹿有偏好的 query。\n Object query 的 attention, 倾向于关注物体边界\n    Out of distribution Results\n    不同 object query 预测检测框的分布\n  Panoptic Segmentation #  Detr 这个架构可以扩展到 Panoptic Segmentation，思路是\n detr 会输出每个检测物体的 embedding，每个 object query 有一个。 回忆，encoder 那一节我们也提到了，其实 encoder 的结果就已经有一个聚类的效果了。 因此，我们可以通过一个 attention，把每个检测物体的覆盖区域，通过 attention map 大概估计出来。 对于每个检测物体，都有一个 attention map，然后我们结合 Resnet 的特征，过一个 CNN，然后过一个二分类 FFN，得到每个检测物体细化的二分类 segmentation 结果。 最后，每个物体的二分类结果，会通过 argmax 概率得到最终的 panoptic segmentation 的结果。  PS：这么做的话，应该是只能应用到 Panoptic Segmentation，因为每个像素 segmentation 的结果必须属于检测那一步的某个类别才行。\n Illustration of the panoptic head. A binary mask is generated in parallel for each detected object, then the masks are merged using pixel-wise argmax.\n  一些细节 #   Transformer Encoder 的 Q，K 是带 Pos 的，但是 V 不带。 Transformer Decoder 里 V 还是不带 Pos 【1】，Q 和 V 分别带不同的 Pos。 待补充  【1】: 那FFN的时候,位置信息到底从哪来的 🤨？   2. Deformable Detr #  Deformable Detr (Citation: Zhu,\u0026#32;Su \u0026amp; al.,\u0026#32;2021Zhu,\u0026#32; X.,\u0026#32; Su,\u0026#32; W.,\u0026#32; Lu,\u0026#32; L.,\u0026#32; Li,\u0026#32; B.,\u0026#32; Wang,\u0026#32; X.\u0026#32;\u0026amp;\u0026#32;Dai,\u0026#32; J. \u0026#32; (2021). \u0026#32;Deformable DETR: Deformable Transformers for End-to-End Object Detection.\u0026#32;Retrieved from\u0026#32; http://arxiv.org/abs/2010.04159 ) 主要是提出了 Deformable Attention Module 用于改进 Detr 的两个问题：\n 收敛慢：作者 claim 这个点是来自于 Detr 所用的 attention 是个全局 attention，一开始都是平均的权重，但最后一般会收敛到比较 sparse 的权重。 这个学习的过程会比较慢。 计算复杂度大：还是因为是全局 attention，时间复杂度随图像大小平方增长。  Deformable Attention #  Deformable Attention 解决上述两个问题的方式，就是通过 Deformable 得到一个局部的 token list，然后只在这个 token list 内做 attention。\n下面是 Deformable Attention 的示意图，一些要点\n Deformable Attention 需要一个 reference point，然后局部 token list 是通过计算以 reference point 为中心的 offset 得到的。 对于 encoder 来说，Q，K，V 都是 2D 图片，所以 reference point 就是 Q 里每个 token 的自身坐标（归一化到 0～1）。 对于 decodedr 的 cross attention，Q 是 object query，没有坐标，这里的 reference point 是通过一个 learnable linear projection followed by a sigmoid function 得到的。 最后的 bbox prediction head 预测的是 reference point 的 offset 和 bbox 的长和宽。   Deformable Attention 示意图\n  Multi-scale #  作者实际在用的时候，是使用的 Multi-scale Deformable Attention 。\n 这个多层级的版本，主要区别就是 deformable 的局部 token list 扩展到多个层级的 feature map 上。 为了区分不同 scale 的 query，作者还加入了一个可学习的 scale embedding 到 query 里面。  Additional Improvement #  Iterative Bounding Box Refinement #  每一层 Decoder layer 预测的 output embedding 都过一个 detection head 得到一个 bbox 预测结果。\n 然后将这个预测结果的中心点，作为下一层的 decoder layer 的 reference point 下一层预测的 deformable offset 也用预测结果的 w，h 调制一下。  Two-Stage Deformable DETR #  用 Transformer Encoder 输出的 feature map，对每个像素的特征都过一个 prediction head 得到一个粗的 bbox，类别只有前景和背景。用这些 proposed region 的中心点，作为下一步 object query 的 reference point。\n3. Conditional Detr #   官方知乎专栏解读\nConditional Detr (Citation: Meng,\u0026#32;Chen \u0026amp; al.,\u0026#32;2021Meng,\u0026#32; D.,\u0026#32; Chen,\u0026#32; X.,\u0026#32; Fan,\u0026#32; Z.,\u0026#32; Zeng,\u0026#32; G.,\u0026#32; Li,\u0026#32; H.,\u0026#32; Yuan,\u0026#32; Y.,\u0026#32; Sun,\u0026#32; L.\u0026#32;\u0026amp;\u0026#32;Wang,\u0026#32; J. \u0026#32; (2021). \u0026#32;Conditional DETR for Fast Training Convergence. https://doi.org/10.48550/arXiv.2108.06152 ) 的核心思想真的非常简单，就是把原始 Detr 中 cross attention 的 Q 和 K 换了一下。\nSeperate Embedding #  具体来说，Q 和 K 都是由一个 content embedding 和 position (作者这里称为spatial) embedding，通过 add 得到，Conditional Detr 就是把 add 变成了 concate。\n背后的原理，作者是这样解释的，使用 add 的方式，算 attention weight 是这样的：\n $$ \\begin{aligned} \u0026\\left(\\mathbf{c}_{q}+\\mathbf{p}_{q}\\right)^{\\top}\\left(\\mathbf{c}_{k}+\\mathbf{p}_{k}\\right) \\\\ =\u0026 \\mathbf{c}_{q}^{\\top} \\mathbf{c}_{k}+\\mathbf{c}_{q}^{\\top} \\mathbf{p}_{k}+\\mathbf{p}_{q}^{\\top} \\mathbf{c}_{k}+\\mathbf{p}_{q}^{\\top} \\mathbf{p}_{k} \\end{aligned} $$  可以看到 content embedding 不仅要和 content embedding 做相似度匹配，还要和 spatial embedding 做相似度匹配。 这意味着 content embedding 不仅要包含 content 的信息，还需要包含一定的 spatial 的信息。这会使得训练难度加大。\n如果改成 concate 形式，那么 attention weight 的计算就变成了：\n $$ \\mathbf{c}_{q}^{\\top} \\mathbf{c}_{k}+\\mathbf{p}_{q}^{\\top} \\mathbf{p}_{k} $$  这时候 content embedding 只和 content embedding 做匹配，spatial embedding 只和 spatial embedding 做匹配。 这样就降低了训练难度。\n事实上，单纯改成 concate 并不能提点，作者在知乎专栏回复了，Detr 改成 concate 还掉点了。\nReference Point #  类似 Deformable Detr (Citation: Zhu,\u0026#32;Su \u0026amp; al.,\u0026#32;2021Zhu,\u0026#32; X.,\u0026#32; Su,\u0026#32; W.,\u0026#32; Lu,\u0026#32; L.,\u0026#32; Li,\u0026#32; B.,\u0026#32; Wang,\u0026#32; X.\u0026#32;\u0026amp;\u0026#32;Dai,\u0026#32; J. \u0026#32; (2021). \u0026#32;Deformable DETR: Deformable Transformers for End-to-End Object Detection.\u0026#32;Retrieved from\u0026#32; http://arxiv.org/abs/2010.04159 ) ，作者提出让 decoder 预测一个 reference point 的 offset，以及 bbox 的宽高。\n $$ \\mathbf{b}=\\operatorname{sigmoid}\\left(\\operatorname{FFN}(\\mathbf{f})+\\left[\\mathbf{s}^{\\top} 000\\right]^{\\top}\\right) $$  作者尝试了两种不同的计算 reference point 的方法，ablation 如下。\n   Method AP     不用 reference point, s=(0,0) 36.8   将 s 作为网络参数，进行优化 40.7   根据对应的 object query 预测而来 40.9    Conditional Spatial Query #  作者提出用 Conditional Spatial Query 替代 object query 。\nIntuition 主要是，encoder 的 feature 里面包含了我们要预测的 bbox 的位置和类别信息，我们只需要通过 cross attention 把它有效的提取出来。 这里的 cross attention 其实就是通过 decoder embedding 和 encoder embedding 以及对应的 spatial embedding 直接的相似度进行的。 这里的相似度，可以看作是 object query 这个 slot 和 encoder 的 feature 的相似度。\n在多层的 decoder layer 里，decoder embedding 不断在向目标框的 embedding 对齐，这样 cross attention 就能得到更准的 encoder feature。\n但是原始的 Detr 的 spatial embedding 是单纯的 object query，和 encoder 的 spatial embedding 可能不在一个 space，这样做相似度计算可能不准。 作者似乎没比用原始 Detr 的 object query 做spatial embedding的结果。\n作者提出使用 reference point 的 sin embedding 做 spatial embedding，\n $$ \\mathbf{p}_{s}=\\operatorname{sinusoidal}(\\operatorname{sigmoid}(\\mathbf{s})) $$  然后计算一个 transformation，将其和 decoder embedding 联系起来，做一个 offset，\n $$ \\mathbf{p}_{q}=\\mathbf{T} \\mathbf{p}_{s}=\\boldsymbol{\\lambda}_{q} \\odot \\mathbf{p}_{s} $$  其中 $\\mathbf{T}=\\operatorname{FFN}(\\mathbf{f})$, $\\boldsymbol{\\lambda}_{q}$ 是个对角阵。\n实验结果\n CSQ-P: 直接用 sin 过后的 positional embedding $p_s$ CSQ-T: 直接用 transformation $\\boldsymbol{\\lambda}_{q}$ CSQ-C: 用 decoder content embedding $f$ CSQ-I: 用 f 经过 self attention 之后的 $c_q$ 预测的 transformation 乘上 $p_s$ 的结果。   理论上 Concate 这种做法，对于原始 Detr 也是可以直接用的，reference point 从 object query 得到，但是 positional embedding 直接就用 object query。 这样做效果如何？而且，既然 reference point 是从 object query 得到的，那么 object query 实际上就包含了 reference point 的信息。  4. Anchor Detr #  Anchor Detr (Citation: Wang,\u0026#32;Zhang \u0026amp; al.,\u0026#32;2022Wang,\u0026#32; Y.,\u0026#32; Zhang,\u0026#32; X.,\u0026#32; Yang,\u0026#32; T.\u0026#32;\u0026amp;\u0026#32;Sun,\u0026#32; J. \u0026#32; (2022). \u0026#32;Anchor DETR: Query Design for Transformer-Based Object Detection.\u0026#32;Retrieved from\u0026#32; http://arxiv.org/abs/2109.07107 ) 和 Conditional Detr (Citation: Meng,\u0026#32;Chen \u0026amp; al.,\u0026#32;2021Meng,\u0026#32; D.,\u0026#32; Chen,\u0026#32; X.,\u0026#32; Fan,\u0026#32; Z.,\u0026#32; Zeng,\u0026#32; G.,\u0026#32; Li,\u0026#32; H.,\u0026#32; Yuan,\u0026#32; Y.,\u0026#32; Sun,\u0026#32; L.\u0026#32;\u0026amp;\u0026#32;Wang,\u0026#32; J. \u0026#32; (2021). \u0026#32;Conditional DETR for Fast Training Convergence. https://doi.org/10.48550/arXiv.2108.06152 ) 是同期工作，后者稍微早一点。\nAnchor as Object Query #  其实和 Conditional Detr 很像，都是 reference point 做 anchor 和 object query，然后 decoder 预测 offset。\n Row-Column Decoupled Attention #  不太重要，暂时没写。\n对比 #  对比 Deformable Detr (Citation: Zhu,\u0026#32;Su \u0026amp; al.,\u0026#32;2021Zhu,\u0026#32; X.,\u0026#32; Su,\u0026#32; W.,\u0026#32; Lu,\u0026#32; L.,\u0026#32; Li,\u0026#32; B.,\u0026#32; Wang,\u0026#32; X.\u0026#32;\u0026amp;\u0026#32;Dai,\u0026#32; J. \u0026#32; (2021). \u0026#32;Deformable DETR: Deformable Transformers for End-to-End Object Detection.\u0026#32;Retrieved from\u0026#32; http://arxiv.org/abs/2010.04159 ) \n对比 Conditional Detr (Citation: Meng,\u0026#32;Chen \u0026amp; al.,\u0026#32;2021Meng,\u0026#32; D.,\u0026#32; Chen,\u0026#32; X.,\u0026#32; Fan,\u0026#32; Z.,\u0026#32; Zeng,\u0026#32; G.,\u0026#32; Li,\u0026#32; H.,\u0026#32; Yuan,\u0026#32; Y.,\u0026#32; Sun,\u0026#32; L.\u0026#32;\u0026amp;\u0026#32;Wang,\u0026#32; J. \u0026#32; (2021). \u0026#32;Conditional DETR for Fast Training Convergence. https://doi.org/10.48550/arXiv.2108.06152 ) \n 都用 reference point 转 embedding 作为 object query。  Conditional Detr 的 reference point 是由 object query 通过 FFN 得到的。 Anchor Detr 的 reference point 是可学习的参数（其实是 Conditional Detr 的另一种方案，他们的实验结果是这种为低 0.2）   Anchor 通过 Pattern embedding 可以一个 anchor point 预测多个物体。 转 Position embedding 的方式不一样：conditional detr 用的是 sin，anchor detr 额外加了一个 FFN。  5. DAB Detr #  DAB Detr (Citation: Liu,\u0026#32;Li \u0026amp; al.,\u0026#32;2022Liu,\u0026#32; S.,\u0026#32; Li,\u0026#32; F.,\u0026#32; Zhang,\u0026#32; H.,\u0026#32; Yang,\u0026#32; X.,\u0026#32; Qi,\u0026#32; X.,\u0026#32; Su,\u0026#32; H.,\u0026#32; Zhu,\u0026#32; J.\u0026#32;\u0026amp;\u0026#32;Zhang,\u0026#32; L. \u0026#32; (2022). \u0026#32;DAB-DETR: Dynamic Anchor Boxes are Better Queries for DETR.\u0026#32;Retrieved from\u0026#32; http://arxiv.org/abs/2201.12329 ) , 前面的工作都是用 anchor point 做 object query，DAB Detr 也 follow 这个做法，然后通过一个 modulated attention 引入了 Width 和 Height。最后 output embedding 预测的不止是 x，y 的 offset 还有 h，w 的 offset。\n 6. DN Detr #  Denoising Detr (Citation: Li,\u0026#32;Zhang \u0026amp; al.,\u0026#32;2022Li,\u0026#32; F.,\u0026#32; Zhang,\u0026#32; H.,\u0026#32; Liu,\u0026#32; S.,\u0026#32; Guo,\u0026#32; J.,\u0026#32; Ni,\u0026#32; L.\u0026#32;\u0026amp;\u0026#32;Zhang,\u0026#32; L. \u0026#32; (2022). \u0026#32;DN-DETR: Accelerate DETR Training by Introducing Query DeNoising.\u0026#32;11. ) 引入一个额外的 Denoising task 作为辅助任务，具体的，将 GT object 的 noisy bbox 作为 DAB 的 object query 输入，然后目标是去噪回来。\n参考文献 #    Wang,\u0026#32; Zhang,\u0026#32; Yang\u0026#32;\u0026amp;\u0026#32;Sun (2022)  Wang,\u0026#32; Y.,\u0026#32; Zhang,\u0026#32; X.,\u0026#32; Yang,\u0026#32; T.\u0026#32;\u0026amp;\u0026#32;Sun,\u0026#32; J. \u0026#32; (2022). \u0026#32;Anchor DETR: Query Design for Transformer-Based Object Detection.\u0026#32;Retrieved from\u0026#32; http://arxiv.org/abs/2109.07107    Meng,\u0026#32; Chen,\u0026#32; Fan,\u0026#32; Zeng,\u0026#32; Li,\u0026#32; Yuan,\u0026#32; Sun\u0026#32;\u0026amp;\u0026#32;Wang (2021)  Meng,\u0026#32; D.,\u0026#32; Chen,\u0026#32; X.,\u0026#32; Fan,\u0026#32; Z.,\u0026#32; Zeng,\u0026#32; G.,\u0026#32; Li,\u0026#32; H.,\u0026#32; Yuan,\u0026#32; Y.,\u0026#32; Sun,\u0026#32; L.\u0026#32;\u0026amp;\u0026#32;Wang,\u0026#32; J. \u0026#32; (2021). \u0026#32;Conditional DETR for Fast Training Convergence. https://doi.org/10.48550/arXiv.2108.06152    Liu,\u0026#32; Li,\u0026#32; Zhang,\u0026#32; Yang,\u0026#32; Qi,\u0026#32; Su,\u0026#32; Zhu\u0026#32;\u0026amp;\u0026#32;Zhang (2022)  Liu,\u0026#32; S.,\u0026#32; Li,\u0026#32; F.,\u0026#32; Zhang,\u0026#32; H.,\u0026#32; Yang,\u0026#32; X.,\u0026#32; Qi,\u0026#32; X.,\u0026#32; Su,\u0026#32; H.,\u0026#32; Zhu,\u0026#32; J.\u0026#32;\u0026amp;\u0026#32;Zhang,\u0026#32; L. \u0026#32; (2022). \u0026#32;DAB-DETR: Dynamic Anchor Boxes are Better Queries for DETR.\u0026#32;Retrieved from\u0026#32; http://arxiv.org/abs/2201.12329    Zhu,\u0026#32; Su,\u0026#32; Lu,\u0026#32; Li,\u0026#32; Wang\u0026#32;\u0026amp;\u0026#32;Dai (2021)  Zhu,\u0026#32; X.,\u0026#32; Su,\u0026#32; W.,\u0026#32; Lu,\u0026#32; L.,\u0026#32; Li,\u0026#32; B.,\u0026#32; Wang,\u0026#32; X.\u0026#32;\u0026amp;\u0026#32;Dai,\u0026#32; J. \u0026#32; (2021). \u0026#32;Deformable DETR: Deformable Transformers for End-to-End Object Detection.\u0026#32;Retrieved from\u0026#32; http://arxiv.org/abs/2010.04159    Carion,\u0026#32; Massa,\u0026#32; Synnaeve,\u0026#32; Usunier,\u0026#32; Kirillov\u0026#32;\u0026amp;\u0026#32;Zagoruyko (2020)  Carion,\u0026#32; N.,\u0026#32; Massa,\u0026#32; F.,\u0026#32; Synnaeve,\u0026#32; G.,\u0026#32; Usunier,\u0026#32; N.,\u0026#32; Kirillov,\u0026#32; A.\u0026#32;\u0026amp;\u0026#32;Zagoruyko,\u0026#32; S. \u0026#32; (2020). \u0026#32;End-to-End Object Detection with Transformers.\u0026#32;Retrieved from\u0026#32; http://arxiv.org/abs/2005.12872    Li,\u0026#32; Zhang,\u0026#32; Liu,\u0026#32; Guo,\u0026#32; Ni\u0026#32;\u0026amp;\u0026#32;Zhang (2022)  Li,\u0026#32; F.,\u0026#32; Zhang,\u0026#32; H.,\u0026#32; Liu,\u0026#32; S.,\u0026#32; Guo,\u0026#32; J.,\u0026#32; Ni,\u0026#32; L.\u0026#32;\u0026amp;\u0026#32;Zhang,\u0026#32; L. \u0026#32; (2022). \u0026#32;DN-DETR: Accelerate DETR Training by Introducing Query DeNoising.\u0026#32;11.       略大于一张图里最多能检测到的物体数\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n  "},{"id":13,"href":"/blog/posts/ai/sd_cg/","title":"Steepest Descent \u0026\u0026 Conjugate Gradient","section":"Posts","content":"这是一篇主要介绍Conjugate Gradient (CG)的笔记，当然为了引入CG，也会一并介绍其“前身” Steepest Descent。\n本文主要参考这篇论文： An Introduction to the Conjugate Gradient Method Without the Agonizing Pain\n It is definitely the best paper to understand the steepest descent conjugate gradient method, which save me a lot of time, thanks god. And it is written in 1994, pretty cool, right? 🧐\n 类似的知乎： https://zhuanlan.zhihu.com/p/64227658\n Introduction #  Well, let\u0026rsquo;s begin with a short outline of this paper:\n首先，我们需要了解CG要求解的问题，CG是一个迭代求解大规模线性方程组的方法，即我们要求:\n$$ Ax = b $$\n其中x是我们要求的一个向量，b是一个已知向量，A是一个已知的 square, symmetric, positive-definite 的矩阵。\nThe Quadratic Form #  二次型是一个标量二次函数，即输入是一个向量x，输出一个标量，它的形式如下：\n$$ f(x) = \\frac{1}{2}x^T A x - b^T x + c $$\n对$f(x)$求导，我们有：\n$$ f'(x) = \\frac{1}{2}A^Tx + \\frac{1}{2}Ax -b $$\n当A是对称矩阵时，我们有:\n$$ f'(x) = Ax - b $$\n不难得出，当A是对称矩阵时，原问题$Ax=b$的解就是二次型导数为0的点，也即极值点。因此，我们可以通过求解二次型的极值点找到$Ax=b$的解。\n进一步的，如果A是正定（postive definite）矩阵，二次型的极值点是它的最小值点，因此我们可以通过最小化 $f(x)$ 找到 $Ax=b$ 的解。\n当A矩阵是正定矩阵时，二次型有最小值，如a所示，如果是负定矩阵，则如b所示。 原论文 Figure 5。 Steepest Descent #  回顾，我们现在需要做的是找出二次型的最小值。\n首先，基于迭代的求最小值的方法思路都是从一个随机解 $x_0$开始，不断更新，得到 $x_1, x_2, \u0026hellip;$，直到与真实值足够接近。（用$r=Ax-b$判断）\nSteepest Descent 也是基于迭代的方法，它是梯度下降的一个改进，即从初始点出发，每次都朝负梯度方向更新。\n$$ -f'(x_i) = b - Ax_i $$\n我们定义 residual 和 error $$ r_i = b - Ax_i $$ $$ e_i = x_i -x $$\n则每次更新公式为：\n$$ x_{i+1} = x_i + \\alpha r_i $$\n现在一个问题是，我们知道更新的方向，但我们要走多远呢？即 $\\alpha$ 要如何选取。\nSteepest Descent的思路是，每次更新都取从负梯度方向出发能够的到达的最低点。如下图a,b所示。\n 从数学上，我们的目标就是找到一个 $\\alpha$ 使得 $f(x_{i+1})$ 最小。回忆，因为A是正定的，所以 $f$ 的极值点就是最值点，因此我们可以通过导数 $\\frac{\\partial f(x_{i+1})}{ \\partial \\alpha}$ 为0，求得 $\\alpha$。\n应用复合函数求导： $$ \\frac{\\partial f(x_{i+1})}{ \\partial \\alpha} = \\frac{\\partial f(x_{i+1})}{ \\partial x_{i+1}} \\frac{\\partial x_{i+1}}{ \\partial \\alpha} $$\n其中 $\\frac{\\partial f(x_{i+1})}{ \\partial x_{i+1}} = f'(x_{i+1}) = - r_{i+1}$， $ \\frac{\\partial x_{i+1}}{ \\partial \\alpha} = r_i$\n令导数为0，我们有（为了简化表达式，这里用1表示i+1，0表示i）：\n $$ \\begin{aligned} r_{(1)}^{T} r_{(0)} \u0026=0 \\\\ \\left(b-A x_{(1)}\\right)^{T} r_{(0)} \u0026=0 \\\\ \\left(b-A\\left(x_{(0)}+\\alpha r_{(0)}\\right)\\right)^{T} r_{(0)} \u0026=0 \\\\ \\left(b-A x_{(0)}\\right)^{T} r_{(0)}-\\alpha\\left(A r_{(0)}\\right)^{T} r_{(0)} \u0026=0 \\\\ \\left(b-A x_{(0)}\\right)^{T} r_{(0)} \u0026=\\alpha\\left(A r_{(0)}\\right)^{T} r_{(0)} \\\\ r_{(0)}^{T} r_{(0)} \u0026=\\alpha r_{(0)}^{T}\\left(A r_{(0)}\\right) \\\\ \\alpha \u0026=\\frac{r_{(0)}^{T} r_{(0)}}{r_{(0)}^{T} A r_{(0)}} . \\end{aligned} $$  事实上 Steepest Descent 每次更新的方向都与上一步的方向正交的。\n这是因为每一步更新的时候都是从负梯度方向走到最低点，如果停下来的位置梯度不与更新梯度正交，那么这个位置就不是最低点，因为这个位置在更新梯度上还有一个不为0的分量。\n  "},{"id":14,"href":"/blog/posts/algorithms/%E6%9C%80%E7%9F%AD%E8%B7%AF/","title":"最短路算法","section":"Posts","content":"Dijkstra用于求没有负权边的单源最短路。\nDijkstra #  从源点出发，每次选择与访问过的点距离最近的点，更新距离。这个距离就是从源点到该点的最短距离。\nWhy？\nBellman-Ford #  SPFA # "},{"id":15,"href":"/blog/posts/algorithms/gcd/","title":"快速求最大公约数gcd","section":"Posts","content":"快速求两个数的最大公约数(公因数)有两个办法：\n 更相减损法 辗转相除法  更相减损法 #  原理：两个正整数a和b（a\u0026gt;b），它们的最大公约数等于a-b（大减小）和b（小）的最大公约数。\nint gcd(int a,int b) { if(a==b) return a; if(a\u0026gt;b) return gcd(a-b,b); if(a\u0026lt;b) return gcd(b-a,a); } 辗转相除法 #  原理：两个正整数a和b（a\u0026gt;b），它们的最大公约数等于a%b（大模小）和b（小）之间的最大公约数。\nwhy？\n 假设最大公约数是x, 显然，x也是a%b因数。 现在证明x是a%b和b的最大公因数：假设存在更大的公因数y，因为a=kb+a%b, 则y肯定也是a的公因数。因此x=y，得证。  int gcd(int a,int b) { if(b==0) return a; else return gcd(b,a%b); } // 一行写法 int gcd(int a,int b) { return b ? gcd(b,a%b):a; } 比较 #  更相减损法避免了大整数取模导致效率低下的问题，但是运算次数要比辗转相除多得多。\nReference #    https://www.cnblogs.com/fusiwei/p/11301436.html "},{"id":16,"href":"/blog/posts/ai/monte_carlo/","title":"蒙特卡洛法","section":"Posts","content":"蒙特卡洛(MonteCarlo)是一大类随机算法(RandomizedAlgorithms)的总称，它们通过随机样本来估算真实值。\n估计圆周率 #  假设有一个半径为1，圆心在原点的圆，我们知道它的面积是$\\pi$。现在我们随机在$x\\in[-1,1], y\\in[-1,1]$上随机取一个点，我们知道这个点落在圆内的概率为圆与正方形面积之比：\n$$ p = \\frac{\\pi}{4} $$\n假设我们随机选取了n个点，我们可以使用下面的公式判断哪些点位于圆内，假设有m个。\n$$ x^2 + y^2 \u0026lt; 1 $$\n显然，我们知道m的数学期望是\n$$ E[M] = \\frac{\\pi n}{4} $$\n当n很大时, m近似于数学期望，因此有\n $$ \\begin{aligned} m \\approx \\frac{\\pi n}{4} \\\\ \\pi \\approx \\frac{4m}{n} \\end{aligned} $$  近似求定积分 #  蒙特卡洛求积分的本质是利用随机模拟估计一个随机变量的期望。\n假设我们想求定积分:\n$$ \\int_{a}^{b} f(x) \\mathrm{d} x $$\n我们可以把它转换成某个随机变量的数学期望，具体如下：\n设随机变量$X \\sim U[a, b]$，即服从均匀分布，X具有概率密度$p(x)=\\frac{1}{b-a}$，那么就有:\n$$ E[f(X)] =\\int_{a}^{b} p(x)f(x) \\mathrm{d} x = \\frac{1}{b-a}\\int_{a}^{b} f(x) \\mathrm{d} x $$\n在统计学中，我们知道期望是可以估计的，我们随机取N个$f(x)$的样本，这些样本的平均值可以作为所求期望的近似，即：\n$$ E[f(x)] = \\frac{\\sum_1^Nf(x_i)}{N} = \\frac{1}{b-a}\\int_{a}^{b} f(x) \\mathrm{d} x $$\n那么就有：\n$$ \\int_{a}^{b} f(x) \\mathrm{d} x = (b-a)\\frac{\\sum_1^Nf(x_i)}{N} $$\n参考资料 #    https://blog.csdn.net/weixin_41503009/article/details/107853383  https://github.com/wangshusen/DRL "},{"id":17,"href":"/blog/posts/ai/conv-fft/","title":"Convolution with Image Filter \u0026\u0026 Convolution with fft/ifft","section":"Posts","content":"我们可以使用傅立叶变换实现卷积，具体做法大概就是先对数据和卷积核进行傅立叶变换将数据变换到频域，然后卷积就是频域上的乘积, 最后做逆傅立叶变换转化回原来的空域。\nr = ifft(fft(x).*fft(h)) 但是需要注意的是傅立叶变换做的卷积对应的是Circular Convolution。\ng = conv2(f,h,\u0026#39;same\u0026#39;); g_fft2 = ifft2(fft2(circshift(f,[-1,-1])).*fft2(rot90(h,2),2,4)); 使用傅立叶变换如果要获得和Circular Convolution一模一样的结果，需要对数据做一个shift，shift的大小和卷积核大小有关，二维情况就是[-w/2, -h/2]；然后卷积核也要反转一下，因为conv2卷积是倒着的。\n"},{"id":18,"href":"/blog/posts/ai/vae-more/","title":"More about Variational Autoencoder","section":"Posts","content":"一些关于VAE的扩展知识。\n不断更新中\u0026hellip;\nTraining Tips #   spectral regularization1 有利于稳定VAE的训练2 训练的时候可以使用KL cost annealing3的训练策略，KL项的权重一开始为0，只关注重建，等重建能力差不多了，再逐渐增加KL项的权重到1。 限制KL项中logvar.exp()，防止其值过大。4  强制clip weight初始化要小, 或使用$log(\\sigma^2)$5    Related Models \u0026amp;\u0026amp; Papers #  Beta-VAE #   beta-vae6就是给KLD加了一个权重beta。\n $$ \\mathcal{F}(\\theta, \\phi, \\beta ; \\mathbf{x}, \\mathbf{z}) \\geq \\mathcal{L}(\\theta, \\phi ; \\mathbf{x}, \\mathbf{z}, \\beta)=\\mathbb{E}_{q_{\\phi}(\\mathbf{z} \\mid \\mathbf{x})}\\left[\\log p_{\\theta}(\\mathbf{x} \\mid \\mathbf{z})\\right]-\\beta D_{K L}\\left(q_{\\phi}(\\mathbf{z} \\mid \\mathbf{x}) \\| p(\\mathbf{z})\\right) $$  原文还设计了一个评测指标用于评测latent representation disentangle好不好的方法，简单来说是这样的：\n 前提是：假设数据x是有一系列的disentangle factor y得到的，而且我们有一个ground truth simulator可以根据这些factor合成出数据x。\n 具体方法：\n 随机选一个factor y。 (Choose a factor y ∼ Unif[1\u0026hellip;K]) 对一个batch里的L个样本（一个batch中每个sample的factor都一样）：  sample 两个latent representation（人工设计的），这两个样本，在刚刚选的那个factor上相同，其他随机。 用simulator合成两张图像，用之前训练好的vae-encoder预测一个latent representaiton（网络学到的） 计算两张图像的latent representation的差值。   使用L个sample差值的平均数作为一个线性分类器的输入，预测刚刚选的factor是哪个。用预测的准确性作为评测指标。  Intuition：\n 分类器会被强行设计的只有线性分类能力。 如果vae学习到的latent representation够好，那理论上它应该有一维就是代表factor y， 在这个维度，每个样本的两张图像的值应该是很接近的，也就是说它们的差值会很接近0，那么分类器只需要找到很接近0的那一项就可以预测出刚刚选的factor是哪个了。  Extended beta VAE #   在Understanding disentangling in β -VAE7中，作者进一步扩展了beta VAE， 方法如下：\n $$ \\mathcal{L}(\\theta, \\phi ; \\mathbf{x}, \\mathbf{z}, C)=\\mathbb{E}_{q_{\\phi}(\\mathbf{z} \\mid \\mathbf{x})}\\left[\\log p_{\\theta}(\\mathbf{x} \\mid \\mathbf{z})\\right]-\\gamma\\left|D_{K L}\\left(q_{\\phi}(\\mathbf{z} \\mid \\mathbf{x}) \\| p(\\mathbf{z})\\right)-C\\right| $$  其中C是一个逐渐增大的常数。\nIntuition是，当C逐渐增大时，KLD的作用逐渐变小，重构误差逐渐占主导地位，因此我们可以学习到更好的重构图像。这点与KLD annealing正好是反过来的。\nSpectral Regularization #   简单来说：spectral regularization1用于降低 sensitivity to perturbation（测试数据微小的变动会引起结果很大的变化），方法是使用一个正则化，约束网络权重矩阵的谱范数，不让其过大。\n 原文：To reduce the sensitivity to perturbation, we propose a simple and effective regularization method, referred to as spectral norm regularization, which penalizes the high spectral norm of weight matrices in neural networks.\n 设$f$是我们要学习的函数，我们的目标是要让perturbation，即 $f(\\boldsymbol{x}+\\boldsymbol{\\xi})-f(\\boldsymbol{x})$ 尽量小。通常$f$ 都是一个线性函数加一个非线性激活函数。考虑到深度学习常用ReLU等piecewise linear function[?]作为激活函数。当$\\boldsymbol{\\xi}$很小的，我们可以把$f$看出一个线性函数。因此我们有： $$ \\frac{\\left|f_{\\Theta}(\\boldsymbol{x}+\\boldsymbol{\\xi})-f(\\boldsymbol{x})\\right|{2}}{|\\boldsymbol{\\xi}|{2}}=\\frac{\\left|\\left(W_{\\Theta, \\boldsymbol{x}}(\\boldsymbol{x}+\\boldsymbol{\\xi})+\\boldsymbol{b}{\\Theta, \\boldsymbol{x}}\\right)-\\left(W{\\Theta, \\boldsymbol{x}} \\boldsymbol{x}+\\boldsymbol{b}{\\Theta, \\boldsymbol{x}}\\right)\\right|{2}}{|\\boldsymbol{\\xi}|{2}}=\\frac{\\left|W{\\Theta, \\boldsymbol{x}} \\boldsymbol{\\xi}\\right|{2}}{|\\boldsymbol{\\xi}|{2}} \\leq \\sigma\\left(W_{\\Theta, \\boldsymbol{x}}\\right), $$ 其中$\\boldsymbol{\\xi}$是个常数，因此，如果我们要让$f(\\boldsymbol{x}+\\boldsymbol{\\xi})-f(\\boldsymbol{x})$ 尽量小，我们应该让上界$\\sigma\\left(W_{\\Theta, \\boldsymbol{x}}\\right)$尽量小。\n即：我们应当约束网络权重矩阵的谱范数，不让其过大。\nLadder Variational Autoencoders #   Ladder Variational Autoencoders8\n 提出了一个类似Ladder Network的Ladder Variational Autoencoders。  具体结构：TODO\n指出Batch Normal和KL Warm Up对训练很重要。  Re-balancing Variational Autoencoder Loss #   这篇文章9分析了RNN-based VAE中posterior collapse问题出现的原因，并提出了一个loss减轻这个问题。\nposterior collapse：任务是在RNN-VAE中，因为decoder训练的时候有ground truth作为teaching force，因此当latent representation很差的时候，decoder会忽视掉latent representation，导致latent representation和先验很接近，KLD这项很小，虽然loss可能不高，reconstruct因为有teaching force，loss不会太高，但是总体效果是很差的。\n分析原因，就是reconstruct loss被低估了，因此需要用系数调整，思路和beta-vae是一样的。\n $$ \\begin{aligned} \\mathcal{L}(x ; \\theta, \\phi)=\u0026 \\mathbb{E}_{q_{\\phi}(z \\mid x)}\\left[\\log p_{\\theta}(x \\mid z)\\right] \\\\ \u0026-D_{\\mathrm{KL}}\\left(q_{\\phi}(z \\mid x) \\| p(z)\\right), \\alpha1 \\end{aligned} $$  也可以改成beta-vae的形式，不过这里beta是在0-1区间，而beta-vae是\u0026gt;1，因为目标不一样。这里是向增大reconstruction的占比 - 等价于缩小KLD。\n $$ \\begin{aligned} \\mathcal{L}(x ; \\theta, \\phi)=\u0026 \\mathbb{E}_{q_{\\phi}(z \\mid x)}\\left[\\log p_{\\theta}(x \\mid z)\\right] \\\\ \u0026-\\beta D_{\\mathrm{KL}}\\left(q_{\\phi}(z \\mid x) \\| p(z)\\right), 0 \\leq \\betaCVAE #   Learning Structured Output Representation using Deep Conditional Generative Models10这篇论文提出了CVAE。\n传统VAE估计的是边缘概率$P(X)$， 而CVAE估计的是条件概率$P(X|Y)$。例如在图像中，X就是图像，Y是图像的类别，CVAE不仅可以生成图像，还可以指定生成哪种类型的图像。\n传统VAE的ELBO是： $$ \\log P(X)-D_{K L}[Q(z \\mid X) | P(z \\mid X)]=E[\\log P(X \\mid z)]-D_{K L}[Q(z \\mid X) | P(z)] $$ 加入条件概率，直观地，相当于我们让encoder同时依赖于X和Y - $Q(z|x,y)$，让decoder依赖于Z和Y - $P(x|z,y)$，那我们的ELBO就变成了: $$ \\log P(X \\mid c)-D_{K L}[Q(z \\mid X, c) | P(z \\mid X, c)]=E[\\log P(X \\mid z, c)]-D_{K L}[Q(z \\mid X, c) | P(z \\mid c)] $$ 详细的推导：\n TODO  Conditional Variational Image Deraining #   这篇文章11是CVAE的一个应用，它的任务是把下雨时候照的照片中的雨给去掉。\n要理解它的做法，我们需要重新理解下CVAE究竟在做什么。\n 传统的VAE都是输入一张图像X，然后我们用encoder学它的latent representation，然后我们再sample，经过decoder生成图像。如果我们想要生成指定类别的图像，这种方法是做不到的。\n那么一个很直接的思路是，我们可不可以输入一个类别，让encoder学习输出这个类别的latent representation，然后我们再通过同样的过程生成特定类别的图像？答案是很难。\n CVAE的做法是什么呢？我们给encoder一个额外信息，我们告诉它某个类别的图像是长什么样的，这样它在学习的时候会更有效。在这种角度下，CVAE其实是对传统VAE的一个小优化。\n在这篇去雨论文中，它的思路是类似的：\n 我们把下雨照片当作“类别”，每一张下雨照片都是一个类别 我们希望学习每个类别的latent representation，即每张下雨照片，干净版本的latent representation。 然后我们通过多次sample，decode出多张干净照片，取个平均作为最终结果。 只输入下雨照片不好训练encoder，因此我们加入一个condition，训练的时候我们把干净照片也加进去，帮助encoder进行训练。 但是问题是预测的时候，我们没有干净照片作为encoder的额外输入，这时候encoder就没法用了，为此作者引入了一个额外的prior network去模仿encoder的encode过程，但是只用rainy image作为输入。   预测的时候使用的是prior network。\n NVAE #   英伟达2020的一个工作2，主要说两点：\n 提出了一个精心设计的VAE网络，并指出VAE可以在网络设计上多下点功夫。 提出了多个稳定KLD的方法：  Residual Normal Distributions: Spectral Regularization (SR) More Expressive Approximate Posteriors with Normalizing Flows    具体还没细看。\nResources #    Denoising Criterion for Variational Autoencoding Framework  Some useful tricks in training variational autoencoder  https://github.com/loliverhennigh/Variational-autoencoder-tricks-and-tips/blob/master/README.md  Loss设计 #     Balancing Reconstruction vs KL Loss Variational Autoencoder\n   Why don\u0026rsquo;t we use MSE as a reconstruction loss for VAE ? #399\n   how to weight KLD loss vs reconstruction loss in variational auto-encoder\n  Github #  这里是一些Github上使用VAE的项目代码：\n  AntixK/PyTorch-VAE  NVlabs/NVAE  Reference #    Yoshida 和 Miyato - 2017 -Spectral Norm Regularization for Improving the Generalizability of Deep Learning\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Vahdat 和 Kautz - 2020 - NVAE A Deep Hierarchical Variational Autoencoder\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Bowman 等。 - 2016 - Generating Sentences from a Continuous Space\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n  https://discuss.pytorch.org/t/kld-loss-goes-nan-during-vae-training/42305\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n  https://github.com/y0ast/VAE-Torch/issues/3\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Higgins 等。 - 2017 - β-VAE: LEARNING BASIC VISUAL CONCEPTS WITH A CONSTRAINED VARIATIONAL FRAMEWORK\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Burgess 等。 - 2018 - Understanding disentangling in $\\beta$-VAE\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Sønderby 等。 - 2016 - Ladder Variational Autoencoders\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Yan 等。 - 2020 - Re-balancing Variational Autoencoder Loss for Molecule Sequence Generation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Sohn 等。 - 2015 - Learning Structured Output Representation using Deep Conditional Generative Models\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Du 等。 - 2020 - Conditional Variational Image Deraining\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n  "},{"id":19,"href":"/blog/posts/misc/hugo-book/","title":"Hugo-Book Shortcodes Usages","section":"Posts","content":"Hugo-Book Shortcodes Usages\n 如果公式里出现矩阵，需要用div将$$包括起来，否则无法正常显。见 Link 如果公式需要换行，需要用六个斜杠\\\\\\，见 Link   Buttons #  {{\u0026lt; button relref=\u0026#34;/\u0026#34; [class=\u0026#34;...\u0026#34;] \u0026gt;}}Get Home{{\u0026lt; /button \u0026gt;}}{{\u0026lt; button href=\u0026#34;https://github.com/alex-shpak/hugo-book\u0026#34; \u0026gt;}}Contribute{{\u0026lt; /button \u0026gt;}} Get Home  Contribute  Columns #  Columns help organize shorter pieces of content horizontally for readability.\n{{\u0026lt; columns \u0026gt;}} \u0026lt;!-- begin columns block --\u0026gt; # Left Content Lorem markdownum insigne... \u0026lt;---\u0026gt; \u0026lt;!-- magic separator, between columns --\u0026gt; # Mid Content Lorem markdownum insigne... \u0026lt;---\u0026gt; \u0026lt;!-- magic separator, between columns --\u0026gt; # Right Content Lorem markdownum insigne... {{\u0026lt; /columns \u0026gt;}} Example #  Left Content #  Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.  Mid Content #  Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter!  Right Content #  Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.   Details #  Details shortcode is a helper for details html5 element. It is going to replace expand shortcode.\nExample #  {{\u0026lt; details \u0026#34;Title\u0026#34; [open] \u0026gt;}}## Markdown content Lorem markdownum insigne... {{\u0026lt; /details \u0026gt;}}{{\u0026lt; details title=\u0026#34;Title\u0026#34; open=true \u0026gt;}}## Markdown content Lorem markdownum insigne... {{\u0026lt; /details \u0026gt;}}Title Markdown content #  Lorem markdownum insigne\u0026hellip;   Expand #  Expand shortcode can help to decrease clutter on screen by hiding part of text. Expand content by clicking on it.\nExample #  Default #  {{\u0026lt; expand \u0026gt;}}## Markdown content Lorem markdownum insigne... {{\u0026lt; /expand \u0026gt;}}  展开 ↕  Markdown content Lorem markdownum insigne\u0026hellip;    With Custom Label #  {{\u0026lt; expand \u0026#34;Custom Label\u0026#34; \u0026#34;...\u0026#34; \u0026gt;}}## Markdown content Lorem markdownum insigne... {{\u0026lt; /expand \u0026gt;}}  Custom Label ...  Markdown content Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.    Hints #  Hint shortcode can be used as hint/alerts/notification block.\nThere are 3 colors to choose: info, warning and danger.\n{{\u0026lt; hint [info|warning|danger] \u0026gt;}}**Markdown content** Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa {{\u0026lt; /hint \u0026gt;}}Example #  Markdown content\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa  Markdown content\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa  Markdown content\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa  Mermaid Chart #   Mermaid is library for generating svg charts and diagrams from text.\nExample #  {{\u0026lt; mermaid [class=\u0026#34;text-center\u0026#34;]\u0026gt;}}sequenceDiagram Alice-\u0026gt;\u0026gt;Bob: Hello Bob, how are you? alt is sick Bob-\u0026gt;\u0026gt;Alice: Not so good :( else is well Bob-\u0026gt;\u0026gt;Alice: Feeling fresh like a daisy end opt Extra response Bob-\u0026gt;\u0026gt;Alice: Thanks for asking end {{\u0026lt; /mermaid \u0026gt;}}   mermaid.initialize({ \"flowchart\": { \"useMaxWidth\":true }, \"theme\": \"default\" } ) sequenceDiagram Alice-Bob: Hello Bob, how are you? alt is sick Bob-Alice: Not so good :( else is well Bob-Alice: Feeling fresh like a daisy end opt Extra response Bob-Alice: Thanks for asking end   Tabs #  Tabs let you organize content by context, for example installation instructions for each supported platform.\n{{\u0026lt; tabs \u0026#34;uniqueid\u0026#34; \u0026gt;}}{{\u0026lt; tab \u0026#34;MacOS\u0026#34; \u0026gt;}}# MacOS Content {{\u0026lt; /tab \u0026gt;}}{{\u0026lt; tab \u0026#34;Linux\u0026#34; \u0026gt;}}# Linux Content {{\u0026lt; /tab \u0026gt;}}{{\u0026lt; tab \u0026#34;Windows\u0026#34; \u0026gt;}}# Windows Content {{\u0026lt; /tab \u0026gt;}}{{\u0026lt; /tabs \u0026gt;}}Example #  MacOS MacOS #  This is tab MacOS content.\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.\nLinux Linux #  This is tab Linux content.\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.\nWindows Windows #  This is tab Windows content.\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.\n"},{"id":20,"href":"/blog/posts/algorithms/AC%E8%87%AA%E5%8A%A8%E6%9C%BA/","title":"AC自动机","section":"Posts","content":"AC自动机用于解决下述问题及其同类问题:\n 给定一系列模式串和一个文本串，判断有多少模式串出现在文本串中，给出数目和对应模式串的出现位置。\n 主要思想 #  AC自动机主要用到了 Trie树和 KMP算法的思想。\n构造 #  我们首先将所有模式串构建成一个Trie树，构建方法与普通Trie树的构建方法没有区别。\nAC自动机的树结构主要是比Trie树多一个fail指针（类似于KMP算法的next数组）。\nclass AcNode { public: AcNode* m_childs[26] = { nullptr }; bool m_is_end; // 是否是单词边界  char m_c; // 新增内容  AcNode* fail = nullptr; }; 该fail指针是AC自动机的核心，它表示当前树节点匹配失败，下一个要尝试匹配的树节点。实际上，fail指针所指的树节点所构成的字符串是当前树节点构成字符串的后缀。\nFail指针的求法\nroot的孩子的fail指针是root, 对于其他节点，其fail指针是父亲的fail指针所指的树节点的孩子中和当前节点字母相同的节点。如果不存在这样的节点，则尝试寻找fail指针所指树节点的fail指针所指的节点有无这样的节点，直到root节点。\n比较绕口，举个例子：\n{% include image.html url=\u0026quot;/assets/img/ac_automaton1.png\u0026quot; description=\u0026ldquo;图1. Fail指针求解\u0026rdquo; size=\u0026ldquo;30%\u0026rdquo; %}\n如图1所示，h2的fail指针是h1。求解过程是h2 -\u0026gt; s2 -\u0026gt; s2.fail = s1 -\u0026gt; h1。\n匹配 #  匹配的时候也很简单，对于文本串中的每个字母，从AC自动机的root开始尝试匹配。\n 匹配成功，则跳至其fail指针，继续尝试匹配，直到跳回root指针 - 处理类似she同时包含she和he的情况。 匹配失败，也要跳到其fail指针继续尝试匹配。  根据需要记录匹配成功的数目，位置以及对应的模式串。\nC++实现 #  具体实现参见 ac_automaton.cpp，这里解释一下求fail指针的build函数。\nvoid build() { queue\u0026lt;AcNode*\u0026gt; q; for(int i=0; i\u0026lt;26; i++) { if(root-\u0026gt;m_childs[i] != NULL) { root-\u0026gt;m_childs[i]-\u0026gt;fail = root; q.push(root-\u0026gt;m_childs[i]); } else { root-\u0026gt;m_childs[i] = root; } } AcNode* current; while(!q.empty()) { current = q.front(); q.pop(); for(int i=0; i\u0026lt;26;i ++) { if(current-\u0026gt;m_childs[i] != NULL) { current-\u0026gt;m_childs[i]-\u0026gt;fail = current-\u0026gt;fail-\u0026gt;m_childs[i]; q.push(current-\u0026gt;m_childs[i]); } else { current-\u0026gt;m_childs[i] = current-\u0026gt;fail-\u0026gt;m_childs[i]; // 路径压缩  } } } } 要点:\n 使用BFS逐层的求解fail指针。 不存父亲指针，遍历到当前节点时，计算子节点的fail指针。 注意把root指针的所有“空”孩子设置为root，否则容易在计算孩子的fail指针时发生segemntation fault，current-\u0026gt;fail-\u0026gt;m_childs[i]这个表达式fail可能是root。 不用递归寻找符合要求的fail指针, 使用类似并查集的思想进行路径压缩。  路径压缩\n核心为这行代码:\ncurrent-\u0026gt;m_childs[i] = current-\u0026gt;fail-\u0026gt;m_childs[i]; 当current-\u0026gt;fail-\u0026gt;m_childs[i] = NULL的时候，这行代码将m_childs[i]置为其fail-\u0026gt;m_childs[i]，由于是逐层求解fail的，因此当fail-\u0026gt;m_childs[i]也等于NULL的时候，其值会在之前被设置成其fail-\u0026gt;m_childs[i]。\n因此current-\u0026gt;fail-\u0026gt;m_childs[i];总是指向满足要求的节点或者root。\n 满足要求: fail指针所指的树节点所构成的字符串是当前树节点构成字符串的后缀。\n 参考资料 #   [洛谷日报第44期]强势图解AC自动机: Link "},{"id":21,"href":"/blog/posts/algorithms/trie%E6%A0%91/","title":"Trie树","section":"Posts","content":"Trie树可以:\n 压缩存储大量的字符串 快速找出具有相同前缀的字符串 快速按字典序对字符串进行排序 \u0026hellip;  主要操作 #  Trie树的主要操作包括:\n insert: 插入字符串。 search: 查询某字符串是否存在。 startsWith: 查询包含某前缀的字符串。  [str]: 返回所有包含该前缀的字符串。 bool: 返回是否存在。    实现 #  Trie树的实现和普通树的实现类似，可以用数组或链表实现。 这里的例子是链表实现的，如下是树节点的定义。\nclass TrieNode { public: TrieNode* m_childs[26] = { nullptr }; bool m_is_end; // 是否是单词边界  char m_c; }; Trie树的定义如下:\nclass Trie { public: Trie(); void insert(string word); bool search(string word); bool startsWith(string prefix); protected: TrieNode* root; }; "},{"id":22,"href":"/blog/posts/programming/semaphores/","title":"Semaphores(信号量)","section":"Posts","content":"Semaphores是一种同步机制（Concurrency Mechanisms），它用来协调各个进程访问公共资源。其基本思想如下所述：\n 两个或多个进程通过一个信号量进行协调，当一个进程需要某个资源时，它需要申请并等待一个信号，如果信号没有来临则等待。\n General Semaphores #  general semaphore的一种实现。\nstruct semahpore { int count; queueType queue; }; void semWait(semaphore a) { s.count--; if (s.count \u0026lt; 0) { /* place this process in s.queue. */ /* block this process. */ } } void semSignal(semaphore a) { s.count++; if(s.count \u0026lt;= 0) { /* remove a process from s.queue. */ /* place process p on ready list. */ } }   count的含义\n 大于0时：指示当前可以加进来的进程数。 小于等于0时：绝对值指示当前想加入还未加入的进程数。    队列里存储的就是等待加入的进程。\n  Binary Semaphore #  struct binary_semaphore { enum {zero, one} value; queueType queue; }; // B: Binary void semWaitB(binary_semaphore s) { if (s.value == one) s.value = zero; else { /* place this process in s.queue. */ /* block this process. */ } } void semSignalB(semaphore s) { if (s.queue is empty()) s.value = one; else { /* remove a process P from s.queue. */ /* place process P on ready list. */ } } 优缺点 #   比较难编程，当需要同时使用多个semaphore的时候，需要仔细安排semaphore调用顺序等，否则容易出现死锁。  例子：\n/* program producersonsumer */ semaphore n = 0, s = 1; void producer() { while (true) { produce(); semWait(s); append(); semSignal(s); semSignal(n); } } void consumer() { while(true) { semWait(n); semWait(s); take(); semSignal(s); consume(); } } void main() { parbegin (producer, consumer); }  这里 semaphore n 用于防止consumer消耗空buffer，s用于buffer的mutual exclusion。 如果buffer为空，且consumer的 semWait(n); 与 semWait(s); 互换，则第一个semWait能成功进入，但会在第二semWait被阻塞。 这时由于，buffer被consumer占用，producer无法生产新的product加入buffer， semWait(s);将被一直阻塞，产生死锁。 "},{"id":23,"href":"/blog/posts/algorithms/%E6%B5%B7%E6%98%8E%E7%A0%81/","title":"错误检测-海(汉)明码","section":"Posts","content":"Hamming code，海明码，汉明码都是一个东西。它是一种编码方式，通常用在网络信息传输中，通过这种编码方式编码出来的二进制数据具有检测一位错误位的能力。\n例如：\n 假设要传输的二进制数据为 1011001 。 通过海明码编码后（如何编码后面会说），得到 101 0100 1110 。 假设从右往左第6位从0变为了1。 通过某种方法我们可以从产生变化后的数据 101 0110 1110 得知第六位发生改变。  下面则将具体讲解这些过程。\n编码过程 #  第一步是确定冗余位(bit)的数目，这些位将为检错提供必要的信息。\n根据算法要求，冗余位的数目(r)必须满足： $$ 2^r \\geq m + r + 1 $$ 其中m为原始数据位的数目。\n第二步是确定冗余位的位置\n同样根据算法设计，冗余位将放在位置编号为2的幂次的位置上。\n如：1,2,4,8\u0026hellip;\n假设要传输的数据为 1011001 ，则编码后各个数据位的排布应如下图所示：\n 第三步是确定冗余位的值\n计算方法如下：\n 处于第$2^i$位的冗余位的值，将是所有位置编码(二进制表示)中第i位为1的那些位置的原始数据的偶校验。\n 如R1，它的值将是第1,3,5,7,9,11这些位置上的数据的偶校验，所以\n由于3，5，7，9，11中1的个数为偶数，故R1=0（偶校验～1的个数为偶数个）。\n 假设要传输的数据为 1011001 ，则编码后结果如下：\n 检错与纠错 #  同上，假设要传输的数据为 1011001 ，编码后为1010 1001 110 。\n假设实际传输过去的数据为 1010 1101 110 ，即从右往左第6位由0变为了1。\n这时候，如果我们再用计算冗余位值的方法重新计算一遍冗余位的值，我们会发现：\nR4R3R2R1 = 0110 即十进制下的6。\n这表明从右往左第6位发生错误，这时候我们将其反转即可纠正。\nIntuition #  实际上，我们的目标是得到一个数字，这个数字表示数据中出错那一位的位置。\n如果我们将其表示为二进制的形式，那么我们的任务即变为了确定各个bit位是0还是1。\n在前面我曾要求过这个表达式：\n$2^r \\geq m + r + 1$\n它的含义即在于，如果我们利用r个冗余位确定这个二进制数字（r个冗余位确定r个数字中的bit位），那么我们必须保证这个数字的范围能够表示编码数据串中的所有位置。\n可能有人会问，既然如此，那满足这个表达式$2^r \\geq m + r$ 不就可以了吗，为什么要+1呢？\n 因为位置编码必须从1开始，从0开始没法纠错。因此位置编码的最大值位m+r+1。\n  海明码的巧妙之处就在于它偶校验的分组上，每个冗余位都对应了一个bit位为1的那些位置。\n  一开始将数据编码成海明码的时候，所有组都是满足偶校验的，即1的个数为偶数。\n  如果某一位发生变化，不管是从0变为1还是从1变为0，它所在组对应的偶校验均会变为1。\n  而且它只属于-它位置编码为1的那几位对应的那些组，也只有这些组的偶校验会变成1。\n  这样，如果我们对所有组求一次偶校验，组成的二进制数表示的正好是发生变化那个位的位置。\n  换句话说，海明码将错误位置的确认分散到了各个组上，通过一次能偶校验，能够确定错误位置属不属于这个组，经过r次偶校验后，便能确定其具体位置。\n参考资料 #   https://www.geeksforgeeks.org/computer-network-hamming-code/\n"},{"id":24,"href":"/blog/posts/ai/Generalized-Linear-Model/","title":"How genralized linear model work?","section":"Posts","content":"本文将简单的讲述：GLM是如何工作的？\nOur goal 在讨论GLM之前，我们还是先要明确我们的目标是什么：\n 给定一些 feature X，我们需要预测一个y。 即我们需要构造一个 hpythoesis: $h_\\theta(x) = y$\n How GLM work?  假设 y 的取值服从某个分布 如果这个分布可以写成指数族的形式：$p(y; \\eta) = b(y) exp(\\eta^T T(y) − a(\\eta))$ 则有一个性质：T(y)是y的充分统计量 然后我们则用 y 在该分布下的数学期望去预测y，即我们让 $h_\\theta(x) = E(y)$ 除此之外还假设 $\\eta$ 与 X 线性相关，即： $\\eta = \\theta^TX$  Example  Logistic Regression   假设y的取值服从伯努利分布： $y|x; \\theta ∼ Bernoulli(\\phi)$ 伯努利分布在指数族中，将其改写成指数族的形式：  \\[ \\begin{align} p(y; \\phi) \u0026= \\phi^y (1-\\phi)^{1-y} \\\\ \u0026= exp(ylog(\\phi) + (1-y)log(1-\\phi))\\\\ \u0026= exp(ylog\\frac{\\phi}{1-\\phi} +log(1-\\phi)) \\end{align} \\]\n​ 由此可得： \\( T(y) = y \\\\ \\eta = log\\frac{\\phi}{1-\\phi} \\) ​ 反解$\\phi$ ： \\( \\phi = \\frac{e^{\\eta}}{1+e^{\\eta}}= \\frac{1}{1+e^{-\\eta}} \\)\n 利用y在伯努利分布下的数学期望预测y：  \\[ \\begin{align} y \u0026= E[y|x;\\theta] \\\\ \u0026=\\phi \\\\ \u0026= \\frac{1}{1+e^{-\\eta}} \\end{align} \\]\n 假设 $\\eta$ 与 X 线性相关，即： $\\eta = \\theta^TX$ 。可得：  \\[ y = \\frac{1}{1+e^{-\\theta^TX}} \\]\n"},{"id":25,"href":"/blog/posts/algorithms/%E5%85%8B%E9%B2%81%E6%96%AF%E5%8D%A1%E5%B0%94%E7%AE%97%E6%B3%95/","title":"克鲁斯卡尔算法","section":"Posts","content":"首先，克鲁斯卡尔算法是用来求最小生成树的。另一种求最小生成树的算法叫普林姆算法（Prim）。\n克鲁斯卡尔算法本质是贪心，每次选取 不与当前已有边构成环 权值最小 的边作为生成树的边。\n算法细节 #   判断是否构成环使用并查集  复杂度分析 #  使用并查集的克鲁斯卡尔算法时间复杂度为O(eloge)，其中loge为并查集判断环所需时间，每条边都要判断一次，因此为O(eloge)。\n"},{"id":26,"href":"/blog/posts/algorithms/%E6%99%AE%E6%9E%97%E5%A7%86%E7%AE%97%E6%B3%95/","title":"普林姆算法","section":"Posts","content":"普林姆算法也是用来求最小生成树的，与克鲁斯卡尔算法遍历边不同，普林姆遍历的是点。\n普林姆算法同样基于贪心，以任意点为初始点，每次选取与已选点相连的边中权值最小的边，并把与这条边相连的点加入已选点集合。\n算法实现 #   维护一个数组 minEdge[i]  含义为已选点集合中到第i个点 最小权值的边的终点，没有边则为无穷大。\n每次选minEdge中最小的点加入已选点集合，并更新minEdge数组。 重复操作，直到所有点加入已选点集合。  优化 #   使用优先队列维护minEdge  每往已选点集合加入点时，就把与该点相连的所有边都加入优先队列。而当取边时，需要判断一下边的终点是否在已选点集合中（可以使用一个标记数组）。\n时间复杂度分析 #   非优先队列法   在minEdge中找最小的时间复杂度为O(n)。 更新数组时间复杂度总和为O(e) —— 每个点都会更新与它相连的边，所有边加起来为e。 一共要进行n次在minEdge中找最小的操作。  故总的时间复杂度为O(n^2+e)。\n优先队列法  优先队列加边出边的时间复杂度都是O(loge)。\n 所有边都会进入优先队列至少一次，至多两次。时间复杂度为O(eloge)。 出边次数最少为n次，最多为e次，时间复杂度也是O(eloge)。  故总的时间复杂度为O(eloge)。\n分析： 当边数达到cn^2或以上时，用非优先队列法要好，反之可以使用优先队列法。\n当e = n^2 ,  O(eloge) = O(n^2logn) , O(n^2+e) = O(n^2) 。\n"},{"id":27,"href":"/blog/posts/algorithms/%E5%B9%B6%E6%9F%A5%E9%9B%86/","title":"并查集","section":"Posts","content":"使用并查集可以快速判断两个元素是否属于同一个集合。\n算法 #  基本思路 #  使用树来表示集合。\n 初始时，所有元素都分别是一棵树。 若两个元素属于同一个集合，则用一个元素作为另一个元素的孩子。  实现\n数据结构：\n fa[i] : 保存元素i的祖先  第一步：初始化\nfor(int i=0; i \u0026lt; n; ++i) fa[i] = i;\t// 初始时，所有元素都分别是一棵树(祖先是自己） 第二步：根据关系构造并查集\n// 查找树根 int find(int x) { if(fa[x] == x) return x; return find(fa[x]); } int temp_a, temp_b; for(int i=0; i \u0026lt; m; ++i){ cin \u0026gt;\u0026gt; a \u0026gt;\u0026gt; b; // a, b属于同一集合  temp_a = find(a), temp_b = find(b); fa[a] = b; } Note: 先找到树根，不管相不相同，都让a是b的孩子。\n第三步：查询方法\nfor(int i=0; i \u0026lt; T; ++i){ cin \u0026gt;\u0026gt; a \u0026gt;\u0026gt; b; if(find(a) == find(b)) cout \u0026lt;\u0026lt; \u0026#34;Yes\u0026#34; \u0026lt;\u0026lt; endl; else cout \u0026lt;\u0026lt; \u0026#34;No\u0026#34; \u0026lt;\u0026lt; endl; } Note: 判断树根是否相同即可。\n优化 #   降低树的深度（路径压缩）  find 操作耗费时间取决于树的深度，因此，如果在 find  执行过程让树的深度降低，则可以降低后续操作所需的时间。\n方法： 让树根的后代们尽量都是树根的孩子。\n// 查找树根 int find(int x) { if(fa[x] == x) return x; //return find(fa[x]);  return fa[x] = find(fa[x]); } Note: fa[x] = find(fa[x]) 的值为左值 fa[x] ，等价于先fa[x] = find(fa[x]);  再 return fa[x]; 。\n让小树接在大树上  每次发生树的拼接之后的 find 操作都需要重新降低树的深度，而显然元素少的树接到元素多的树上，需要的 重组次数较少。\n例子：\n 灰色圆圈即为要重组的元素，显然小接大要合算。\n实现方法：\n r[i] : 表示以元素i为根的树的相对大小  // 封装一下 void Union(int a, int b) { int temp_a = find(a), temp_b = find(b); if(r[temp_a] \u0026gt;= r[temp_b]) { fa[b] = a; //小树的父亲等于大树  if(r[temp_a] == r[temp_b]) ++r[a]; // b为a的孩子-\u0026gt;树变大了  } else fa[a] = b; } for(int i=0; i \u0026lt; n; ++i) { fa[i] = i;\tr[i] = 0;\t// 记得初始化 } for(int i=0; i \u0026lt; m; ++i) { cin \u0026gt;\u0026gt; a \u0026gt;\u0026gt; b; // a, b属于同一集合 \tUnion(a,b); } 实验 #  输入：\n 10 8 1 2 1 3 1 4 1 5 2 6 5 7 5 8 0 9 5 1 6 1 3 5 7 0 9 1 0 输出：\nYes Yes Yes Yes No 完整代码：\n// 并查集 #include \u0026lt;iostream\u0026gt;using namespace std; const int MAXN = 100; int fa[MAXN], r[MAXN], n, m; // n为元素数,m为关系数  // 查找树根 int find(int x) { if(fa[x] == x) return x; return find(fa[x]); } void Union(int a, int b) { int temp_a = find(a), temp_b = find(b); if(r[temp_a] \u0026gt;= r[temp_b]){ fa[b] = a; //小树的父亲等于大树  if(r[temp_a] == r[temp_b]) ++r[a]; // b为a的孩子-\u0026gt;树变大了  } else fa[a] = b; } int main() { cin \u0026gt;\u0026gt; n; // 初始化  for(int i=0; i \u0026lt; n; ++i) { fa[i] = i;\t// 初始时，所有元素都分别是一棵树(祖先是自己）  r[i] = 0; } cin \u0026gt;\u0026gt; m; // 构造并查集  int a, b; for(int i=0; i \u0026lt; m; ++i) { cin \u0026gt;\u0026gt; a \u0026gt;\u0026gt; b; // a, b属于同一集合  Union(a,b); } // 查询  int T; cin \u0026gt;\u0026gt; T; for(int i=0; i \u0026lt; T; ++i) { cin \u0026gt;\u0026gt; a \u0026gt;\u0026gt; b; if(find(a) == find(b)) cout \u0026lt;\u0026lt; \u0026#34;Yes\u0026#34; \u0026lt;\u0026lt; endl; else cout \u0026lt;\u0026lt; \u0026#34;No\u0026#34; \u0026lt;\u0026lt; endl; } return 0; } 复杂度分析 #   优化前的算法  算法复杂度主要取决于：1. 构造并查集 2. 查询操作\n 构造并查集复杂度分析：  查询find操作递归次数不会超过树的深度，树的深度不会大于n，因此，find操作复杂度为O(logn)。\n构造时时间花费主要在find操作上，且要执行2m次find操作。因此构造并查集的时间复杂度为O(2mlogn), 忽略常数为O(mlogn)。\n 查询操作复杂度分析：  查询操作需要两次find操作，时间复杂度为O(logn)。\n优化后的算法  先说结论：O((n+m)log*n) ，其中log*为增长及其缓慢的 迭代函数，通常可以视为常数。\n证明为构造性证明，较为复杂，这里不做扩展。\n"},{"id":28,"href":"/blog/posts/ai/Principal-component-analysis/","title":"Principal component analysis","section":"Posts","content":"PCA (Principal component analysis) 是一种给数据降维的方法。\n利用PCA，能将一堆高维空间的数据映射到一个低维空间，并最大限度保持它们之间的可区分性。\n 可以看到，图中的数据点大致分布在一条直线上。\n因此，我们能够将点投影到直线上，用直线上的点到原点的距离代替原来二维向量。\n这样我们的数据就从 二维降到了一维。\n 推导过程 #   设输入数据为X ，X 为 (n * m) 的矩阵，每一行为一个sample。  如果我们要将 数据 转换到一个低维空间，我们应该对 X 做一次线性变换（即更换基底）。\n 设新的 基底 为 P ， P 为一个 (m * k) 的矩阵，每一列为一个基底。 经过变换后，设新的数据为 Y, 则 $Y=XP$ 。  X 的协方差矩阵为 $X^TX$，我们希望经过变换后的 Y 的协方差矩阵（$Y^TY$）\n 对角线上元素绝对值尽可能大 非对角线上元素绝对值绝对值尽可能小。  即我们希望，在新的基底下，各个feature的关联性很小，而在同一个feature上，能尽最大可能保持数据的variance。\nY的协方差矩阵的数学表达式:\n$$C_Y = Y^TY = (XP)^T(XP) = P^TX^TXP$$\n可以证明，为了使 $C_Y$ 满足上述条件，P 应为 $X^TX$ 的特征向量矩阵，其中 P 的每一列为一个特征向量。\n那么，由矩阵对角化的知识，可以得到\n$$C_Y = P^TX^TXP = D$$\n其中D为一对角矩阵，对角线上元素为特征向量对应的特征值。\n在这里，每个特征值还对应了新的feature的方差（variance），它的值的大小反映了新的feature用于区分数据的能力。方差小说明这个feature对大部分数据来说基本都一样（直观来说，既然大家都一样，我们就可以说这个feature是多余的）。\n因此，我们可以将特征向量根据特征值排序，根据需要将原始数据转换为低维数据，并尽最大可能保持数据的有效性。\n参考资料 #  Stackexhange\n  How would you explain covariance to someone who understands only the mean?  Making sense of principal component analysis, eigenvectors \u0026amp; eigenvalues  Why is the eigenvector of a covariance matrix equal to a principal component?  Intuition on the definition of the covariance  Does the magnitude of covariance have any real meaning?  Intuitive understanding covariance, cross-covariance, auto-/cross-correliation and power spectrum density  Wikipedia\n  Covariance  Cross product  Covariance matrix  Other\n A Tutorial on Principal Component Analysis\u0026rsquo;by Jonathon Shlens  Principal Components Analysis "},{"id":29,"href":"/blog/posts/misc/%E6%B4%9B%E4%BC%A6%E5%85%B9%E5%8F%98%E6%8D%A2/","title":"洛伦兹变换","section":"Posts","content":"洛伦兹变换是从光速不变原理推出的，不同坐标系坐标之间的转换关系。\n**光速不变原理：**对任何参考系，光速都为一个固定值C\n狭义相对性原理： 在所有惯性系中，物理定律都有相同的表达形式\n 洛伦兹变换推导 #   以二维直角坐标为例，只考虑x轴方向运动\n假设你相对于我向x轴正方向以速度 u 运动，我和你在某个时间相遇，这时候\n 我和你分别以自己为原点建立坐标系。 将我和你的时钟归零    以我看来，假设在 t 时刻， x 位置发生了一个事件。\n设该事件，在你看来，发生在 t‘ 时刻， x‘ 位置。\n接下来，有关我的量都不带 ' ,而有关你的都带 '。\n###相对论出现之前\n那么由于你相对我在运动，则在我看来，你运动了 ut 的距离，并且我认为 你认为事件发生的位置是 $$ x' = x-ut $$ 而反过来，在你看来，你认为你运动了 ut' 的距离，你认为 我认为事件发生的位置是 $$ x = x' + ut' $$\n###相对论出现之后\n如果现在，我们质疑这两个式子的正确性。\n比如，如果在你看来，你觉得你的 x' 与我认为 你认为的 x' 不相等，那么不如给式子乘上一个系数 $\\gamma$ ，通过别的条件计算，如果系数是1，那我就是对的，如果不是，那结果就是那样。 $$ x' = \\gamma (x-ut) $$ 同理，我觉得你的 x 与你认为的我的 x 不相等，同样的，乘一个系数 $\\gamma$ ， 这个系数与之前的一样 [1]。 $$ x = \\gamma (x'+ut') $$ 为了解出这个系数 $\\gamma$ ，我们不妨从一个具体事件出发（当然这可能导致推导不太严谨，但是可以证明，结果是正确的）。\n  假设这个事件以一束光触发，并且在我看来在 t 时间的时候发生\n 由光速不变原理，我们可以得到 [2]\n 在我看来，发生的距离 $x = ct$ 在你看来，距离 $x' = ct'$  由上面四个方程，则能推出洛伦兹变换的坐标变换式 [3]\n$$ \\begin{equation}\n\\left{\n\\begin{array}{lr}\nx' = \\frac{x-ut}{\\sqrt{1-u^2/c^2}} \u0026amp; (1)\\\nx = \\frac{x'+ut'}{\\sqrt{1-u^2/c^2}} \u0026amp; (2) \\end{array}\n\\right.\n\\end{equation} $$ 方程（1）即由我的坐标转换为你的。\n方程（2）反过来。\n注意： u表示你相对我向正方向运动的速度。\n而利用 (1), (2)式还能够导出 洛伦兹变换的时间变换式 [4]。 $$ \\begin{equation}\n\\left{\n\\begin{array}{lr}\nt' = \\frac{t-xu/c^2}{\\sqrt{1-u^2/c^2}} \u0026amp; (3)\\\nt = \\frac{t'+x\u0026rsquo;u/c^2}{\\sqrt{1-u^2/c^2}} \u0026amp; (4) \\end{array}\n\\right.\n\\end{equation} $$ 仅仅通过这四个式子可能不太容易弄明白 洛伦兹变换究竟意味着什么。\n下面将展示一系列通过洛伦兹变换的到的结果。\n时间差与空间差 #  假设在我看来在(在我的坐标系中)， 在$(x_1,t_1)$ 和 $(x_2,t_2)$ 分别发生了两个事件。\n那么由洛伦兹变换，在你看来 $$ \\begin{equation}\n\\left{\n\\begin{array}{lr}\nx_1' = \\frac{x_1-ut_1}{\\sqrt{1-u^2/c^2}} \u0026amp; \\\nt_1' = \\frac{t_1-x_1u/c^2}{\\sqrt{1-u^2/c^2}} \u0026amp;\n\\end{array}\n\\right.\n\\end{equation} $$\n$$ \\begin{equation}\n\\left{\n\\begin{array}{lr}\nx_2' = \\frac{x_2-ut_2}{\\sqrt{1-u^2/c^2}} \u0026amp; \\\nt_2' = \\frac{t_2-x_2u/c^2}{\\sqrt{1-u^2/c^2}} \u0026amp;\n\\end{array}\n\\right.\n\\end{equation} $$\n上下分别相减，则可以得到时间差和空间差的关系 $$ \\begin{equation}\n\\left{\n\\begin{array}{lr}\n\\Delta x' = \\frac{\\Delta x -u\\Delta t }{\\sqrt{1-u^2/c^2}}\u0026amp; (5)\\\n\\Delta t' = \\frac{\\Delta t - \\Delta x u/c^2}{\\sqrt{1-u^2/c^2}}\u0026amp; (6) \\end{array}\n\\right.\n\\end{equation} $$ (5) 意味着在我看来的距离 $\\Delta x$，在相对我运动的你看来，要长一些。\n(6) 意味着在我看来的时间差 $\\Delta t$ ，对于相对我运动的你来说，不再是相同的时间差。\n长度收缩 #  现在，假设我和你要测量一个物体的长度，这个物体以u的速度相对我向正方向运动，而你和这个物体一起运动。\n我将通过两个事件测量这个物体的长度。\n 在某一时刻，在物体两端发生了两个事件，分别记为 $(x_1,t),(x_2,t)$ 那么两个事件的空间差即为物体的长度  那么由前面的空间差的关系，你测量出的长度为 $\\Delta x'$ ，而我测量出的长度为 $\\Delta x$，由公式5可知，我测出的长度比你测出的要短一些。\n即相对物体运动的观察者 测出的物体长度 要比相对物体静止的观察者 测出的要短。\n时间延缓 #  前面提到，我和运动的你，对于两个事件的时间差的认识发生了偏差。\n假设这两个事件对应时钟\n 事件1: 走到这一秒 滴 事件2: 走到下一秒 嗒  那么，由前面的（6）式可以知道，在我的时空坐标中的 1s 与你的时空坐标中的 1s 不再相同。 如果我们忽略两个走针的距离，即$\\Delta x= 0$ (对应其他事件，即同一地点发生的两个事件），那么我们可以得到 $$ \\Delta t' = \\frac{\\Delta t }{\\sqrt{1-u^2/c^2}} $$ 在相对我运动的你的时空坐标中，你的1s变长了。也即你的时间延缓了。\n其实，这里的钟可以提高到更加普遍的范畴上，任何两个事件的时间差都会变长。比如我们的身体的化学反应的进程等等，都被延缓了。\n孪生子悖论\n如果我活了50岁，你可能才到20岁。\n 如果我现在登上飞船，以很高的速度进行星际旅行，那么等我回到地球时，会发现你比我年轻。\n而这在你看来，则相反，你会认为我比你年轻。这就是孪生子悖论。\n 事实上，地球上的你的看法才是对的，狭义相对论只对惯性系有同等意义，即只有在惯性系中上面的等式才成立。对于在飞船上的你，必定经历了一段加速过程（你的时空坐标是非惯性系），在这段时间里，不能利用上面的公式计算 我和你的时间差。\n而要正确计算我和你的年龄差，需要利用积分进行计算。\n参考： 维基百科：双生子佯谬\n同时性的相对性 #  由上面的公式（6）我们还可以得到 同时的概念是相对的 。 $$ \\Delta t' = \\frac{\\Delta t - \\Delta x u/c^2}{\\sqrt{1-u^2/c^2}} $$ 两个对我来说同时发生的时间，即 $\\Delta t = 0$ ，对于你来说\n 如果对我来说，它们不同地发生 [5] ($\\Delta x \\not = 0$) ，则 $\\Delta t' \\not= 0$ ，即对我同时发生的两个事件，对你来说不同时发生。 而如果对我来说是同时同地发生的事件，对你来说也是同时同地发生的。[6]  速度的关系 #  由洛伦兹变换还能推导出，在我的时空坐标中的速度与你的时空坐标中的速度之间的关系。 $$ v' = \\frac{\\Delta x'}{\\Delta t'} = \\frac{\\Delta x -u\\Delta t }{\\Delta t - \\Delta x u/c^2} = \\frac{\\Delta x / \\Delta t -u }{1 - \\Delta x/\\Delta t u/c^2} = \\frac{v -u }{1 - v u/c^2} $$\n附录 #  [1] 根据相对性原理，在所有惯性系中物理定律都具有相同的形式，故修正系数 $\\gamma$ 对任何人都应相同。\n[2]\n[3]\n[4]\n[5] 由公式5，对于你也一定不同地\n[6] 对于这个，我们设想一个事件两辆车相撞，它可以分解为两个事件，一个是一辆车在某个时刻到某个地点，另一个是另一辆车在同一时刻到同一地点。这样它们才能相撞。所以如果对我来说同时同地发生的这两个事件，对你来说不是同时同地的，那么对你来说车不会相撞，而车相撞是客观存在的。因此对我来说是同时同地发生的事件，对你来说也是同时同地发生的。\n四维空间的理解 #  在二维坐标中，一个点(x,y)，不论怎么做变换，旋转，平移等等，都只会涉及x,y。用两个坐标就能够描述这个二维世界。\n在三维世界，我们描述一个事件，需要用到（x,y,z,t），我们怎么\u0026hellip;\n待续.\n"},{"id":30,"href":"/blog/posts/algorithms/Fibonacci%E6%95%B0%E7%9A%84%E8%BF%AD%E4%BB%A3%E7%AE%97%E6%B3%95/","title":"Fibonacci数的迭代算法","section":"Posts","content":"使用迭代算法求斐波那契数列，\n时间复杂度O(n)，空间复杂度O(1)。\nint f(int n) { int f1 = 1, f2= 0; while(--n){ f1 = f1+f2; // f(n) = f(n-1)+f(n-2)  f2 = f1-f2;\t// f(n-1) = f(n)-f(n-2)  } return f1; } "},{"id":31,"href":"/blog/posts/algorithms/%E5%BF%AB%E9%80%9F%E5%B9%82/","title":"快速幂算法","section":"Posts","content":"在c，c++语言中，并没有提供求幂的基本运算，通常我们需要自己写函数或者调用STL提供的函数。\n一般情况下，我们写的求幂函数基本上都是循环累乘，时间复杂度为O(n)。虽说是线性的时间复杂度，但求幂运算作为基础运算，往往调用频繁，这时候即使是线性的时间复杂度也将变得难也接受。\n利用快速幂可以快速计算底数的n次幂。其时间复杂度为 O(logn)\n原理 #  以求 $a^{11}$ 为例，将11写成二进制形式 1011。\n则 $a^{11} = a^{2^0+2^1+2^3}=a^{1+2+8} =a^1\\times a^2\\times a^8$\n使用一个累乘器，每次翻倍 base = base*base 逐步得到 $a^1,a^2,a^4,a^8$ ，根据11的二进制，如果为1则乘进结果里。\n实现 #  迭代算法\nint power(int a,int b) { int base = 1,ans = a; while(a \u0026gt; 0){ if(a \u0026amp; 1 == 1) ans *= base;//二进制位为1的才要乘  base *= base; a \u0026gt;\u0026gt;= 1; } return ans; } 递归算法\nint power(int a,int b) { if(b == 1) return a; int temp = power(a,b\u0026gt;\u0026gt;1) * power(a,b\u0026gt;\u0026gt;1); return (b\u0026amp;1 == 1 ? a:1) * temp * temp; // 若指数为偶数则分解成一半，若为奇数，则还要再乘a } 递归算法与迭代算法的思路略有不同。\n"},{"id":32,"href":"/blog/posts/algorithms/%E4%BD%8D%E8%BF%90%E7%AE%97%E7%9A%84%E5%A6%99%E7%94%A8/","title":"位运算的妙用","section":"Posts","content":"对于一些特定问题，巧妙运用位运算能使解法异常简洁和高效，同时，适当运用位运算也能对程序进行优化。\n运用的时候，可能涉及多种位运算。\n计算机中位运算分为以下六种：\n 与 \u0026amp; 或 | 非 ～ 异或 ^ 左移 \u0026laquo; 右移 \u0026raquo;  异或 #  异或具有以下性质（可能还有，下同）：\n a^b = b^a a^a = 0 a^0 = a  实例 #  [leetcode 136 single number]\n Given an array of integers, every element appears twice except for one. Find that single one.\nNote: Your algorithm should have a linear runtime complexity. Could you implement it without using extra memory?\n **题目大意：**每个元素都出现两次，但有一个只出现一次，找出出现一次的元素。\n 这题如果用标记数组做 时间复杂度，空间复杂度都是 O(n) 。但如果利用异或的前两个性质，则可以将空间复杂度压缩到O(1)。\nclass Solution { public: int singleNumber(vector\u0026lt;int\u0026gt;\u0026amp; nums) { if(nums.size() == 0) return 0; int result = nums[0]; for(int i=1;i\u0026lt;nums.size();i++) result = result ^ nums[i]; return result; } }; 与或 #  与运算可以快速取得一个变量某个 bit位 的数值。\n如： 0010 \u0026amp; 1110 = 0010 0010 \u0026amp; 1101 = 0000\n如果 0010 \u0026amp; b = 0010 则表明 b 的第二位是1，不等则为0。\n 与运算可以快速将某bit为快速置为0，而或运算可以快速将某bit位置为1。\n与运算的其他用法\n n \u0026amp; (n-1) 可以把n的最低位置0  左移右移 #  左移相当于乘2，右移相当于除2，并且它们的速度比乘除要快。\n所以当程序中出现大量✖️2，或➗2运算时，可以用左移和右移进行优化。\n例子 #   LeetCode Bit Manipulation\n"},{"id":33,"href":"/blog/posts/algorithms/%E7%AD%9B%E6%B3%95%E6%B1%82%E7%B4%A0%E6%95%B0/","title":"筛法求素数","section":"Posts","content":" 假设要求n以内的素数\n 筛法求素数是用一个大小为n的数组，作为标记数组，如果没被标记到则为素数。\n开始均为未标记。\n从2开始，2没被标记，将2存入一个存素数的地方，然后筛掉小于n的，2的所有倍数。然后是3，筛掉3的所有倍数，依此类推，直到n-1。\n优化 #  上面的做法，同一个数可能会被筛掉多次，比如6会被3和2各筛一次。\n为了提高效率，需要进行优化，使得每个数尽可能的被少筛，如果能一次最好。\n考虑到任何合数都可以分解成若干个素数的乘积。在筛掉合数的过程中，最好的是让每个合数只被它最小的因子筛掉。\n如24 18 都只被2筛掉\nC++实现 #  int countPrimes(int n) { vector\u0026lt;bool\u0026gt; vis(n,false); vector\u0026lt;int\u0026gt; prime; for(int i=2;i\u0026lt;n;i++){ if(!vis[i]) prime.push_back(i); for(int j=0;j\u0026lt;prime.size() \u0026amp;\u0026amp; i*prime[j]\u0026lt;=n;j++){ vis[i*prime[j]] = true; if(i%prime[j] == 0) break;\t//优化  } } return prime.size(); } 最外层循环每次循环，都能得到小于等于i的所有素数，当要求i+1内的素数时，只需判断i+1是否在之前被筛掉。\n与此同时，将当前所有素数的i+1倍筛掉。\n那后面出现的素数的i+1倍，设为m ，会怎么样呢？\n 如果i+1是素数，m会被 i+1 筛掉 如果i+1不是素数，则m 会被i+1的最小质因数（之前出现过的素数中的某一个）筛掉。  **优化点：**每个数都被它最小的因数筛掉\n具体操作：如果循环到某个素数 prime[j] 是 i+1的倍数时，后面的素数的i+1倍 prime[j+1] * (i+1) 就不用筛了。\n原因在于：后面素数的i+1倍一定会被 prime[j] （更小的一个数）筛掉，\n$prime[j+1] * (i+1) = prime[j+1] * prime[j] * k$\n$k = (i+1) / prime[j]$\n"},{"id":34,"href":"/blog/docs/notes/paper/arbrcan/","title":"ArbSR: 任意尺度超分 - 阅读笔记","section":"Paper","content":"Created: August, 12, 2021 论文: Learning A Single Network for Scale-Arbitrary Super-Resolution\nCode: https://github.com/LongguangWang/ArbSR\n "},{"id":35,"href":"/blog/docs/gen/introduction/","title":"Introduction","section":"AIGC","content":"Created: March, 23, 2023 对于生成式模型来说，我们要解决的核心问题就是如何构造一个 highly flexible families of probability distribution 去拟合真实的数据分布，并且我们希望这个分布家族对于，\n learning：通过数据学习分布形式。 sampling：从分布中取样。 inference：计算条件概率 $p(x|y)$。 evaluation：计算给定样本出现的概率 $p(x)$。  这四个任务，都是或尽可能都是 analytically 或者 computationally tractable [1]_ 的 :raw-latex:\\parencite{sohl2015deep}。\n为了这个目标，人们提出了各种各样的模型，方法。这些方法的核心思路基本就是，在保证 tractable 的前提下，尽可能的提升flexibility，从而更好的拟合复杂的真实数据分布。常见的模型包括：Mixture Gaussian, VAE, Normalizing Flow, DDPM, GAN 等等。对于这些模型，上述的四个任务并不是都能够解的，大部分都只能解决其中一个或几个（例如GAN，我们只能做 learning 和 sampling）。\nThink from Scratch #  以上的介绍可能过于抽象，现在我们可以从零开始思考，如果现在我们拥有一堆数据，这些数据有很多样本，比如说我们有 N 个样本，每个样本都是一个 D 维的向量，我们要如何学习这些数据的分布呢？\n想要回答这个问题，我们必须理解 ”分布“ 是什么？分布其实就是概率分布，概率分布就是一个随机变量不同取值的概率构成的一个函数。对于一个连续的随机变量，单个取值的概率没有意义，这时候，分布其实是代指概率密度函数。\n这时候，我们应该知道，对于前面提到的数据，如果我把数据中的样本视作一个 D 维的随机变量，我们实际上就是想要学习这个随机变量的概率密度函数。\n这时候，又引出了一个新的问题，这个概率密度函数的形式是什么样的呢 ？如果我们知道概率密度函数的解析形式，那么我们就可以通过极大似然估计，根据给定的数据，估计出这个分布的未知参数了。例如，如果我们假设数据服从高斯分布，但是均值方差未知，通过极大似然估计，我们就可以得到这个分布的均值和方差。\n数据分布的形式的选取是需要根据我们的先验知识决定的，但很多时候，我们并没有这些先验知识，我们也不想自己决定。另一方面，即便我们有一些先验知识，但是现实中可供选取的 family of distribution 是有限的，这些分布并不一定能够建模复杂的真实数据。\nLatent Variable Model #  为此，我们通常考虑使用 Latent Variable Model 对数据分布进行建模，即我们希望从一个known well-defined distribution 出发，通过学习一个分布的映射，将这个已知分布映射到未知的数据分布。\nModeling #  具体的，假设我们有一个 q 维的 latent space $\\mathbb{R}^{q}$ 和 n 维的 data space $\\mathbb{R}^{n}$，我们事实上是希望学习一个能够将 latent space 里的 sample（样本） 映射到 data space 里的函数，$g: \\mathbb{R}^{q} \\rightarrow \\mathbb{R}^{n}$。\n如果这个函数是 deterministic 的，那么我们就得到了 GAN 这个模型。特别的，我们要求 data space 里的每个样本，都至少有一个 latent space 里的样本与之对应。\n如果这个函数是 stochastic 的，那么我就得到了 VAE，DDPM 等模型。这时候，我们在学习的函数实际上变成了一个后验概率分布 :math:p_{g}(\\mathbf{x} \\mid \\mathbf{z})\\ 。我们通常会选取具有具体形式的分布对 :math:p_{g}(\\mathbf{x} \\mid \\mathbf{z}) 进行建模（例如高斯分布），我们学习的函数实际上就变成预测这些分布的未知参数。\n进一步的，在学习到后验概率分布 :math:p_{g}(\\mathbf{x} \\mid \\mathbf{z})\\ ，结合已知的先验分布 :math:p_{\\mathcal{Z}}(\\mathbf{z})\\ ，我们便可以通过全概率公式，求出未知的数据分布，如下：\n$$ p_{\\mathcal{X}}(\\mathbf{x})=\\int p_{g}(\\mathbf{x} \\mid \\mathbf{z}) p_{\\mathcal{Z}}(\\mathbf{z}) d \\mathbf{z} \\label{eq-intro-px} $$\nLearning #  直观的，如果我们定义好后验概率分布 :math:p_{g}(\\mathbf{x} \\mid \\mathbf{z}) 和先验分布 :math:p_{\\mathcal{Z}}(\\mathbf{z}) 之后，我们就能够通过公式 [eq-intro-px] \u0026lt;#eq-intro-px\u0026gt;__ 计算出 :math:p(x)\\ ，然后我们通过极大似然估计拟合训练数据，即可估计出后验概率分布中未知的参数了。\n.. math::\n\\prod_{x\\in X}^X p(x) \\label{eq-intro-loglikelihood}\n但是！这么做实际上有一个很大的问题。由于积分的存在，公式 [eq-intro-px] \u0026lt;#eq-intro-px\u0026gt;__ 通常是（大部分时候都是）Intractable的。为什么这么说呢？\n  首先，如果积分可以解析算出来，那肯定没问题。\n  如果不行，最常见的做法是蒙特卡洛估计，即对 :math:z 随机取样，然后计算被积函数，用其平均值替代积分。取样越多估计越准。见公式 [eq-monte-carlo-px] \u0026lt;#eq-monte-carlo-px\u0026gt;__\\ 。\n.. math::\nP(x) \\approx \\frac{1}{N} \\sum_{z_n\\sim P(Z)} P(x|z_n) \\label{eq-monte-carlo-px}    问题在，对于一个高维的 latent variable :math:z 以及真实数据来说，大部分的 :math:p(x|z) 都可能会是零，或非常小，即大部分的 z 都不太可能生成 真实数据中的样本 x [2]_，但是，还是有可能有 z 是可能产生真实数据中的样本 x 的，即 :math:p(x|z) 比较大。因此，为了得到一个准确估计，我们必须要取样非常多的 :math:z\\ ，而这对一个高维的 :math:z 来说，将会是一个我们不能接受的数字。\n  为此，我们通常的做法是优化公式 [eq-intro-loglikelihood] \u0026lt;#eq-intro-loglikelihood\u0026gt;__ 的可解的一个变分下界 VLBO [3]（通常也被称为ELBO [4]），做一个近似的似然估计，如下：\n.. math::\n\\begin{aligned} log P(x) \u0026amp; = log\\int P(x|z)P(z) dz \\ \u0026amp; = log\\int \\frac{Q(z|x)P(x|z)P(z)}{Q(z|x)} dz \\ \u0026amp; = logE_{z\\sim Q}[\\frac{P(x|z)P(z)}{Q(z|x)}] \\ \u0026amp; \\geq E_{z\\sim Q}[log\\frac{P(x|z)P(z)}{Q(z|x)}] \\ \u0026amp; = E_{z\\sim Q}[logP_\\theta(x|z)] - D_{KL}[Q_\\theta(z|x) | P(z)] \\end{aligned} \\label{eq-vae-elbo}\n怎么理解这个下界，为什么会想到转换成这个形式呢？这里提供一种解释。回忆刚刚我们遇到的问题，主要是公式 [eq-intro-px] \u0026lt;#eq-intro-px\u0026gt;__ 中的积分没法有效估计，其原因是从 :math:Z 中采样，击中被积函数 :math:P(x|z) 概率大的地方的概率太小，得到有效估计需要的采样数目无法接受。\n换句话说，我们本质上是想知道 :math:P(x|z) 相对于 z 的期望，我们现在是从 :math:P(z) 中取样估计这个期望，但这么做取样出来的 :math:z 算出来的 :math:P(x|z) 概率太小了。\n.. math:: P(x) = \\int P(x|z)P(z) dz = E_{z\\sim Z}[P(x|z)]\n怎么解决呢？直观的思路就是，那我们就从一个能让 :math:P(x|z) 概率大的分布取一些 :math:z 出来。什么分布能满足这个要求呢？最好的当然是从 :math:P(z|x) 中取样，但真实的 :math:P(z|x) 是一个未知的分布，因此，我们退而求其次，使用一个 :math:Q(z|x) 去近似它，即这时候我们希望这么算 :math:P(x),\n.. math::\n\\begin{aligned} P(x) \u0026amp; = \\int P(x|z)P(z) dz \\ \u0026amp; = \\int \\frac{Q(z|x)P(x|z)P(z)}{Q(z|x)} dz \\ \u0026amp; = E_{z\\sim Q}[\\frac{P(x|z)P(z)}{Q(z|x)}] \\end{aligned}\n这时候蒙特卡洛估计就会更准了，如下所示：\n.. math:: P(x) \\approx \\frac{1}{N} \\sum_{z_n\\sim Q(Z|x)} P(x|z_n) P(z_n) / Q(z_n|x)\n还没完，通常，我们一般会用 log 似然估计，因为这样可以把概率的连乘变成连加。即这时候，我们希望最大化这个函数：\n.. math:: log P(x) = log E_{z\\sim Q}[\\frac{P(x|z)P(z)}{Q(z|x)}]\n那我们要怎么求解 :math:log P(x) 呢？对于 :math:P(x)\\ ，它等价于一个期望，我们直接蒙特卡洛估计没什么问题。但是对于 :math:log P(x) 呢？直觉来看，我们能不能蒙特卡洛估计求出 :math:E_{z\\sim Q}[\\frac{P(x|z)P(z)}{Q(z|x)}] 然后再取个 log 呢？答案是不行，但我还没找到一个精确的解释和反例。直观上来解释，蒙特卡洛估计只能针对一个分布，而 :math:log P(x) 不是一个分布，所以不能这么干。\n我们的做法是通过 Jensen 不等式，将 :math:log P(x) 进行放缩转换成优化一个期望，这时候就可以正常使用蒙特卡洛估计了。\n.. math::\n\\begin{aligned} log P(x) \u0026amp; = logE_{z\\sim Q}[\\frac{P(x|z)P(z)}{Q(z|x)}] \\ \u0026amp; \\geq E_{z\\sim Q}[log\\frac{P(x|z)P(z)}{Q(z|x)}] \\ \u0026amp; = E_{z\\sim Q}[logP_\\theta(x|z)] - D_{KL}[Q_\\theta(z|x) | P(z)] \\end{aligned} \\label{eq-vae-elbo-jensen}\n后记： :math:Q(z|x) 这个分布的选取策略，塑造了不同的生成式模型，例如，在 VAE [5]_ 中，\\ :math:Q(z|x) 是一个联合训练的已知分布（例如高斯或伯努利），在 DDPM 中，\\ :math:Q(z|x) 是一个由已知分布（例如高斯或伯努利）组成的马尔可夫链。\n如果你对EBLO对推导还不太明白，可以再参考一下这篇博客 [6]_。\n.. [1] 如果一个问题即能在有效时间内解决,不管是通过解析还是近似的方式,我们就称它是 tractable 的。\n.. [2] 可以考虑自然图像代表的数据空间，一个128_128的图像，可以视作一个128_128维的随机变量，每个维度都有256种取值，但是只有很小的一部分会得到合理的图像，也就是说这个随机变量代表的数据空间里，只有很小的一个子空间概率密度比较大。因为 data space :math:X 每个 sample 都要至少有一个 latent space :math:Z\\ \\ 的 sample 与之对应，所以从 Z 里取样，通过映射\\ \\ :math:g\\ \\ ，还是很难落到概率的子空间里。\\ \\ 思考\\ \\ ：那我们对 data space 做一个压缩不就行了吗，用PCA 或者 VQVAE 降维？\n.. [3] VLBO: Variantional Lower BOund\n.. [4] ELBO: Evidence Lower BOund\n.. [5] 由前面的解释可以知道，我们采用了一个 :math:Q(z|x) 去近似真实的 :math:P(z|x)\\ \\ ，这种用一个函数去学习另一个函数的方法，通常被称为 variational xx，这也是 VAE 名字中 V 的来源。\n.. [6] http://www.denizyuret.com/2019/11/a-simple-explanation-of-variational.html\n"},{"id":36,"href":"/blog/docs/matrix/jordan/","title":"Jordan Form","section":"Matrix","content":"Created: Decemenber, 7, 2020 Jordan Form是矩阵对角化的一个推广的产物。\n我们知道矩阵$A$可以对角化成一个对角矩阵$\\Lambda$，而且这个矩阵的对角线元素是$A$的特征值，前提是矩阵$A$存在n个线性无关的特征向量。如果不满足，则不能对角化，即找不到一个S，使得：\n$$ \\Lambda = S^{-1}AS $$\nJordan则推广了这个对角化的过程，任何矩阵，即使它不存在n个线性无关的特征向量，它也可以相似“对角化”为一个Jordan标准型$J$。\n$$ J = P^{-1}AP $$\n但这时，J的对角线不在是一个单独的元素，而是一系列Jordan块（请想象一下分块矩阵）。\n$\\lambda$矩阵 #  如果一个矩阵每个元素都是变量$\\lambda$的多项式，则称这个矩阵为$\\lambda$矩阵，记做$A(\\lambda)$。\nSmtih标准形\n每一个$\\lambda$矩阵都可以化成对角形矩阵，这个对角形矩阵称为该$\\lambda$矩阵的Smith标准形。\n对角线上的元素按一定顺序排列：\n 每一个元素都能整除后一个元素 0在最后面（这其实是第一条规则的推论）  不变因子\nSmith标准形对角线上的元素称为$A(\\lambda)$的不变因子。\n行列式因子\nk阶行列式因子就是Smith标准形的前k各元素相乘。k最大只能取到矩阵秩，就是说行列式因子没有0。\n$$ D_k(\\lambda) = d_1(\\lambda)d_2(\\lambda)\u0026hellip;d_k(\\lambda) $$\n初等因子\n不是常数的不变因子的“因数”称为初等因子。\n例如，若$\\lambda$矩阵的不变因子是\n1, 1, $(\\lambda-2)^5(\\lambda-3)^3$, $(\\lambda-2)^5(\\lambda-3)^4(\\lambda+2)$\n则它的初等因子是，仔细看\n$(\\lambda-2)^5$, $(\\lambda-3)^3$, $(\\lambda-2)^5$, $(\\lambda-3)^4$, $(\\lambda+2)$\n"},{"id":37,"href":"/blog/posts/algorithms/kmp/","title":"KMP算法","section":"Posts","content":"问题描述:\n 给定一个文本串S, 和一个模式串P, 我们要找到P在S中的位置，即给出P的第一个字符在S中的位置。\n 朴素算法 #  枚举S中每个位置，判断是否是模式串P的起点。\n基于上述思想，我们可以很容易可以写出如下的枚举代码:\nint vanilla_find(const string\u0026amp; s, const string\u0026amp; p) { int pos = -1; bool ok = true; for(int i=0; i\u0026lt;s.size(); i++) { ok = true; for(int j=0; j\u0026lt;p.size(); j++) { if(s[i+j] != p[j]) { ok = false; break; } } if(ok) { pos = i; break; } } return pos; } 上述实现使用1个循环枚举配对的起点，再用1个循环判断从该起点开始是否有模式串P。\n为了方便理解KMP算法，我们不妨换一种思路实现这个朴素算法。\nint vanilla_find2(const string\u0026amp; s, const string\u0026amp; p) { int i=0, j=0; while(i \u0026lt; s.size() \u0026amp;\u0026amp; j \u0026lt; p.size()) { if(s[i] == p[j]) { i++; j++; } else { i=i-j+1; j=0; } } if(j == p.size()) return i-j; else return -1; } 上述实现使用两个指针, i, j，i指针代表当前S串匹配到的位置，j表示P串匹配到的位置，遇到不匹配，则将i指针回溯到上一次尝试的起始点的后一个位置，即i-j+1。j指针回溯到开头。\n虽然两种实现本质是一样的，但第二种实现会更容易理解KMP算法的优化。\n如图1所示，当我们匹配成功ABCDAB后，发现D不匹配，这时如果我们将i回溯到i-j+1的位置，匹配必然失败，因为我们前一步已经知道S[i-j+1]=B了。\n如果我们能够利用前一步的匹配结果，让i不必回溯，只回溯j的话，那么匹配效率会大幅提升。\n{% include double-image.html url1=\u0026quot;/assets/img/kmp1.png\u0026quot; caption1=\u0026ldquo;Step1\u0026rdquo; url2=\u0026quot;/assets/img/kmp2.png\u0026quot; caption2=\u0026ldquo;Step2\u0026rdquo; size=\u0026ldquo;70%\u0026rdquo; description=\u0026ldquo;图1\u0026rdquo; %}\nKMP算法 #  如果我们把之前的优化\u0008假设形式化一下，我们将得到如下的描述。\n当失配时，我们希望能够让i=i,j=next[j]，即i不用回溯，j根据当前位置决定\u0008模式串要跟S[i]匹配的位置。\n事实上，这个假设是成立的，考虑如图2的情况：\n{% include double-image.html url1=\u0026quot;/assets/img/kmp3.png\u0026quot; caption1=\u0026ldquo;Step1\u0026rdquo; url2=\u0026quot;/assets/img/kmp4.png\u0026quot; caption2=\u0026ldquo;Step2\u0026rdquo; size=\u0026ldquo;70%\u0026rdquo; description=\u0026ldquo;图2\u0026rdquo; %}\n当D失配时，我们知道模式串的D之前有相投的前缀后缀AB，因此我们只需要尝试匹配模式串前缀AB后的D以及文本串的 即可。\n换句话说，我们知道这时候next[j]=2。\n如此，现在的问题就变成如何求next数组了。\n求解next数组 #  让我们再次考虑图2的情况，事实上，我们已经能够发现求解next[j]的规律了。对于P串的第j个元素，其失配后需要回溯到的位置取决于 - P串前j个元素有多长相同的前缀后缀。如果有长度为k的相同前缀后缀，则next[j]=k。\n基于上述思想，我们其实已经可以编写一个暴力求next数组的程序了。\nvector\u0026lt;int\u0026gt; get_next_vanilla(const string\u0026amp; p) { vector\u0026lt;int\u0026gt; next(p.size()); next[0] = -1; for(int i=1; i\u0026lt;p.size(); i++) { int n_match = 0; // 枚举所有\u0008可能的相同前缀后缀  for(int k=1; k\u0026lt;i; k++) { bool ok = true; for(int j=0; j\u0026lt;k; j++) { if(p[j] != p[i-k+j]) ok = false; } if(ok == true) n_match = k; } next[i] = n_match; } return next; } 很显然，这种暴力求解的效率是很低的($$O(n^3)$$)。因此，我们需要对求解next的算法进行优化。\n递推求解优化 #  考虑下面这种情况\nABCDABDC 01234567 如果我们已经求得next[6]=2，即D之前有相同前缀后缀AB，那么我们在求next[7]的时候，只需要判断P[next[6]] == P[7-1] (C==D)是否成立即可。\n 若成立，显然next[7] = next[6] + 1。 若不成立，那么我们需要考虑D要和AB这个前缀中的哪个字母进行配对组成相同前缀后缀。（其实这是一个套娃问题:》）  换句话说，我们在求next[i]的时候我们实际上需要的是，P[:i-1]中最长的相同前缀后缀（可以通过next[i-1]得到），设长度为k, 然后再判断P[l] == P[k]。如果不等于的话，我们就找出P[:k-1]中第二长的相同前缀后缀，用同样方法再判断一次。\n实际上，第二长的相同前缀后缀可以通过next[next[k-1]]得到。\n 为什么？第一长的相同前缀后缀的相同前缀后缀实际上就是第二长的相同前缀后缀。例如 ABABCDABAB, 第一长是 ABAB, 第二长是 AB\n 基于上述思想，我们可以写出如下的递推求解的代码\nvector\u0026lt;int\u0026gt; get_next(const string\u0026amp; p) { vector\u0026lt;int\u0026gt; next(p.size()); next[0] = -1; for(int i=1;i\u0026lt;p.size();i++){ int k=i-1; while(k!=0 \u0026amp;\u0026amp; p[i-1] != p[next[k]]) k=next[k]; // 先找出\u0026#34;OK\u0026#34;的前缀后缀  next[i] = next[k] + 1; } return next; } 继续优化 #  优化1\n我们首先可以重构一下代码, 以下代码和get_next等价。\nvector\u0026lt;int\u0026gt; get_next2(const string\u0026amp; p) { vector\u0026lt;int\u0026gt; next(p.size()); next[0] = -1; int i=0, k=-1; while(i \u0026lt; p.size() - 1) { if(k == -1 || p[i] == p[k]) { i++; k++; next[i] = k; } else { k = next[k]; } } return next; } 优化2\n再者，考虑如下情况\nabab next: -1, 0, 0, 1 当b失配时，next=1，但是P[1]=b，我们没必要再比一次，因为这次一定失配，基于此我们可以再次优化。如下所示：\nvector\u0026lt;int\u0026gt; get_next2_opt(const string\u0026amp; p) { vector\u0026lt;int\u0026gt; next(p.size()); next[0] = -1; int i=0, k=-1; while(i \u0026lt; p.size() - 1) { if(k == -1 || p[i] == p[k]) { i++; k++; // 以下两行为优化内容  if(p[k] != p[i]) next[i] = k; else next[i] = next[k]; } else { k = next[k]; } } return next; } 原来的get_next当然也可以用同样的方法优化，但是要注意写法。 下面这种优化方式就不行。事实上，当你把下面的代码改对之后，你会发现你的代码就变得和get_next2_opt基本一样了。\nvector\u0026lt;int\u0026gt; get_next_opt(const string\u0026amp; p) { vector\u0026lt;int\u0026gt; next(p.size()); next[0] = -1; for(int i=1;i\u0026lt;p.size();i++){ int k=i-1; while(k!=0 \u0026amp;\u0026amp; p[i-1] != p[next[k]]) k=next[k]; // 先找出\u0026#34;OK\u0026#34;的前缀后缀  // 直接这样优化是不行的  if(p[i] != p[next[k]+1]) next[i] = next[k] + 1; else next[i] = next[next[k]+1]; } return next; } 参考资料 #   从头到尾彻底理解KMP: cnblogs "},{"id":38,"href":"/blog/docs/notes/concept/nflow/","title":"Normalizing Flow","section":"Concept","content":"简单介绍 #  首先，Normalizing Flow是一种生成模型（Generative Model），它的提出是为了解决现有的生成的模型的一些问题，如GAN训练不稳定，VAE边缘概率估计intractable的问题。\nNormalizing Flow是一种特殊的inveritable网络，每个模块都是可逆的，并且有tractable determinant of the Jacobian，且求逆也是tractable的。\n优点：\n 相比VAE，不必引入噪声， more powerful local variance models. 相比GAN，训练更稳定，更易收敛。  缺点\n 每个模块都必须可逆，限制了表达能力。 可逆要求latent space的维度很高。  详细介绍 #  参考资料 #   Github: normalizing-flows  Introduction to Normalizing Flows  Stanford CS236: Normalizing flow models  Difference between invertible NN and flow-based NN  "},{"id":39,"href":"/blog/docs/notes/paper/patchmatch/","title":"PatchMatch 导读","section":"Paper","content":"Created: Jan, 24, 2022 PatchMatch: A Randomized Correspondence Algorithm for Structural Image Editing\n Sample Impl ｜ 知乎解读\n图像匹配的典中典，基于匹配块周围的匹配也近似匹配的先验知识的随机化算法。\n 首先明确这篇论文解决的问题是图像匹配问题，即给定两张图像A，B，我们需要将A，B中相同的像素或图像块（Patch）进行匹配，得到一个偏移量f，使得对于A中每个点的坐标x，B中对应点的坐标为x+f(x)。\n这篇论文提出了一个Randomized Correspondence Algorithm来做这件事情。要理解这个算法，我们首先需要这个算法的核心insight：\nThe key insights driving the algorithm are thatsome good patch matches can be found via random sampling, and that natural coherence in the imagery allows us to propagate such matches quickly to surrounding areas.  用中文来说就是，对于一个匹配好的点，我们知道其偏移量为f(x)，基于图像的连续性，那么这个点周围的点的偏移量应该也近似是f(x)，这样我们就可以快速把正确点的偏移量向其周围传播，使其周围点的估计偏移量越来越准确。\n图像的连续性：一个苹果在两张图像上放在不同位置，但是苹果上某两个点的相对位置关系近似不变。  算法 #  前提条件 假设我们有两张图像A，B，我们需要找到一个偏移量f，使得对于A中每个点的坐标x，B中对应点的坐标为x+f(x)。\nPatchMatch的算法主要分为三个步骤：\n Initialization： 随机初始化匹配关系，即A中每个点的偏移量。 Propagation： 根据匹配程度，将每个点的偏移量传播到周围的点。实际实现是，对于某个点(x,y)，使用其周围点的偏移量还是自己的偏移量得到匹配点，计算匹配程度，取匹配程度最好的偏移量作为当前点的偏移量。 Random search： 为了进一步优化匹配结果，我们在前一步得到的偏移量基础上，我们再随机的做一些变化，检查匹配点周围是否有更好的匹配点。   解读：\n 随机初始化在点很多的时候，我们有很大几率会得到不少还不错的匹配，这些正确匹配是后续Propagation的基础。 不加random search性能如何？TODO  应用 #   Coarse-to-Fine Embedded PatchMatch and Multi-Scale Dynamic Aggregation for Reference-based Super-Resolution PatchmatchNet: Learned Multi-View Patchmatch Stereo  "},{"id":40,"href":"/blog/docs/notes/paper/raft/","title":"Raft 阅读笔记","section":"Paper","content":"Created: August, 6, 2021 论文: RAFT: Recurrent All-Pairs Field Transforms for Optical Flow\nCode: https://github.com/princeton-vl/RAFT\n 这篇文章做的是光流估计，简单来说，任务就是输入两张图像$I_1,I_2$，我们需要估计出第二张图像$I_1$每个像素点$(u,v)$相对于第一张图像$I_1$的偏移量$(f^1(u), f^2(v))$。\n$$ I_1 = I_2 + f $$\n这篇文章的思路是这样的：\n 首先使用一个feature encoder  求出flow feature：同时输入img1，img2，得到fmap1，fmap2 求出context feature：只输入img1，得到inp   求出fmap1和fmap2的相似度corr 使用一个RNN迭代的求出flow。  RNN的输入包括一个隐藏状态net，context feature inp，相似度corr，上一步的flow     这里的主要问题是每迭代一次，我们都得到了一个更接近img1的img2，这时候相似度需要重新计算。\n RAFT设计了一个查表的思路，只需要在最开始算一遍即可。它的方法是用新坐标周围的点的flow feature拉成一个向量作为新坐标点的flow特征。\n"},{"id":41,"href":"/blog/docs/gen/reverse_diffusion/","title":"Reverse Time Stochastic Differential Equations for Generative Modelling","section":"AIGC","content":"Created: March, 23, 2023 Originally posted at Reverse Time Stochastic Differential Equations for generative modelling.\n What follows is a derivation of the main result of ‘Reverse-Time Diffusion Equation Models’ by Brian D.O. Anderson (1982). Earlier on this blog we learned that a stochastic differential equation of the form $$ \\begin{align} dX_t = \\mu(X_t, t) dt + \\sigma(X_t, t) dW_t \\end{align} $$\nwith the derivative of Wiener process $W_t$ admits two types of equations, called the forward Kolmogorov or Fokker-Planck equation and the backward Kolmogorov equation. The details of the derivation of the forward and backward Kolmogorov equations via the Kramers-Moyal expansion can be found in the previous blog post. For notational brevity we will use the term $\\mu(x_t)$ for the drift and $\\sigma(x_t)$ as the diffusion parameter and omit the explicit time dependency.\nThe Kolmogorov forward equation is identical to the Fokker Planck equation and states\n $$ \\begin{align} \\partial_t p(x_t) = -\\partial_{x_t} \\left[ \\mu(x_t) p(x_t) \\right] + \\frac{1}{2} \\partial_{x_t}^2 \\left[ \\sigma^2(x_t) \\ p(x_t) \\right]. \\end{align} $$  It describes the evolution of a probability distribution $p(x_t)$ forward in time. We can quite frankly think of it as, for example, a Normal distribution being slowly transformed into an arbitrary complex distribution according to the drift and diffusion parameters $\\mu(x_t)$ and $\\sigma(x_t)$.\nThe Kolmogorov backward equation for $s \\geq t$ is defined as\n $$ \\begin{align} - \\partial_t p(x_s | x_t) = \\mu(x_t) \\ \\partial_{x_t} p(x_s|x_t) + \\frac{1}{2} \\ \\sigma^2(x_t) \\ \\partial_{x_t}^2 p(x_s | x_t) \\end{align} $$  and it basically answers the question how the probability of $x_s$ at a later point in time changes as we change $x_t$ at an earlier point in time. The Kolmogorov backward equation is somewhat confounding with respect to time as we’re taking the partial derivative with respect to the earlier time step $t$ on which we are also coniditoning. But we can think of it as asking ‘How does the probability of $x_s$ at the later point in time $s$ change, as we slowly evolve the probability distribution backwards through time and condition on $x_t$’.\nTaking inspiration from our crude example earlier, the backward equation offers a partial differential equation which we can solve backward in time, which would correspond to evolving the arbitrarily complex distribution backwards to our original Normal distribution. Unfortunately there is no corresponding stochastic differential equation with a drift and diffusion term that describes the evolution of a random variable backwards through time in terms of a stochastic differential equation.\nThis is where the remarkable result from Anderson (1982) comes into play.\nThe granddaddy of all probabilistic equations, Bayes theorem, tells us that a joint distribution can be factorized by conditioning: $p(x_s , x_t) = p(x_s|x_t) p(x_t)$ with the time ordering $t \\leq s$. Why do we invoke the joint probability $p(x_s, x_t)$ we might ask? What we’re trying to achieve is to derive a stochastic differential equation that tells us from what values of $x_t$ we can arrive at $x_s$. We can ask ourselves what the partial differential equation would be that describes the evolution of the joint distribution over time. First multiplying both sides of Bayes theorem with minus one and taking the derivative with respect to time $t$, we obtain via the product rule\n $$ \\begin{align} - \\partial_t p(x_s, x_t) \u0026= - \\partial_t \\left[ p(x_s| x_t) p(x_t) \\right] \\\\ \u0026= \\underbrace{-\\partial_t p(x_s|x_t)}_{\\text{KBE}} p(x_t) - p(x_s | x_t) \\underbrace{\\partial_t p(x_t)}_{\\text{KFE}} \\end{align} $$  into which we can plug in the Kolmogorov forward (KFE) and Kolmogorov backward (KBE) equations,\n $$ \\begin{align} \u0026 -\\partial_t p(x_s|x_t) p(x_t) - p(x_s | x_t) \\partial_t p(x_t) \\\\ \u0026= \\left( \\mu(x_t) \\ \\partial_{x_t} p(x_s|x_t) + \\frac{1}{2} \\ \\sigma^2(x_t) \\ \\partial_{x_t}^2 p(x_s | x_t) \\right) p(x_t) \\\\ \u0026 + p(x_s| x_t) \\left( \\partial_{x_t} \\left[ \\mu(x_t) p(x_t) \\right] - \\frac{1}{2} \\partial_{x_t}^2 \\left[ \\sigma^2(x_t) \\ p(x_t) \\right] \\right) \\end{align} $$  The derivative occuring in the backward Kolmogorov equation are\n $$ \\begin{align} \\partial_{x_t} p(x_s|x_t) \u0026= \\partial_{x_t} \\left[ \\frac{p(x_s, x_t)}{p(x_t)} \\right] \\\\ \u0026 = \\frac{\\partial_{x_t} p(x_s, x_t) p(x_t) - p(x_s, x_t) \\partial_{x_t} p(x_t)}{p^2(x_t)} \\\\ \u0026 = \\frac{\\partial_{x_t} p(x_s, x_t)}{p(x_t)} - \\frac{p(x_s, x_t) \\partial_{x_t} p(x_t)}{p^2(x_t)} \\end{align} $$  The next step is to evaluate the derivative of the products in the forward Kolmogorov equation.\n $$ \\begin{align} \\partial_{x_t} \\left[ \\mu(x_t) p(x_t) \\right] \u0026 = \\partial_{x_t} \\mu(x_t) \\ p(x_t) + \\mu(x_t) \\ \\partial_{x_t} p(x_t) \\\\ \\partial_{x_t}^2 \\left[ \\sigma^2(x_t) \\ p(x_t) \\right] \u0026 = \\partial_{x_t}^2 \\sigma^2(x_t) \\ p(x_t) + 2 \\ \\partial_{x_t} \\sigma^2(x_t) \\ \\partial_{x_t} p(x_t) + \\sigma^2(x_t) \\ \\partial_{x_t}^2 p(x_t) \\end{align} $$  Substituting the derivatives of the probability distributions accordingly we obtain\n $$ \\begin{align} - \\partial_t p(x_s, x_t) = \u0026 - \\partial_t \\left[ p(x_s| x_t) p(x_t) \\right] \\\\ = \u0026 -\\partial_t p(x_s|x_t) p(x_t) - p(x_s | x_t) \\partial_t p(x_t) \\\\ = \u0026 \\left( \\mu(x_t) \\ \\partial_{x_t} p(x_s|x_t) + \\frac{1}{2} \\ \\sigma^2(x_t) \\ \\partial_{x_t}^2 p(x_s | x_t) \\right) p(x_t) \\\\ \u0026 + p(x_s| x_t) \\left( \\partial_{x_t} \\left[ \\mu(x_t) p(x_t) \\right] - \\frac{1}{2} \\partial_{x_t}^2 \\left[ \\sigma^2(x_t) \\ p(x_t) \\right] \\right) \\\\ = \u0026 \\mu(x_t) \\ \\partial_{x_t} p(x_s|x_t) \\ p(x_t) + \\frac{1}{2} \\ \\sigma^2(x_t) \\ \\partial_{x_t}^2 p(x_s | x_t) \\ p(x_t) \\\\ \u0026 + p(x_s| x_t) \\partial_{x_t} \\mu(x_t) \\ p(x_t) + p(x_s| x_t) \\mu(x_t) \\ \\partial_{x_t} p(x_t) \\\\ \u0026 - \\frac{1}{2} p(x_s| x_t) \\partial_{x_t}^2 \\left[ \\sigma^2(x_t) \\ p(x_t) \\right] \\\\ = \u0026 \\mu(x_t) \\ \\left(\\frac{\\partial_{x_t} p(x_s, x_t)}{\\cancel{p(x_t)}} - \\frac{p(x_s, x_t) \\partial_{x_t} p(x_t)}{p^{\\cancel{2}}(x_t)} \\right) \\ \\cancel{p(x_t)} \\\\ \u0026 + p(x_s| x_t) \\partial_{x_t} \\mu(x_t) \\ p(x_t) + p(x_s| x_t) \\mu(x_t) \\ \\partial_{x_t} p(x_t) \\\\ \u0026 + \\frac{1}{2} \\ \\sigma^2(x_t) \\ \\partial_{x_t}^2 p(x_s | x_t) \\ p(x_t) - \\frac{1}{2} p(x_s| x_t) \\partial_{x_t}^2 \\left[ \\sigma^2(x_t) \\ p(x_t) \\right] \\\\ = \u0026 \\mu(x_t) \\ \\left(\\partial_{x_t} p(x_s, x_t) - \\frac{p(x_s, x_t) \\partial_{x_t} p(x_t)}{p(x_t)} \\right) \\\\ \u0026 + p(x_s| x_t) \\partial_{x_t} \\mu(x_t) \\ p(x_t) + p(x_s| x_t) \\mu(x_t) \\ \\partial_{x_t} p(x_t) \\\\ \u0026 + \\frac{1}{2} \\ \\sigma^2(x_t) \\ \\partial_{x_t}^2 p(x_s | x_t) \\ p(x_t) - \\frac{1}{2} p(x_s| x_t) \\partial_{x_t}^2 \\left[ \\sigma^2(x_t) \\ p(x_t) \\right] \\\\ = \u0026 \\mu(x_t) \\ \\left(\\partial_{x_t} p(x_s, x_t) - \\cancel{p(x_s| x_t) \\partial_{x_t} p(x_t)} \\right) \\\\ \u0026 + p(x_s, x_t) \\partial_{x_t} \\mu(x_t) + \\cancel{p(x_s| x_t) \\mu(x_t) \\ \\partial_{x_t} p(x_t)} \\\\ \u0026 + \\frac{1}{2} \\ \\sigma^2(x_t) \\ \\partial_{x_t}^2 p(x_s | x_t) \\ p(x_t) - \\frac{1}{2} p(x_s| x_t) \\partial_{x_t}^2 \\left[ \\sigma^2(x_t) \\ p(x_t) \\right] \\\\ = \u0026 \\underbrace{\\mu(x_t) \\ \\partial_{x_t} p(x_s, x_t) + p(x_s, x_t) \\partial_{x_t} \\mu(x_t)}_{\\text{product rule}} \\\\ \u0026 + \\frac{1}{2} \\ \\sigma^2(x_t) \\ \\partial_{x_t}^2 p(x_s | x_t) \\ p(x_t) - \\frac{1}{2} p(x_s| x_t) \\partial_{x_t}^2 \\left[ \\sigma^2(x_t) \\ p(x_t) \\right] \\\\ = \u0026 \\partial_{x_t} \\left[ \\mu(x_t) \\ p(x_s, x_t) \\right] \\\\ \u0026 + \\underbrace{\\frac{1}{2} \\ \\sigma^2(x_t) \\ \\partial_{x_t}^2 p(x_s | x_t) \\ p(x_t)}_{(1)} - \\underbrace{\\frac{1}{2} p(x_s| x_t) \\partial_{x_t}^2 \\left[ \\sigma^2(x_t) \\ p(x_t) \\right]}_{(2)} \\end{align} $$  In order to transform the partial differential equation above into a form from which we can deduce an equivalent stochastic differential equation, we match the terms of the second order derivatives with the following identity,\n $$ \\begin{align} \u0026 \\frac{1}{2} \\partial_{x_t}^2 \\left[ p(x_s, x_t) \\sigma^2(x_t) \\right] \\\\ = \u0026 \\frac{1}{2} \\partial_{x_t}^2 \\left[ p(x_s | x_t) p(x_t) \\sigma^2(x_t) \\right] \\\\ = \u0026 \\frac{1}{2} \\partial_{x_t}^2 p(x_s | x_t) p(x_t) \\sigma^2(x_t) + \\partial_{x_t} \\left[ p(x_t) \\sigma^2(x_t) \\right] \\partial_{x_t} p(x_s| x_t) + \\frac{1}{2} \\partial_{x_t}^2 \\left[ p(x_t) \\sigma^2(x_t) \\right] p(x_s| x_t) \\\\ = \u0026 \\underbrace{\\frac{1}{2} \\sigma^2(x_t) \\partial_{x_t}^2 p(x_s | x_t) p(x_t)}_{(1)} + \\partial_{x_t} \\left[ p(x_t) \\sigma^2(x_t) \\right] \\partial_{x_t} p(x_s| x_t) + \\underbrace{\\frac{1}{2} p(x_s| x_t) \\partial_{x_t}^2 \\left[ p(x_t) \\sigma^2(x_t) \\right]}_{(2)} \\end{align} $$  by observing that the terms (1) and (2) occur in both equations. We can see from the expansion of the derivative above that we can combine the terms in our derivation if we expand the “center term”. Furthermore we can employ the identity $-\\frac{1}{2} X = -X + \\frac{1}{2} X$ to obtain\n $$ \\begin{align} -\\partial_t p(x_s, x_t) = \u0026 \\partial_{x_t} \\left[ \\mu(x_t) \\ p(x_s, x_t) \\right] \\\\ \u0026 + \\frac{1}{2} \\ \\sigma^2(x_t) \\ \\partial_{x_t}^2 p(x_s | x_t) \\ p(x_t) - \\frac{1}{2} p(x_s| x_t) \\partial_{x_t}^2 \\left[ \\sigma^2(x_t) \\ p(x_t) \\right] \\\\ = \u0026 \\partial_{x_t} \\left[ \\mu(x_t) \\ p(x_s, x_t) \\right] \\\\ \u0026 + \\frac{1}{2} \\ \\sigma^2(x_t) \\ p(x_t) \\ \\partial_{x_t}^2 p(x_s | x_t) \\underbrace{ - \\frac{1}{2} p(x_s| x_t) \\partial_{x_t}^2 \\left[ \\sigma^2(x_t) \\ p(x_t) \\right] }_{-\\frac{1}{2} X = -X + \\frac{1}{2} X} \\\\ \u0026 \\underbrace{\\pm \\partial_{x_t} p(x_s | x_t) \\partial_{x_t} \\left[ p(x_t) \\sigma^2(x_t) \\right]}_{\\text{complete the square}} \\\\ = \u0026 \\partial_{x_t} \\left[ \\mu(x_t) \\ p(x_s, x_t) \\right] \\textcolor{red}{+ \\frac{1}{2} \\ \\sigma^2(x_t) \\ \\partial_{x_t}^2 p(x_s | x_t) \\ p(x_t)} \\\\ \u0026 \\underbrace{ - p(x_s| x_t) \\partial_{x_t}^2 \\left[ \\sigma^2(x_t) \\ p(x_t) \\right] + \\textcolor{red}{\\frac{1}{2} p(x_s| x_t) \\partial_{x_t}^2 \\left[ \\sigma^2(x_t) \\ p(x_t) \\right]} }_{-\\frac{1}{2} X = -X + \\frac{1}{2} X} \\\\ \u0026 \\textcolor{red}{\\pm \\partial_{x_t} p(x_s | x_t) \\partial_{x_t} \\left[ p(x_t) \\sigma^2(x_t) \\right]} \\\\ = \u0026 \\partial_{x_t} \\left[ \\mu(x_t) \\ p(x_s, x_t) \\right] + \\textcolor{red}{\\frac{1}{2} \\partial_{x_t}^2 \\left[ p( x_s | x_t) p(x_t) \\sigma^2(x_t) \\right]} \\\\ \u0026 \\underbrace{- p(x_s| x_t) \\partial_{x_t}^2 \\left[ \\sigma^2(x_t) \\ p(x_t) \\right] - \\partial_{x_t} p(x_s | x_t) \\partial_{x_t} \\left[ p(x_t) \\sigma^2(x_t) \\right]}_{ - \\partial_{x_t} \\left[ p(x_s| x_t) \\partial_{x_t} \\left[ \\sigma^2(x_t) \\ p(x_t) \\right] \\right] \\text{ (product rule) } } \\\\ = \u0026 \\partial_{x_t} \\left[ \\mu(x_t) \\ p(x_s, x_t) \\right] + \\frac{1}{2} \\partial_{x_t}^2 \\left[ p( x_s , x_t) \\sigma^2(x_t) \\right] \\\\ \u0026 - \\partial_{x_t} \\left[ p(x_s| x_t) \\partial_{x_t} \\left[ \\sigma^2(x_t) \\ p(x_t) \\right] \\right]. \\end{align} $$  the result of which is in the form of a Kolmogorov forward equation, although using the joint probability distribution $p(x_s, x_t)$. For the time ordering of $t \\leq s$, we can observe that the term $-\\partial_t p(x_s, x_t)$ describes the change of the probability distribution as we move backward in time. In accordance with Leibniz’ rule we can marginalize over $x_s$ without interferring with the partial derivative $\\partial_t$, to obtain\n $$ \\begin{align} -\\partial_t p(x_t) = \u0026 -\\partial_{x_t} \\left[ p(x_t) \\left( -\\mu(x_t) + \\frac{1}{p(x_t)} \\partial_{x_t} \\left[ \\sigma^2(x_t) \\ p(x_t) \\right] \\right) \\right] \\\\ \u0026 + \\frac{1}{2} \\partial_{x_t}^2 \\left[ p(x_t) \\sigma^2(x_t) \\right] \\\\ \\end{align} $$  and introduce the time reversal $\\tau \\doteq 1 - t$ which, with respect to the integration with respect to the flow of time, yields\n $$ \\begin{align} - \\partial_t p(x_t) = \u0026 \\partial_\\tau p(x_{1-\\tau}) \\\\ = \u0026 -\\partial_{x_{1-\\tau}} \\left[ p(x_{1-\\tau}) \\left( -\\mu(x_{1-\\tau}) + \\frac{1}{p(x_{1-\\tau})} \\partial_{x_{1-\\tau}} \\left[ \\sigma^2(x_{1-\\tau}) \\ p(x_{1-\\tau}) \\right] \\right) \\right] \\\\ \u0026 + \\frac{1}{2} \\partial_{x_{1-\\tau}}^2 \\left[ p(x_{1-\\tau}) \\sigma^2(x_{1-\\tau}) \\right] \\end{align} $$  which finally gives us a stochastic differential equation analogous to the Fokker-Planck/forward Kolmogorov equation that we can solve backward in time:\n $$ \\begin{align} dX_\\tau = \\left(-\\mu(x_{1-\\tau}) + \\frac{1}{p(x_{1-\\tau})} \\partial_{x_{1-\\tau}} \\left[ \\sigma^2(x_{1-\\tau}) \\ p(x_{1-\\tau}) \\right] \\right) d\\tau + \\sigma(x_{1-\\tau}) dW_\\tau \\end{align} $$  where $\\tilde{W}_t$ is a Wiener process that flows backward in time.\nBy keeping the $\\sigma^2(x_t)$ constant and independent of $x_t$ and applying the log-derivative trick, the drift simplifies to\n $$ \\begin{align} dX_\\tau \u0026 = \\Big(-\\mu(x_{1-\\tau}) + \\frac{1}{p(x_{1-\\tau})} \\partial_{x_{1-\\tau}} \\big[ \\overbrace{\\sigma^2(x_{1-\\tau})}^{=\\sigma^2} \\ p(x_{1-\\tau}) \\big] \\Big) d\\tau + \\sigma(x_{1-\\tau}) dW_\\tau \\\\ \u0026 =\\left(-\\mu(x_{1-\\tau}) + \\frac{\\sigma^2}{p(x_{1-\\tau})} \\partial_{x_{1-\\tau}} \\ p(x_{1-\\tau}) \\right) d\\tau + \\sigma(x_{1-\\tau}) dW_\\tau \\\\ \u0026= \\Big(-\\mu(x_{1-\\tau}) + \\sigma^2 \\partial_{x_{1-\\tau}} \\ \\log p(x_{1-\\tau}) \\Big) dt + \\sigma(x_{1-\\tau}) d\\tilde{W}_\\tau \\end{align} $$  "},{"id":42,"href":"/blog/docs/gen/sde/","title":"Stochastic Differential Equations","section":"AIGC","content":"Created: March, 23, 2023  A Wiener twist to differential equations\n Non-Differential Equations #  Most of us are quite familiar with linear and non-linear equations from our 101 math classes and lectures. These equations define an equality between the two terms left and right of the equal sign: $$ \\begin{align} y = f(x) \\end{align} $$\nThese functions assert an equality between $y$ and $x$ through the function $f(\\cdot)$ and describe a \u0026ldquo;static\u0026rdquo; relationship between a value $x$ and its corresponding value $y$. Examples of these functions are numerous and we can list a couple of them here:\n Linear equations: $y = A x + b$ Exponential equations: $y = e^x$ Polynomials: $y = \\sum_{k=0}^n a_k x^k$ Trigonometric equations: $y = \\sin(x)$ and the list goes on and on \u0026hellip;  All the equations above share the characteristic that they equate two separate values $y$ and $f(x)$.\nDifferential Equations #  As you can guess from the title there is another important class of equations: differential equations. These equations relate one or more functions to their derivatives. Mathematically this looks like the following: $$ \\begin{align} \\underbrace{\\frac{d y}{dx}}_{\\text{derivative}} = f(x) \\end{align} $$\nAs we can see from above the one thing that changed to our earlier, non-differential equation is the derivative. Instead of telling us what the value $y$ is given the function $f(x)$ as in the case of non-differential equations, the differential equation above tells us the change of $y$ with respect to $x$. In plain English, it tells us how much $y$ changes if we change $x$ by simply evaluating the function $f(x)$.\nNaturally, the question arises where we ask ourselves what the heck do these equations tell us. In non-differential equations, the relationship between input to a function and output is quite straight forward.\nI struggled for quite some time to arrive at an intuitive interpretation of what differential equations actually represent. Fortunately, one field where differential equations pop up en masse is physics (which apart from quantum physics tends to be quite intuitive for humans). So we\u0026rsquo;ll make a detour through physics to keep the intuition alive while diving into differential equations.\nDifferential equations are often employed in physics when a physical system is most accurately described through its instantaneous change in time. It should be noted that the differential could be defined with respect to any argument of the function $f(\\cdot)$, but in physics the time differential $d / dt$ is often the differential of interest as we want to predict things into the future. In the simplest case, a physical object $x(t)$ moves through time and space according to some function:\n $$ \\begin{align} \\underbrace{\\frac{d}{dt} \\ x(t)}_{\\text{change over time}} = \\underbrace{f(t, x(t))}_{\\text{value of change}} \\quad \\cong \\quad f(x(t)) \\end{align} $$  The equation above simply states that the change over time, $d x(t) / dt$ is equivalent to the function $f(t, x(t))$. Mathematically, we require the time $t$ to appear in the function $f(t, x(t))$ since otherwise the time derivative wouldn\u0026rsquo;t exist. For a more intuitive notation we can drop it and equate the change $d/dt x(t)$ with the function $f( \\cdot )$ with the \u0026lsquo;essentially the same\u0026rsquo; symbol $\\cong$.\nWe can write the differential equation in a shorter way by using the infinitesimal differential by pulling $dt$ over to the other side: $$ \\begin{align} dx(t) = f(t, x(t)) dt \\end{align} $$\nwhich simply states that a \u0026ldquo;super small\u0026rdquo; change $dx(t)$ in $x(t)$ corresponds to function $f(t, x(t))$ \u0026ldquo;scaled\u0026rdquo; by the \u0026ldquo;super small\u0026rdquo; time difference $dt$.\nBelow is an image juxtaposing what we refer to as non-differential equations and a differential equations with respect to time:\n {: .align=\u0026ldquo;center\u0026rdquo; height=\u0026ldquo;50%\u0026rdquo; width=\u0026ldquo;100%\u0026quot;}\nInstead of working with a \u0026ldquo;absolute\u0026rdquo; equation as shown on the left side, the differential equation on the right gives us the change $dx(t)$ for any point $x(t)$ at any point in time $t$ (which is mathematically a vector field). Each arrow in the right plot is an evaluation of the differential equation $dx(t)$ at a specific point $x(t)$ at a specific point in time $t$.\nA more intuitive example of the right hand plot above is the temperature of a hot coffee mug. The hotter the coffee mug, the larger the temperature gradient between coffee mug and the surrounding. So the larger the gradient the more temperature (thermal energy) is passed off into the environment of the hot coffee mug, ergo the temperature decrease is faster for coffee mugs with high temperatures. (To be frank, this is not the most physically correct way of how energy behaves, but this is just for an intuitive visualization.)\nThe grey lines in in the right plot model the changing temperatures over time of three coffee mugs with different temperatures. We model the thermal energy dissipation through a (ordinary) differential equation and would like to know what the temperature of the three coffee mugs will be at a later point in time. Computing the later temperature amounts to \u0026ldquo;little more\u0026rdquo; than following the arrows. These arrows are computed through the differential equation and tell us what the temperature change $dx(t)$ is for a mug with a specific temperature $x(t)$ at time $t$.\nOn a side note: Notice how the arrows don\u0026rsquo;t change in their direction and magnitude for a specific value $x(t)$ while we progress in time. This signals that $dx(t)$ doesn\u0026rsquo;t actually use $t$ to compute the change in temperature.\nThe way we solve differential equations is to start at some initial point $x(0)$ and add up all the temperature changes $dx(t)$ that the hot coffee mug is exposed to over time. Mathematically, this amounts to little more than: $$ \\begin{align} x(T) = x(0) + \\underbrace{\\int_{t=0}^T dx(t)}_{\\text{sum up all the changes}} \\end{align} $$\nthe solution of which is shown as the grey line in the right plot.\nAnother analogy would be kicking a soccer ball over a soccer field. The ball starts somewhere $x(0)$ and you kick it repeatedly in some direction (adding $dx(t)$ repeatedly). Each kick changes the location of the soccer ball and results in the ball lying in a new position $x(t)$. After we kicked the soccer ball about the soccer field enough, we\u0026rsquo;ll finally leave it at $x(T)$.\nUnfortunately, computers can\u0026rsquo;t really work with infinitesimal small number like $dx(t)$ or $dt$ since numbers in computers are stored with a finite amount of bits. As so often, the (approximate) solution is to discretize the changes to very small, yet still representable values of $\\Delta x(t)$ and $\\Delta t$: $$ \\begin{align} x(T) \u0026amp;= x(0) + \\underbrace{\\int_{t=0}^T dx(t)}{\\text{sum up all the changes}} \\ \u0026amp; \\underbrace{\\approx}{\\text{discretize}} x(0) + \\sum_{t=0}^T \\Delta x(t) \\end{align} $$\nwhere $t$ is some finite partition of time into discrete values.\nIt turns out that the integral above (and its respective discrete approximation) is all we need to solve (ordinary) differential equations. More importantly it\u0026rsquo;s all we need to get a basic understanding of stochastic differential equations. But before we can proceed to stochastic differential equations, we have to talk above stochasticity over time.\nEnter Wiener processes \u0026hellip;\nWiener Process #  In order to understand Wiener processes we need to think about the position of a particle in an Euclidean space that moves purely randomly. The question is how we could model such a particle.\nThe first idea would be to determine that at any point in time the particle has the tendency to move randomly in space. Therefore it does not jiggle and bounce at discrete time steps but will always move an infinitesimally small distance $dx(t)$ in a random direction $\\epsilon$ for any infinitesimally short period of time $dt$.\nVisually we want the random moving particle looking something like this in two dimensions:\n {: .align=\u0026ldquo;center\u0026rdquo; height=\u0026ldquo;50%\u0026rdquo; width=\u0026ldquo;50%\u0026quot;}\nWe can thus proclaim the following, somewhat un-mathematical property of this rambunctious little particle: $$ \\begin{align} \\underbrace{dx_t}{\\text{change in space}} = \\overbrace{\\epsilon}^{\\text{random move}} \\underbrace{\u0026ldquo;dt\u0026rdquo;}{\\text{some change in time}} \\end{align} $$\nThere are a couple of things to observe here:\n First we introduced a random variable $\\epsilon$ which follows some probability distribution. Secondly, through the infinitesimal differentials on both sides we equated the random move in space with the duration of the movement just like in a differential equation. Thirdly, the infinitesimal movements of $x_t$ through time are completely independent since $\\epsilon$ is sampled uncorrelated through time.  It turns out that if we choose the random movements $\\epsilon$ and the change in time $\u0026ldquo;dt\u0026rdquo;$ smartly, we can derive convenient theoretical properties about the movement of the little random particle $x_t$.\nSince $\\epsilon$ is a random variable at any point in time, the position of $x_t$ will never be predictable with absolute certainty. Instead we have to treat the position of the particle $x_t$ itself as a random variable, the behavior of which is governed by the differential equation above.\nFirst up is the choice of $\\epsilon$. The usage of the Normal distribution $\\mathcal{N}(\\mu, \\sigma)$ is prevalent in a lot of modelling approaches due to the convergence of sequences of random variables and it furthermore has nice theoretical properties. For that reason we will model the probability of the random movement $\\epsilon$ with a standard normal distribution, namely $\\epsilon \\sim \\mathcal{N}(0,1)$.\nSecondly we will chose the \u0026ldquo;amount of time $dt$\u0026rdquo; to actually be $\\sqrt{dt}$, the reason of which will be clear in an instant.\nThirdly, we want to particle to start at zero, so $x_0 = 0$.\nGiven these modelling assumptions, we are interested where the particle could turn up at a later point in time, so we want to know what $x_T$ is: $$ \\begin{align} x_T \u0026amp;= x_0 + \\int_{t=0}^T dx_t \\ \u0026amp;= \\underbrace{x_0}{\\text{$=0$}} + \\int{t=0}^T \\epsilon \\sqrt{dt} \\ \u0026amp;= \\int_{t=0}^T \\epsilon \\sqrt{dt} \\end{align} $$\nBut since $\\epsilon$ is a random variable we actually have to treat the position of the particle at $x_T$ as a random variable. The most that we can do is thus to treat $x_T$ as a probability distribution for which we can compute the first two moments, the mean and the variance: $$ \\begin{align} \\mathbb{E}\\left[ x_T \\right] \u0026amp;= \\mathbb{E}\\left[\\int_{t=0}^T dx_t \\right] \\ \u0026amp;= \\int_{t=0}^T \\underbrace{\\mathbb{E}\\left[ \\epsilon \\right]}_{\\mathcal{N}(0,1)} \\sqrt{dt} \\ \u0026amp;= 0 \\end{align} $$\nand $$ \\begin{align} \\mathbb{V}\\left[ x_T \\right] \u0026amp;= \\mathbb{V}\\left[\\int_{t=0}^T dx_t \\right] \\ \u0026amp;= \\int_{t=0}^T \\underbrace{\\mathbb{V}\\left[ \\epsilon \\sqrt{dt} \\right]}{\\mathbb{V}[a X] = a^2 \\mathbb{V}[X]} \\ \u0026amp;= \\int{t=0}^T dt \\underbrace{\\mathbb{V}\\left[ \\epsilon \\right]}{\\epsilon \\sim \\mathcal{N}(0,1)} \\ \u0026amp;= \\int{t=0}^T dt \\ \u0026amp;= T \\end{align} $$\nWe can validate the properties of the Wiener process experimentally through what a good friend of mine calls \u0026ldquo;computational evidence\u0026rdquo;:\n {: .align=\u0026ldquo;center\u0026rdquo; height=\u0026ldquo;50%\u0026rdquo; width=\u0026ldquo;50%\u0026quot;}\nwith the following code\nT = 1000 dt = 1 MC = 200 mu = 0.0 sigma = 0.1 def drift(x, mu, dt): return mu*dt def diffusion(x, sigma, dt): return sigma * dt**0.5*np.random.randn(*x.shape) # start at zero x = [np.zeros(MC)] # simulate Brownian Motion in parallel for _ in range(T): x.append(x[-1]+drift(x[-1], mu, dt) + diffusion(x[-1], sigma, dt)) x = np.array(x) fig = plt.figure(1) ax = fig.add_subplot(111) # plot all the trajectories _ = ax.plot(x, color=\u0026#39;red\u0026#39;, alpha=0.1) # compute the analytical means and variances of the Brownian Motion analytic_var = np.arange(0,T)*dt*sigma**2 analytic_std = analytic_var**0.5 analytic_mean = np.arange(0,T)*dt*mu # compute the empirical mean and variance from the sampled Brownian Motion empiric_var = x.var(axis=1) empiric_std = empiric_var**0.5 empiric_mean = x.mean(axis=1) ax.plot(empiric_mean + 3*empiric_std, ls=\u0026#39;--\u0026#39;, color=\u0026#39;red\u0026#39;) ax.plot(empiric_mean - 3*empiric_std, ls=\u0026#39;--\u0026#39;, color=\u0026#39;red\u0026#39;) ax.plot(x.mean(axis=1), ls=\u0026#39;-.\u0026#39;, color=\u0026#39;red\u0026#39;) ax.fill_between(x=np.arange(0,T),y1=analytic_mean+3*analytic_std, y2=analytic_mean+-3*analytic_std, color=\u0026#39;gray\u0026#39;, alpha=0.1) plt.plot(analytic_mean, color=\u0026#39;gray\u0026#39;, ls=\u0026#39;-.\u0026#39;) ax.grid(True) ax.set_xlim(-20,100) ax.set_ylim(-4,4) ax.set_xticklabels([],[]) ax.set_yticklabels([],[]) plt.show() We can observe both the sampled mean and the variance (in red) of our 100 Wiener processes match the expected mean and variance (in gray) up to the noise that we introduce through sampling. Basically all the paths stay around zero where they start and they spread out according to our analytical computed variance of $\\mathbb{V}[x_t] = t$ over time.\nSince we chose $\\epsilon$ and $\u0026ldquo;dt\u0026rdquo;$ smartly, we arrive at quite succinct definitions for the mean and variance of this random variable $x_T$. In fact, this specific kind of stochastic process has a specific name. By choosing the random movement $\\epsilon \\sim \\mathcal{N}(0,1)$, the starting value $x_0=0$ and the time differential $\\sqrt{dt}$ we have defined our little, rambunctious particle to follow a Wiener process which is a specific kind of stochastic process. The defining properties of a Wiener process $W_t$ ( $W_t$ being the common notation of a Wiener process) that describes the infinitesimal movement of a particle through $dx_t = \\epsilon \\sqrt{dt}$ are the following:\n  $W_0 = 0$ \\ This means that the Wiener process always starts at zero.\n  Independent increments: $\\mathbb{C}[W_{t+u} - W_s, W_s] =0$ for $u \\geq 0$ and $s \\leq t$ \\ Increments (the movement of the Wiener process) are independent from the past movements. $\\mathbb{C}[\\cdot , \\cdot ]$ is the covariance between two random variables.\n  Gaussian increments: $W_{t+u} - W_t \\sim \\mathcal{N}(0, u)$ \\ The difference between any two realizations is Gaussian distributed accordingly to the time difference between these two realizations.\n  Continuous paths in time $t$.\\ We can basically zoom infinitely far into the movements on the time axis and we will never find a discontinuous jump. Yet, due to it being a stochastic process it turns out that the Wiener process is not differentiable.\n  In order to be all set up for the final chapter of this post, we will define an infinitesimal version of the Gaussian increment property of the Wiener process: $$ \\begin{align} W_{t+u} - W_t \\sim \\mathcal{N}(0, u) \\quad \\Leftrightarrow \\quad dW_t \\sim \\mathcal{N}(0,dt) \\end{align} $$\nStochastic Differential Equations (= Differential Equations + Wiener Processes) #  Once we understood differential equations and Wiener processes, we\u0026rsquo;ll realize that (basic) stochastic differential equations are just the combination of the two. We can thus define a stochastic differential equation as $$ \\begin{align} \\underbrace{dX_t}{\\text{total change}} = \\underbrace{\\mu_t dt}{\\text{deterministic}} + \\underbrace{\\sigma_t dW_t}_{\\text{stochastic}} \\end{align} $$\nwhich defines the infinitesimal change in the random variable $X_t$ at time $t$ as the combination of a deterministic change $\\mu_t dt$ and a scaled Wiener process $\\sigma_t dW_t \\sim \\mathcal{N}(0,\\sigma_t^2 dt)$.\nWith a constant drift, this looks something like this:\n {: .align=\u0026ldquo;center\u0026rdquo; height=\u0026ldquo;50%\u0026rdquo; width=\u0026ldquo;50%\u0026quot;}\nthrough\nT = 1000 dt = 1 MC = 200 mu = 0.1 sigma = 0.1 def drift(x, mu, dt): return mu*dt def diffusion(x, sigma, dt): return sigma * dt**0.5*np.random.randn(*x.shape) # start at zero x = [np.zeros(MC)] # simulate Brownian Motion in parallel for _ in range(T): x.append(x[-1]+drift(x[-1], mu, dt) + diffusion(x[-1], sigma, dt)) x = np.array(x) fig = plt.figure(1) ax = fig.add_subplot(111) # plot all the trajectories _ = ax.plot(x, color=\u0026#39;red\u0026#39;, alpha=0.1) # compute the analytical means and variances of the Brownian Motion analytic_var = np.arange(0,T)*dt*sigma**2 analytic_std = analytic_var**0.5 analytic_mean = np.arange(0,T)*dt*mu # compute the empirical mean and variance from the sampled Brownian Motion empiric_var = x.var(axis=1) empiric_std = empiric_var**0.5 empiric_mean = x.mean(axis=1) ax.plot(empiric_mean + 3*empiric_std, ls=\u0026#39;--\u0026#39;, color=\u0026#39;red\u0026#39;) ax.plot(empiric_mean - 3*empiric_std, ls=\u0026#39;--\u0026#39;, color=\u0026#39;red\u0026#39;) ax.plot(x.mean(axis=1), ls=\u0026#39;-.\u0026#39;, color=\u0026#39;red\u0026#39;) ax.fill_between(x=np.arange(0,T),y1=analytic_mean+3*analytic_std, y2=analytic_mean+-3*analytic_std, color=\u0026#39;gray\u0026#39;, alpha=0.1) plt.plot(analytic_mean, color=\u0026#39;gray\u0026#39;, ls=\u0026#39;-.\u0026#39;) ax.grid(True) ax.set_xlim(-20,100) ax.set_ylim(-4,4) ax.set_xticklabels([],[]) ax.set_yticklabels([],[]) plt.show() For such drift-diffusion processes, or more specifically Ito drift-diffusion processes, we can compute the analytical mean and variance of how $X_t$ will be distributed in the future. To keep things simple, we will work with a constant mean $\\mu = \\mu_t$ and diffusion $\\sigma = \\sigma_t$. Solving the SDE amounts to: $$ \\begin{align} X_T \u0026amp;= \\int_{t=0}^T dX_t \\ \u0026amp;= \\int_{t=0}^T \\mu dt + \\sigma dW_t \\ \u0026amp;= \\mu \\int_{t=0}^T dt + \\sigma \\int_{t=0}^T dW_t \\ \u0026amp;= \\mu T + \\sigma \\int_{t=0}^T dW_t \\ \u0026amp;= \\mu T + \\sigma W_T \\ \\end{align} $$\nSimilarly to earlier, the Brownian motion $W_T \\sim \\mathcal{N}(0,T)$ is a random variable, which entices us to compute the mean and variance of the term above: $$ \\begin{align} \\mathbb{E}[X_T] \u0026amp;= \\mathbb{E}[\\mu T + \\sigma W_T] \\ \u0026amp;= \\mu T + \\sigma \\mathbb{E}[W_T] \\ \u0026amp;= \\mu T \\end{align} $$ and $$ \\begin{align} \\mathbb{V}[X_T] \u0026amp;= \\mathbb{V}[\\mu T + \\sigma W_T] \\ \u0026amp;= \\underbrace{\\mathbb{V}[\\mu T]}_{=0} + \\mathbb{V}[\\sigma W_T] \\ \u0026amp;= \\sigma^2 \\mathbb{V}[ W_T] \\ \u0026amp;= \\sigma^2 T \\ \\mathbb{Std}[X_T] \u0026amp;= \\sigma \\sqrt{T} \\end{align} $$\nwhich we were able to validate with our \u0026ldquo;computational evidence\u0026rdquo; in the plot above. The mean increases constantly as time progresses and the standard deviation above and below the mean increases asymptotically due to the $\\sqrt{T}$.\nThis is a fairly simple SDE since we assume that $\\mu_t$ and $\\sigma_t$ are constant in time and do not depend on the value of $X_t$. Things get significantly more interesting when both $\\mu_t$ and $\\sigma_t$ change over time depending on the value of $X_t$ such that we are working with $$ \\begin{align} dX_t = \\mu(t, X_t) dt + \\sigma(t, X_t) dW_t \\end{align} $$\nThe drift $\\mu(t, X_t)$ and $\\sigma(t, X_t)$ can now be potentially highly non-linear and complex functions which could even take in other stochastic processes as additional input. But Ito\u0026rsquo;s lemma, Ornstein-Uhlenbeck processes and Geometric Brownian Motion are topics for another time \u0026hellip;\n"},{"id":43,"href":"/blog/docs/matrix/types/","title":"各种矩阵","section":"Matrix","content":"Created: Decemenber, 1, 2020 对称矩阵 #    定义：满足$A^T=A$的矩阵。 显然，对称矩阵是方阵，否则转一下形状都变了。  对称矩阵的特征值/向量有着很好的性质：\n 实对称矩阵的特征值都是实数。 对称矩阵的特征向量是正交的。没验证，不过应该是不同特征值对应的特征向量一定是正交的，同一个特征值对应的特征向量可能需要Schmidt正交化。  证明 1. 实对称矩阵的特征值都是实数\n已知$Ax = \\lambda x$，左右两边同时取共轭，有\n$$ \\bar{A}\\bar{x}=\\bar{\\lambda}\\bar{x} $$\n因为A是实对称矩阵，$\\bar{A}=A$，因此有 $$ A\\bar{x}=\\bar{\\lambda}\\bar{x} $$\n左右两边同时取转置，有\n$$ \\bar{x}^TA=\\bar{x}^T\\bar{\\lambda} $$\n左右两边同时右乘x，得 $$ \\bar{x}^TAx=\\bar{x}^T\\bar{\\lambda}x $$\n对$Ax = \\lambda x$，左右两边同时左乘$\\bar{x}^T$，得 $$ \\bar{x}^TAx=\\bar{x}^T\\lambda x $$\n比较两个式子，可以得到\n$$ \\bar{\\lambda} = \\lambda $$\n一个数的共轭等于其本身，这个数是实数。\n2. 对称矩阵的特征向量是正交的\n  正定矩阵 #   正定矩阵是对称矩阵的一种特殊情况，因此它也是对称的。\n定义 #  正定矩阵有各种各样的定义，它们互相之间是等价的。下面是几种常见定义/判定方法：\n 所有特征值大于0。 所有顺序主子式都大于0。 所有Pivots都大于0。 $x^TAx\u0026gt;0$ ： $x=[x_1,x_2, \u0026hellip;, x_n]$, 对于所有的非零x恒大于0  类似的可以定义半正定(大于等于0)，负定（小于0），半负定（小于等于0）。\n上述四个定义相关性的不严格证明 考虑第四个定义，我们知道正定矩阵就是二次型的系数矩阵，当二次型要恒大于0，则它必定可以化成一系列平方的和，且每一项的系数都大于0（可以等于0吗？不行，平方项是可以等于0的，如果有一项系数是0，就多了一个自由变量，就可以构造出等于0的x），而化为平方和形式的过程，等价于对A做elimination，平方项的系数就是elimination之后的pivots，里面的系数是elimination过程的L矩阵。\n例：\n  特殊情况 #   $A^TA$必定是半正定矩阵，如果A(m*n矩阵)的秩为n，则必定是正定矩阵。  证明 直观的，这个相当于矩阵形式的平方。我们知道标量，$a^2\u0026gt;0$，对应的，我们可以想象$A^TA$是应该是正定的。\n回忆正定矩阵的四种定义：特征值不知道，pivots不知道，顺序主子式不知道，因此考虑最后一种形式。\n严格证明：\n考虑矩阵$A\\in R^{m\\times n}$\n$$ x^TA^TAx = (Ax)^TAx = ||Ax||^2 \\geq 0 $$\n上式，只有在Ax=0的时候才取0，如果我们希望$A^TA$是正定的，这意味着Ax=0不能有解，而无解的条件是A的列向量线性无关，即A的秩为n。\n  正交矩阵 #   正交矩阵（英语：orthogonal1 matrix）是一个方块矩阵Q，其元素为实数，而且行向量与列向量皆为正交的单位向量。\n 相同行/列向量内积为1 不同行/列向量内积为0  显然，每个行/列向量都不能由其他行/列向量线性表出，因此正交矩阵必定是满秩矩阵。\n行向量正交能否推出列向量正交? 可以，推导如下：\n行向量正交，因此有$AA^T = I$, 对于方阵，有$AB = I \\simeq BA=I$ ( 证明)， 则有$A^TA=I$，则有列向量正交。\n 重要性质 #   正交矩阵的转置矩阵等于其逆矩阵: $A^T = A^{-1}$ 行列式值必定为+1或-1 $$ 1=\\operatorname{det}(I)=\\operatorname{det}\\left(Q^{T} Q\\right)=\\operatorname{det}\\left(Q^{T}\\right) \\operatorname{det}(Q)=(\\operatorname{det}(Q))^{2} \\Rightarrow \\operatorname{det}(Q)=\\pm 1 $$    虽然更完整的说法是orthonormal matrix(标准正交矩阵)，但我们说正交矩阵的时候一般都是指标准正交。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   "},{"id":44,"href":"/blog/docs/matrix/svd/","title":"奇异值分解","section":"Matrix","content":"Created: Decemenber, 1, 2020 所有矩阵都可以分解成：正交矩阵 * 对角矩阵 * 正交矩阵，这个分解叫奇异值分解。\n$$ A = U\\Sigma V^T $$\n其中A是一个m*n的矩阵，V是一个n*n的矩阵，U是一个m*m的矩阵，$\\Sigma$是一个m*n的矩阵。\n在一些特殊情况下，如A是对称矩阵，它的特征向量是正交的，奇异值分解退化为矩阵对角化，设Q是是A的特征向量（列向量）构成的矩阵。则有\n$$ A = U\\Sigma V^T = Q \\Lambda Q^T $$\nIntuition - 几何含义 #   当我们在做奇异值分解的时候，我们实际上是在做什么？\n 在MIT Linear Algebra 第29讲，Strang教授给了我们一个很生动的解释。  详细解释 Revision needed\n考虑两个线性空间$R^n$和$R^m$, 其中$V=[v_1,v_2,\u0026hellip;,v_n]$是$R^n$的一组标准正交基，我们希望对这个基底做一个线性变换得到$R^m$空间的一组基底，这个基底也是正交的。\n这个新基底是$R^m$空间下某个标准正交基乘上某个系数矩阵，用矩阵的语言来说，我们实际有这个等式：\n$$ AV = U\\Sigma $$\n其中A表示线性变换，V是$R^n$的一组标准正交基，U是$R^m$的一组标准正交基，$\\Sigma$是系数对角阵。\n换句话说，对每一个m*n的矩阵，它其实都是其行空间$R^n$和列空间$R^m$某两个正交基底的变换矩阵，奇异值分解其实就要找到这两个基底。\n  求解 #   简单来说：\n V是$A^TA$的特征向量构成的矩阵。 U是$AA^T$的特征向量构成的矩阵。 $\\Sigma$是$A^TA$和$AA^T$的特征值（二者特征值一致）。  详细推导 直接求解下式，并不好求，因为它同时包含很多个未知量。\n$$ A = U\\Sigma V^T $$\n我们知道$A^TA$具有很好的性质，考虑\n$$ A^TA = V\\Sigma^T U^TU\\Sigma V^T = V\\Sigma^T\\Sigma V^T $$\n我们知道$A^TA$是对称矩阵，而对称矩阵的特征向量是正交的，而我们正好要求V是一个正交矩阵！因此，我们知道$A^TA$的特征向量构成的矩阵就是（满足要求，但唯一性需要证明）我们要求的V。$\\Sigma^T\\Sigma$则是$A^TA$的特征值。\n类似的，考虑$AA^T$，我们有\n$$ AA^T = U\\Sigma^T V^TV\\Sigma U^T = U\\Sigma^T\\Sigma U^T $$\n即U是$AA^T$的特征向量构成的矩阵，$\\Sigma^T\\Sigma$则是$AA^T$的特征值。\n我们这时候其实得到了一个附属结论，那就是$AA^T$和$A^TA$的特征值是相同的。     对于复矩阵（酉矩阵），只需要将转置T改成共轭转置H即可。  需要注意的是，并不是任取n个$A^TA$的两两正交单位长的特征向量都可以作为V的列向量。$V_1$和$U_1$必须要满足下面的关系才行:\n$$ V_1 = A^HU_1\\Delta^{-1} $$\n其中$U_1$, $V_1$是非零特征值对应的特征向量组。\n"},{"id":45,"href":"/blog/docs/matrix/road/","title":"如何将各个知识点串起来？","section":"Matrix","content":"Created: Decemenber, 3, 2020 引入 特征值与特征向量之后，我们可以很容易的推导出 矩阵对角化的公式。\n矩阵对角化是针对一般方阵的，对于特殊方阵，如 对称矩阵，矩阵对角化可以进一步特化。\n对称矩阵有很多很好的性质，它是它的进一步特例， 正定矩阵有着更好的性质。\n#  "},{"id":46,"href":"/blog/docs/matrix/misc/","title":"杂七杂八","section":"Matrix","content":"Created: Decemenber, 1, 2020 Quick Look #   酉矩阵: $A^HA=E$ 正规矩阵: $A^HA=AA^H$, 包括对称矩阵，反对称矩阵，Hermite矩阵，反Hermite矩阵，正交矩阵，酉矩阵等。 酉对角化： $A=Q\\Lambda Q^H$, 普通对角化: $A=Q\\Lambda Q^{-1}$ 单纯矩阵：可以对角化的矩阵，即有n个线性无关的特征向量。  线性代数中常见的等价关系 #    singular matrix = 奇异矩阵 = 不可逆矩阵\n  A不可逆 \u0026lt;-\u0026gt;1 Ax = 0 有非零解 \u0026lt;-\u0026gt;2 特征值=0\n  Spectrum #  矩阵中有谱（spectrum）这个概念，例如谱分解，谱范数等等。\n这个谱其实说的就是特征值，特征向量，它是从光学里借过来的说法。光学中光是由各种pure light构成的，光谱就是各个成分的占比。而在矩阵中，矩阵由各个pure的component，特征值特征向量构成。\n进一步来说，我们看矩阵对角化，我们知道任何一个对称矩阵A都可以对角化成$Q\\Lambda Q^{T}$，其中Q为特征向量组成的矩阵。\n我们进一步把这个式子拆开，我们设A的特征向量为\u0008$q_i$, 则\n$$ A = Q\\Lambda Q^{T} = \\lambda_1 q_1 q_1^T + \\lambda_2 q_2 q_2^T + \u0026hellip; + \\lambda_n q_n q_n^T $$\n$q_i$是一个列向量，$q_1 q_1^T$是一个矩阵，因此A实际上就化成了n个矩阵的线性组合，第i个矩阵是$q_i q_i^T$，系数是特征值$\\lambda_i$。\n  A可逆的话，意味着简化阶梯形最后一行不全为0，为了满足Ax=0，x必须等于0。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n TODO\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   "},{"id":47,"href":"/blog/docs/matrix/eigen/","title":"特征值\u0026\u0026特征向量","section":"Matrix","content":"Created: Decemenber, 1, 2020 首先明确一点，特征值和特征向量是针对方阵来说的，我们说某个矩阵A有什么特征值和特征向量时，我们实际上暗示了矩阵A是一个方阵。\n定义 #  任何满足下列条件的标量和向量分别为矩阵A的特征值和特征向量。1\n$$ Ax = \\lambda x $$\nIntuition #  将一个矩阵A与一个向量x相乘，我们实际上在对向量x做一个 线性变换，特征向量实际上就是经过这个变换与原向量仍然平行的那些向量，特征值就是前后两个向量长度的一个比值。\n 显然，零向量满足条件，那它是任何矩阵的特征向量吗？\n不是，我们显示将特征向量定义为非零向量。\n 求解 #  根据定义，有\n$$ (A-\\lambda I)x = 0 $$\n这个等式要有非零解，$(A-\\lambda I)$必须是singular（不可逆）的，特征值要等于0：\n$$ Det(A-\\lambda I) = 0 $$\n于是：\n 求行列式并解方程即可求出特征值。 对于特征向量，我们回代特征值，解$(A-\\lambda I)x=0$这个方程。  因为$(A-\\lambda I)$不可逆，所以解有无穷多个，即特征向量有无穷多个，这时候我们只需要给出一个就行了。    性质 #   $\\sum \\lambda = trace(A)$ : 矩阵A的所有特征值之和等于矩阵A的 trace（对角线元素之和）。 $\\prod \\lambda = det(A)$ : 矩阵A的所有特征值的乘积等于矩阵A的行列式。 三角矩阵的特征值就是对角线上的元素。 对称矩阵的特征向量是正交的。  证明：对称矩阵的特征向量是正交的 To be done     由特征向量的定义，显然A必须要个方阵，若不是，A与x相乘，x维数就变了。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   "},{"id":48,"href":"/blog/docs/matrix/similar/","title":"相似矩阵","section":"Matrix","content":"Created: Decemenber, 7, 2020 满足以下条件的两个矩阵，我们称它们是相似的。\n$$ B = M^{-1}AM $$\n换句话说，如果某个矩阵可以由另一个矩阵左乘一个矩阵再右乘这个矩阵的逆，则称它们是相似的。\nIntuition #  相似的矩阵具有很多相似的属性。\n我们可以把每一个矩阵和其相似的矩阵（们）都想成一个family，这个family里可能有一些矩阵很特殊，通过研究这些特殊的矩阵（通常更为容易），我们可以反推出原矩阵的一些属性。\n 矩阵对角化$\\Lambda = S^{-1}AS$的对角矩阵就是一种特殊的相似矩阵。   性质 #   相似矩阵的特征值是相同的（特征向量可能不同1,但相互独立的数量是相同的）  证明 证明要分两个方向，A的特征值是B的特征值，B的特征值也是A的，由这两者即可得到二者特征值相等。\n对于原矩阵A, 其特征值满足：\n$$ Ax = \\lambda x $$\n对于B：\n$$ (M^{-1}AM)M^{-1}x = M^{-1} \\lambda x = \\lambda M^{-1} x $$ $$ BM^{-1}x = \\lambda M^{-1} x $$\n于是，我们知道A的特征值也是B的特征值，且\u0008B的特征向量是A的特征向量乘以$M^{-1}$。\n反向很容易，把M乘到B那边得到$MBM^{-1} = A$，用类似的方法即可证明。\n     还是一定不同？TODO\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n  "},{"id":49,"href":"/blog/docs/matrix/diagonalization/","title":"矩阵对角化","section":"Matrix","content":"Created: Decemenber, 1, 2020  To be continue.  Keypoint: 一些矩阵可以对角化 $S^{-1}AS = \\Lambda$。其中S为特征向量(列向量)构成的矩阵，$\\Lambda$为特征值构成的对角矩阵。\n 什么样的矩阵可以？ 因为定义里S要可逆，所以A必须拥有n个线性无关的特征向量。   关于矩阵对角化，我们其实可以从两个角度理解：\n 一些矩阵可以对角化$S^{-1}AS = \\Lambda$。 或一些矩阵可以化成三个矩阵的乘积：$A = S\\Lambda S^{-1}$  推导 #   $$ \\begin{equation} \\begin{aligned} AS \u0026= A[x_1, x_2, ..., x_n] = [Ax_1, Ax_2, ..., Ax_n] = [\\lambda_1 x_1, \\lambda_1 x_2, ..., \\lambda_1 x_n] \\\\\\\\\\\\ \u0026= [x_1, x_2, ..., x_n] \\begin{bmatrix} \\lambda_1 \u0026 0 \u0026 \\cdots \u0026 0\\\\ 0 \u0026 \\lambda_2 \u0026 \\cdots \u0026 0\\\\ \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 0 \\\\ 0 \u0026 0 \u0026 0 \u0026 \\lambda_n\\\\ \\end{bmatrix} = S\\Lambda \\end{aligned} \\end{equation} $$  左右两边同时乘S的逆，即可得到：\n$$ S^{-1}AS = \\Lambda $$\n特殊情况 #  当矩阵A是对称矩阵时，其特征向量是正交的1。因此，对角化可以写成\n$$ Q^{T}AQ = \\Lambda $$\n   证明\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   "},{"id":50,"href":"/blog/docs/matrix/space/","title":"线性空间和线性变换","section":"Matrix","content":"Created: Decemenber, 9, 2020 抽象来说，线性空间就是里面元素满足一定运算规律的一个空间。\n具体来说，空间的概念在数学上就是一个集合，空间里的元素就是集合里的元素，线性空间就是里面元素满足一定运算规律的一个集合。\n线性空间 #    符号说明：实数域R，复数域C，统称数域F。\n 线性空间是数域F上满足加法和数乘运算规律的一个集合。具体定义如下：\n TODO  核(零)空间 #   核空间，或者说零空间是针对一个矩阵来说的。对一个矩阵A，它的核空间就是Ax=0的解空间。\n常用 N(A) 来表示，N其实就是英文里Null Space的首字母。\n列空间/值域 #   同样是针对一个矩阵来说的，具体不解释。常用 R(A) 表示。\n向量 #   我们把线性空间里的元素称为向量。\n注意，这里的向量比线性代数里的n元向量含义更广。  概念：\n 线性组合/线性表示 线性相关/无关  基 #   一个线性空间的基，是可以线性表出这个线性空间中其它所有向量的n个线性无关的向量。\n$$ \\alpha = k_1a_1 + k_2a_2 + \u0026hellip; + k_na_n $$\n其中系数称为向量$\\alpha$在这个基下的坐标。\n基变换 #   不同基之间可以进行变换，其中P称为过渡矩阵。\n$$ B = AP $$\n$$ [b_1,b_2,\u0026hellip;,b_n] = [a_1,a_2,\u0026hellip;,a_n]P $$\n坐标变换 #   坐标变换是左乘$P^{-1}$。推导如下\n$$ B\\beta^T = A\\alpha^T $$\n$$ AP\\beta^T = A\\alpha^T $$\n$$ \\beta^T = P^{-1}\\alpha^T $$\n线性子空间 #   线性子空间是线性空间中仍满足线性空间要求的一个子空间。\n特殊的两个子空间：也称这两个子空间为平凡子空间\n 线性空间本身 零空间  生成子空间：写做 span{$a_1, a_2, \u0026hellip;, a_n$}\n交空间：两个子空间的交集，同时存在于两个子空间。\n $$ V_{1} \\cap V_{2}=\\left\\{\\boldsymbol{\\alpha} \\mid \\boldsymbol{\\alpha} \\in V_{1} \\text { 且 } \\boldsymbol{\\alpha} \\in V_{2}\\right\\} $$  和空间：这个空间的向量是两个空间向量的和。这两个子空间有点像是和空间的基底。\n $$ V_{1}+V_{2}=\\left\\{\\boldsymbol{\\alpha}=\\boldsymbol{\\alpha}_{1}+\\boldsymbol{\\alpha}_{2} \\mid \\boldsymbol{\\alpha}_{1} \\in V_{1} \\text { 且 } \\boldsymbol{\\alpha}_{2} \\in V_{2}\\right\\} $$  维数公式：\n$$ \\operatorname{dim} V_{1}+\\operatorname{dim} V_{2}=\\operatorname{dim}\\left(V_{1}+V_{2}\\right)+\\operatorname{dim}\\left(V_{1} \\cap V_{2}\\right) $$\n直和空间：若V1，V2两个子空间没有交集，则它们的和空间称为V1，V2的直和空间。\n补子空间：直和空间为全集的两个子空间互为自己代数补。\n线性映射 #    定义：满足加法和数乘的两个线性空间的映射关系称为线性映射。\n 线性映射前的空间叫原像，后的叫“像”。\n证明线性映射，只需要证明下面两个式子：\n $$ \\begin{array}{l} \\mathcal{A} \\left( \\alpha _{1}+ \\alpha _{2}\\right)= \\mathcal{A} \\left( \\alpha _{1}\\right)+ \\mathcal{A} \\left( \\alpha _{2}\\right) \\\\ \\mathcal{A} \\left(\\lambda \\alpha _{1}\\right)=\\lambda \\mathcal{A} \\left( \\alpha _{1}\\right) \\end{array} $$  性质 #   零元素经过线性映射还是零元素。 一组元素经过线性映射，如果原来线性相关，则之后也线性相关。但是，如果原来线性无关，则之后不一定线性无关。  矩阵表示 #  线性映射可以用矩阵表示，但这之前我们需要将两个线性空间的元素用各自的基底进行表示。\n选取不同的基底，同一个线性映射的矩阵表示就不同。\n注意区分两个概念：\n 基坐标变换：$\\alpha=\\beta A$ 向量坐标变换：$y=Ax$  给定基的情况下给个矩阵都表示一个线性映射。\n不同基底下矩阵表示之间的关系：\n设有两个空间$X,Y$, 两组基底$x_1,y_1$和$x_2,y_2$，\n $Q$是$y_1$到$y_2$的过渡矩阵， $P$是$x_1$到$x_2$之间的过渡矩阵，  则\u0008在$x_1,y_1$下的$A$与在$x_2,y_2$的$B$有如下关系。\n$$ B = Q^{-1}AP $$\n值域\u0026amp;\u0026amp;核 #  值域\n核子空间：线性映射的“零空间“，映射之后为0的元素构成的空间。\n对于一个从n维线性空间v1，映射到m维线性空间v2的线性映射。\n 核子空间核值域的维数之和为n  线性变换 #    同一个空间的线性映射称之为线性变换。\n 矩阵相似, 存在矩阵P，满足：\n$$ B=P^{-1}AP $$\n则称A，B相似。\n两个矩阵相似，意味着它们是不同基底下同一个线性变换的不同矩阵表示。  线性变换本身也可以定义运算, 这些运算和其矩阵表示有着对应关系:\n 乘法: AB 加法: A+B 数乘: kA  特征值\u0026amp;\u0026amp;特征向量 #  矩阵特征值的推广，求还是用线性变换的矩阵表示来求。\n 特征子空间：一个特征值对应的特征向量和零向量构成的一个子空间，称为这个特征值的特征子空间。 代数重复度：每个不同特征值的重复数目称为这个特征值的代数重复度。 几何重复度：一个特征值特征子空间的维数称为这个特征值的几何重复度。  相似对角化 #   n阶矩阵A可对角化的充要条件是A有n个线性无关的特征向量。  注意，并不是什么线性变换存在一个基，使得在这个基下的矩阵表示，呈现对角形。 "},{"id":51,"href":"/blog/posts/algorithms/%E8%B4%AA%E5%BF%83%E7%94%9F%E6%88%90%E6%9C%80%E4%BC%98%E7%BC%96%E7%A0%81%E7%9A%84%E6%80%9D%E8%B7%AF%E5%88%86%E6%9E%90/","title":"贪心生成最优编码的思路分析","section":"Posts","content":"贪心生成最优编码的思路分析 #  目标：求字符编码\n首先得先想到用二叉树表示编码，节点即为字符，边为编码。\n然后优化目标（目标函数）即为： f(x) = w(x)*l(x)\n w(x) 为 字符x的频率 l(x) 为 字符编码的长度  决策目标：巧妙安排二叉树的结构，使得目标函数值最小。\n最优编码树性质一：对于最优编码树，频率最小的两个节点深度最大，且为兄弟。\n证明：\n  深度最大显然，否则深度最大的频率更大，会使得目标函数值增大。\n  若最小的节点有兄弟，且其兄弟不是次小的，则可以让次小的节点与该节点交换，使得目标函数更小。\n  若最小的节点没有兄弟，则可以将该节点与其父亲交换，去掉“父亲”，可以使得目标函数更小。\n  有了这个性质，我们便可以先将两个频率最小的点连起来作兄弟。但为了进一步构造最优编码树，还需要第二个原则。\n最优编码树性质二： 对于最优编码树，删掉频率最小的节点（两个叶子节点），则其父亲变成了叶子结点，另其频率为两孩子频率之和，则新的编码树仍然是最优编码树。\n证明：f1为删之前，f2为删之后目标函数值，最小两个节点为x1,x2, 则有\nf1 = f2 + x1 + x2。\n已知f1最小，则f2也是最小的，否则调整新的编码树使其变为最优编码树，则f1更小，与已知f1最小矛盾。故新编码树也为最优编码树。\n有了这第二个性质，我们已知新的编码树为最优编码树，则根据性质一， 新编码树频率最小的节点为兄弟。递归这个过程，直到所有节点都纳入编码树（叶子节点）。\n例: 将两个频率最小的点连起来作兄弟，然后用这两个点的父亲代替这两个点，求剩余点的最优编码树。\n"}]