<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Introduction on Ze&#39;s Blog</title>
    <link>https://zeqiang-lai.github.io/blog/</link>
    <description>Recent content in Introduction on Ze&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language><atom:link href="https://zeqiang-lai.github.io/blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>DragGAN 抢先体验与本地部署教程</title>
      <link>https://zeqiang-lai.github.io/blog/posts/ai/drag_gan/</link>
      <pubDate>Thu, 25 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/posts/ai/drag_gan/</guid>
      <description>&lt;p&gt;最近风靡全网的DragGAN, 官方代码尚未放出。不过现在已经可以抢先体验啦。&lt;/p&gt;
&lt;p&gt;项目地址&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
  &lt;a href=&#34;https://github.com/Zeqiang-Lai/DragGAN&#34;&gt;Zeqiang-Lai/DragGAN&lt;/a&gt;: 相关代码模型，支持本地部署，Colab在线体验。&lt;/li&gt;
&lt;li&gt;
  &lt;a href=&#34;https://github.com/OpenGVLab/InternGPT&#34;&gt;OpenGVLab/InternGPT&lt;/a&gt;: 可以免费在线体验&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Detr Family for End-to-End Detection</title>
      <link>https://zeqiang-lai.github.io/blog/posts/ai/detr/</link>
      <pubDate>Mon, 27 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/posts/ai/detr/</guid>
      <description>&lt;p&gt;Detr（Detection Transformer）是 facebook 在 2020 年提出的第一个端到端的目标检测模型，
它改变了现有基于 Fast-RCNN 和 YOLO 的目标检测范式，后续有许多工作，基于 Detr 提出了各种个样的改进。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Steepest Descent &amp;&amp; Conjugate Gradient</title>
      <link>https://zeqiang-lai.github.io/blog/posts/ai/sd_cg/</link>
      <pubDate>Mon, 25 Apr 2022 14:32:05 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/posts/ai/sd_cg/</guid>
      <description>&lt;p&gt;这是一篇主要介绍Conjugate Gradient (CG)的笔记，当然为了引入CG，也会一并介绍其“前身” Steepest Descent。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>最短路算法</title>
      <link>https://zeqiang-lai.github.io/blog/posts/algorithms/%E6%9C%80%E7%9F%AD%E8%B7%AF/</link>
      <pubDate>Fri, 11 Feb 2022 13:52:51 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/posts/algorithms/%E6%9C%80%E7%9F%AD%E8%B7%AF/</guid>
      <description>&lt;p&gt;Dijkstra用于求没有负权边的单源最短路。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>快速求最大公约数gcd</title>
      <link>https://zeqiang-lai.github.io/blog/posts/algorithms/gcd/</link>
      <pubDate>Wed, 09 Feb 2022 13:52:51 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/posts/algorithms/gcd/</guid>
      <description>&lt;p&gt;快速求两个数的最大公约数(公因数)有两个办法：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;更相减损法&lt;/li&gt;
&lt;li&gt;辗转相除法&lt;/li&gt;
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>蒙特卡洛法</title>
      <link>https://zeqiang-lai.github.io/blog/posts/ai/monte_carlo/</link>
      <pubDate>Tue, 25 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/posts/ai/monte_carlo/</guid>
      <description>&lt;p&gt;蒙特卡洛(MonteCarlo)是一大类随机算法(RandomizedAlgorithms)的总称，它们通过随机样本来估算真实值。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Convolution with Image Filter &amp;&amp; Convolution with fft/ifft</title>
      <link>https://zeqiang-lai.github.io/blog/posts/ai/conv-fft/</link>
      <pubDate>Thu, 04 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/posts/ai/conv-fft/</guid>
      <description>&lt;p&gt;我们可以使用傅立叶变换实现卷积，具体做法大概就是先对数据和卷积核进行傅立叶变换将数据变换到频域，然后卷积就是频域上的乘积, 最后做逆傅立叶变换转化回原来的空域。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>More about Variational Autoencoder</title>
      <link>https://zeqiang-lai.github.io/blog/posts/ai/vae-more/</link>
      <pubDate>Fri, 04 Dec 2020 21:32:04 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/posts/ai/vae-more/</guid>
      <description>&lt;p&gt;一些关于VAE的扩展知识。&lt;/p&gt;
&lt;p&gt;不断更新中&amp;hellip;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Hugo-Book Shortcodes Usages</title>
      <link>https://zeqiang-lai.github.io/blog/posts/misc/hugo-book/</link>
      <pubDate>Tue, 01 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/posts/misc/hugo-book/</guid>
      <description>&lt;p&gt;Hugo-Book Shortcodes Usages&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>AC自动机</title>
      <link>https://zeqiang-lai.github.io/blog/posts/algorithms/AC%E8%87%AA%E5%8A%A8%E6%9C%BA/</link>
      <pubDate>Sat, 25 Jan 2020 12:03:00 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/posts/algorithms/AC%E8%87%AA%E5%8A%A8%E6%9C%BA/</guid>
      <description>&lt;p&gt;AC自动机用于解决下述问题及其同类问题:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;给定一系列模式串和一个文本串，判断有多少模式串出现在文本串中，给出数目和对应模式串的出现位置。&lt;/p&gt;
&lt;/blockquote&gt;</description>
    </item>
    
    <item>
      <title>Trie树</title>
      <link>https://zeqiang-lai.github.io/blog/posts/algorithms/trie%E6%A0%91/</link>
      <pubDate>Fri, 24 Jan 2020 13:52:51 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/posts/algorithms/trie%E6%A0%91/</guid>
      <description>&lt;p&gt;Trie树可以:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;压缩存储大量的字符串&lt;/li&gt;
&lt;li&gt;快速找出具有相同前缀的字符串&lt;/li&gt;
&lt;li&gt;快速按字典序对字符串进行排序&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Semaphores(信号量)</title>
      <link>https://zeqiang-lai.github.io/blog/posts/programming/semaphores/</link>
      <pubDate>Tue, 16 Oct 2018 13:52:51 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/posts/programming/semaphores/</guid>
      <description>&lt;p&gt;Semaphores是一种同步机制（Concurrency Mechanisms），它用来协调各个进程访问公共资源。其基本思想如下所述：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;两个或多个进程通过一个信号量进行协调，当一个进程需要某个资源时，它需要申请并等待一个信号，如果信号没有来临则等待。&lt;/p&gt;
&lt;/blockquote&gt;</description>
    </item>
    
    <item>
      <title>错误检测-海(汉)明码</title>
      <link>https://zeqiang-lai.github.io/blog/posts/algorithms/%E6%B5%B7%E6%98%8E%E7%A0%81/</link>
      <pubDate>Mon, 15 Oct 2018 17:08:00 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/posts/algorithms/%E6%B5%B7%E6%98%8E%E7%A0%81/</guid>
      <description>&lt;p&gt;Hamming code，海明码，汉明码都是一个东西。它是一种编码方式，通常用在网络信息传输中，通过这种编码方式编码出来的二进制数据具有检测一位错误位的能力。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>How genralized linear model work?</title>
      <link>https://zeqiang-lai.github.io/blog/posts/ai/Generalized-Linear-Model/</link>
      <pubDate>Sat, 12 May 2018 08:24:04 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/posts/ai/Generalized-Linear-Model/</guid>
      <description>&lt;p&gt;本文将简单的讲述：GLM是如何工作的？&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>克鲁斯卡尔算法</title>
      <link>https://zeqiang-lai.github.io/blog/posts/algorithms/%E5%85%8B%E9%B2%81%E6%96%AF%E5%8D%A1%E5%B0%94%E7%AE%97%E6%B3%95/</link>
      <pubDate>Sun, 15 Apr 2018 14:03:00 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/posts/algorithms/%E5%85%8B%E9%B2%81%E6%96%AF%E5%8D%A1%E5%B0%94%E7%AE%97%E6%B3%95/</guid>
      <description>&lt;p&gt;首先，克鲁斯卡尔算法是用来求最小生成树的。另一种求最小生成树的算法叫普林姆算法（Prim）。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>普林姆算法</title>
      <link>https://zeqiang-lai.github.io/blog/posts/algorithms/%E6%99%AE%E6%9E%97%E5%A7%86%E7%AE%97%E6%B3%95/</link>
      <pubDate>Sun, 15 Apr 2018 14:03:00 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/posts/algorithms/%E6%99%AE%E6%9E%97%E5%A7%86%E7%AE%97%E6%B3%95/</guid>
      <description>&lt;p&gt;普林姆算法也是用来求最小生成树的，与克鲁斯卡尔算法遍历边不同，普林姆遍历的是点。&lt;/p&gt;
&lt;p&gt;普林姆算法同样基于贪心，以任意点为初始点，每次选取&lt;code&gt;与已选点相连的边&lt;/code&gt;中&lt;code&gt;权值最小&lt;/code&gt;的边，并把与这条边相连的点加入已选点集合。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>并查集</title>
      <link>https://zeqiang-lai.github.io/blog/posts/algorithms/%E5%B9%B6%E6%9F%A5%E9%9B%86/</link>
      <pubDate>Sun, 15 Apr 2018 12:03:00 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/posts/algorithms/%E5%B9%B6%E6%9F%A5%E9%9B%86/</guid>
      <description>&lt;p&gt;使用并查集可以快速判断两个元素是否属于同一个集合。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Principal component analysis</title>
      <link>https://zeqiang-lai.github.io/blog/posts/ai/Principal-component-analysis/</link>
      <pubDate>Mon, 08 Jan 2018 12:45:04 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/posts/ai/Principal-component-analysis/</guid>
      <description>&lt;p&gt;PCA (Principal component analysis) 是一种给数据降维的方法。&lt;/p&gt;
&lt;p&gt;利用PCA，能将一堆高维空间的数据映射到一个低维空间，并最大限度保持它们之间的可区分性。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>洛伦兹变换</title>
      <link>https://zeqiang-lai.github.io/blog/posts/misc/%E6%B4%9B%E4%BC%A6%E5%85%B9%E5%8F%98%E6%8D%A2/</link>
      <pubDate>Sun, 17 Dec 2017 21:33:22 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/posts/misc/%E6%B4%9B%E4%BC%A6%E5%85%B9%E5%8F%98%E6%8D%A2/</guid>
      <description>&lt;p&gt;洛伦兹变换是从光速不变原理推出的，不同坐标系坐标之间的转换关系。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Fibonacci数的迭代算法</title>
      <link>https://zeqiang-lai.github.io/blog/posts/algorithms/Fibonacci%E6%95%B0%E7%9A%84%E8%BF%AD%E4%BB%A3%E7%AE%97%E6%B3%95/</link>
      <pubDate>Sat, 30 Sep 2017 16:01:39 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/posts/algorithms/Fibonacci%E6%95%B0%E7%9A%84%E8%BF%AD%E4%BB%A3%E7%AE%97%E6%B3%95/</guid>
      <description>&lt;p&gt;使用迭代算法求斐波那契数列，&lt;/p&gt;
&lt;p&gt;时间复杂度O(n)，空间复杂度O(1)。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>快速幂算法</title>
      <link>https://zeqiang-lai.github.io/blog/posts/algorithms/%E5%BF%AB%E9%80%9F%E5%B9%82/</link>
      <pubDate>Sat, 30 Sep 2017 15:25:28 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/posts/algorithms/%E5%BF%AB%E9%80%9F%E5%B9%82/</guid>
      <description>&lt;p&gt;在c，c++语言中，并没有提供求幂的基本运算，通常我们需要自己写函数或者调用STL提供的函数。&lt;/p&gt;
&lt;p&gt;一般情况下，我们写的求幂函数基本上都是循环累乘，时间复杂度为O(n)。虽说是线性的时间复杂度，但求幂运算作为基础运算，往往调用频繁，这时候即使是线性的时间复杂度也将变得难也接受。&lt;/p&gt;
&lt;p&gt;利用快速幂可以快速计算底数的n次幂。其时间复杂度为 O(logn)&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>位运算的妙用</title>
      <link>https://zeqiang-lai.github.io/blog/posts/algorithms/%E4%BD%8D%E8%BF%90%E7%AE%97%E7%9A%84%E5%A6%99%E7%94%A8/</link>
      <pubDate>Wed, 27 Sep 2017 13:52:51 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/posts/algorithms/%E4%BD%8D%E8%BF%90%E7%AE%97%E7%9A%84%E5%A6%99%E7%94%A8/</guid>
      <description>&lt;p&gt;对于一些特定问题，巧妙运用位运算能使解法异常&lt;strong&gt;简洁&lt;/strong&gt;和&lt;strong&gt;高效&lt;/strong&gt;，同时，适当运用位运算也能对程序进行&lt;strong&gt;优化&lt;/strong&gt;。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>筛法求素数</title>
      <link>https://zeqiang-lai.github.io/blog/posts/algorithms/%E7%AD%9B%E6%B3%95%E6%B1%82%E7%B4%A0%E6%95%B0/</link>
      <pubDate>Fri, 15 Sep 2017 21:33:22 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/posts/algorithms/%E7%AD%9B%E6%B3%95%E6%B1%82%E7%B4%A0%E6%95%B0/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;假设要求n以内的素数&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;筛法求素数是用一个大小为n的数组，作为标记数组，如果没被标记到则为素数。&lt;/p&gt;
&lt;p&gt;开始均为未标记。&lt;/p&gt;
&lt;p&gt;从2开始，2没被标记，将2存入一个存素数的地方，然后筛掉小于n的，2的所有倍数。然后是3，筛掉3的所有倍数，依此类推，直到n-1。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ArbSR: 任意尺度超分 - 阅读笔记</title>
      <link>https://zeqiang-lai.github.io/blog/docs/notes/paper/arbrcan/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/docs/notes/paper/arbrcan/</guid>
      <description>Created: August, 12, 2021 论文: Learning A Single Network for Scale-Arbitrary Super-Resolution
Code: https://github.com/LongguangWang/ArbSR
 </description>
    </item>
    
    <item>
      <title>Introduction</title>
      <link>https://zeqiang-lai.github.io/blog/docs/gen/introduction/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/docs/gen/introduction/</guid>
      <description>Created: March, 23, 2023 对于生成式模型来说，我们要解决的核心问题就是如何构造一个 highly flexible families of probability distribution 去拟合真实的数据分布，并且我们希望这个分布家族对于，
 learning：通过数据学习分布形式。 sampling：从分布中取样。 inference：计算条件概率 $p(x|y)$。 evaluation：计算给定样本出现的概率 $p(x)$。  这四个任务，都是或尽可能都是 analytically 或者 computationally tractable [1]_ 的 :raw-latex:\parencite{sohl2015deep}。
为了这个目标，人们提出了各种各样的模型，方法。这些方法的核心思路基本就是，在保证 tractable 的前提下，尽可能的提升flexibility，从而更好的拟合复杂的真实数据分布。常见的模型包括：Mixture Gaussian, VAE, Normalizing Flow, DDPM, GAN 等等。对于这些模型，上述的四个任务并不是都能够解的，大部分都只能解决其中一个或几个（例如GAN，我们只能做 learning 和 sampling）。
Think from Scratch #  以上的介绍可能过于抽象，现在我们可以从零开始思考，如果现在我们拥有一堆数据，这些数据有很多样本，比如说我们有 N 个样本，每个样本都是一个 D 维的向量，我们要如何学习这些数据的分布呢？
想要回答这个问题，我们必须理解 ”分布“ 是什么？分布其实就是概率分布，概率分布就是一个随机变量不同取值的概率构成的一个函数。对于一个连续的随机变量，单个取值的概率没有意义，这时候，分布其实是代指概率密度函数。
这时候，我们应该知道，对于前面提到的数据，如果我把数据中的样本视作一个 D 维的随机变量，我们实际上就是想要学习这个随机变量的概率密度函数。
这时候，又引出了一个新的问题，这个概率密度函数的形式是什么样的呢 ？如果我们知道概率密度函数的解析形式，那么我们就可以通过极大似然估计，根据给定的数据，估计出这个分布的未知参数了。例如，如果我们假设数据服从高斯分布，但是均值方差未知，通过极大似然估计，我们就可以得到这个分布的均值和方差。
数据分布的形式的选取是需要根据我们的先验知识决定的，但很多时候，我们并没有这些先验知识，我们也不想自己决定。另一方面，即便我们有一些先验知识，但是现实中可供选取的 family of distribution 是有限的，这些分布并不一定能够建模复杂的真实数据。
Latent Variable Model #  为此，我们通常考虑使用 Latent Variable Model 对数据分布进行建模，即我们希望从一个known well-defined distribution 出发，通过学习一个分布的映射，将这个已知分布映射到未知的数据分布。</description>
    </item>
    
    <item>
      <title>Jordan Form</title>
      <link>https://zeqiang-lai.github.io/blog/docs/matrix/jordan/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/docs/matrix/jordan/</guid>
      <description>&lt;h5&gt;Created: Decemenber, 7, 2020&lt;/h5&gt;
&lt;p&gt;Jordan Form是矩阵对角化的一个推广的产物。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>KMP算法</title>
      <link>https://zeqiang-lai.github.io/blog/posts/algorithms/kmp/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/posts/algorithms/kmp/</guid>
      <description>&lt;p&gt;问题描述:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;给定一个文本串S, 和一个模式串P, 我们要找到P在S中的位置，即给出P的第一个字符在S中的位置。&lt;/p&gt;
&lt;/blockquote&gt;</description>
    </item>
    
    <item>
      <title>Normalizing Flow</title>
      <link>https://zeqiang-lai.github.io/blog/docs/notes/concept/nflow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/docs/notes/concept/nflow/</guid>
      <description>简单介绍 #  首先，Normalizing Flow是一种生成模型（Generative Model），它的提出是为了解决现有的生成的模型的一些问题，如GAN训练不稳定，VAE边缘概率估计intractable的问题。
Normalizing Flow是一种特殊的inveritable网络，每个模块都是可逆的，并且有tractable determinant of the Jacobian，且求逆也是tractable的。
优点：
 相比VAE，不必引入噪声， more powerful local variance models. 相比GAN，训练更稳定，更易收敛。  缺点
 每个模块都必须可逆，限制了表达能力。 可逆要求latent space的维度很高。  详细介绍 #  参考资料 #   Github: normalizing-flows  Introduction to Normalizing Flows  Stanford CS236: Normalizing flow models  Difference between invertible NN and flow-based NN  </description>
    </item>
    
    <item>
      <title>PatchMatch 导读</title>
      <link>https://zeqiang-lai.github.io/blog/docs/notes/paper/patchmatch/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/docs/notes/paper/patchmatch/</guid>
      <description>Created: Jan, 24, 2022 PatchMatch: A Randomized Correspondence Algorithm for Structural Image Editing
 Sample Impl ｜ 知乎解读
图像匹配的典中典，基于匹配块周围的匹配也近似匹配的先验知识的随机化算法。
 首先明确这篇论文解决的问题是图像匹配问题，即给定两张图像A，B，我们需要将A，B中相同的像素或图像块（Patch）进行匹配，得到一个偏移量f，使得对于A中每个点的坐标x，B中对应点的坐标为x+f(x)。
这篇论文提出了一个Randomized Correspondence Algorithm来做这件事情。要理解这个算法，我们首先需要这个算法的核心insight：
The key insights driving the algorithm are thatsome good patch matches can be found via random sampling, and that natural coherence in the imagery allows us to propagate such matches quickly to surrounding areas.  用中文来说就是，对于一个匹配好的点，我们知道其偏移量为f(x)，基于图像的连续性，那么这个点周围的点的偏移量应该也近似是f(x)，这样我们就可以快速把正确点的偏移量向其周围传播，使其周围点的估计偏移量越来越准确。
图像的连续性：一个苹果在两张图像上放在不同位置，但是苹果上某两个点的相对位置关系近似不变。  算法 #  前提条件 假设我们有两张图像A，B，我们需要找到一个偏移量f，使得对于A中每个点的坐标x，B中对应点的坐标为x+f(x)。
PatchMatch的算法主要分为三个步骤：
 Initialization： 随机初始化匹配关系，即A中每个点的偏移量。 Propagation： 根据匹配程度，将每个点的偏移量传播到周围的点。实际实现是，对于某个点(x,y)，使用其周围点的偏移量还是自己的偏移量得到匹配点，计算匹配程度，取匹配程度最好的偏移量作为当前点的偏移量。 Random search： 为了进一步优化匹配结果，我们在前一步得到的偏移量基础上，我们再随机的做一些变化，检查匹配点周围是否有更好的匹配点。   解读：</description>
    </item>
    
    <item>
      <title>Raft 阅读笔记</title>
      <link>https://zeqiang-lai.github.io/blog/docs/notes/paper/raft/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/docs/notes/paper/raft/</guid>
      <description>Created: August, 6, 2021 论文: RAFT: Recurrent All-Pairs Field Transforms for Optical Flow
Code: https://github.com/princeton-vl/RAFT
 这篇文章做的是光流估计，简单来说，任务就是输入两张图像$I_1,I_2$，我们需要估计出第二张图像$I_1$每个像素点$(u,v)$相对于第一张图像$I_1$的偏移量$(f^1(u), f^2(v))$。
$$ I_1 = I_2 + f $$
这篇文章的思路是这样的：
 首先使用一个feature encoder  求出flow feature：同时输入img1，img2，得到fmap1，fmap2 求出context feature：只输入img1，得到inp   求出fmap1和fmap2的相似度corr 使用一个RNN迭代的求出flow。  RNN的输入包括一个隐藏状态net，context feature inp，相似度corr，上一步的flow     这里的主要问题是每迭代一次，我们都得到了一个更接近img1的img2，这时候相似度需要重新计算。
 RAFT设计了一个查表的思路，只需要在最开始算一遍即可。它的方法是用新坐标周围的点的flow feature拉成一个向量作为新坐标点的flow特征。</description>
    </item>
    
    <item>
      <title>Reverse Time Stochastic Differential Equations for Generative Modelling</title>
      <link>https://zeqiang-lai.github.io/blog/docs/gen/reverse_diffusion/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/docs/gen/reverse_diffusion/</guid>
      <description>Created: March, 23, 2023 Originally posted at Reverse Time Stochastic Differential Equations for generative modelling.
 What follows is a derivation of the main result of ‘Reverse-Time Diffusion Equation Models’ by Brian D.O. Anderson (1982). Earlier on this blog we learned that a stochastic differential equation of the form $$ \begin{align} dX_t = \mu(X_t, t) dt + \sigma(X_t, t) dW_t \end{align} $$
with the derivative of Wiener process $W_t$ admits two types of equations, called the forward Kolmogorov or Fokker-Planck equation and the backward Kolmogorov equation.</description>
    </item>
    
    <item>
      <title>Stochastic Differential Equations</title>
      <link>https://zeqiang-lai.github.io/blog/docs/gen/sde/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/docs/gen/sde/</guid>
      <description>Created: March, 23, 2023  A Wiener twist to differential equations
 Non-Differential Equations #  Most of us are quite familiar with linear and non-linear equations from our 101 math classes and lectures. These equations define an equality between the two terms left and right of the equal sign: $$ \begin{align} y = f(x) \end{align} $$
These functions assert an equality between $y$ and $x$ through the function $f(\cdot)$ and describe a &amp;ldquo;static&amp;rdquo; relationship between a value $x$ and its corresponding value $y$.</description>
    </item>
    
    <item>
      <title>各种矩阵</title>
      <link>https://zeqiang-lai.github.io/blog/docs/matrix/types/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/docs/matrix/types/</guid>
      <description>Created: Decemenber, 1, 2020 对称矩阵 #    定义：满足$A^T=A$的矩阵。 显然，对称矩阵是方阵，否则转一下形状都变了。  对称矩阵的特征值/向量有着很好的性质：
 实对称矩阵的特征值都是实数。 对称矩阵的特征向量是正交的。没验证，不过应该是不同特征值对应的特征向量一定是正交的，同一个特征值对应的特征向量可能需要Schmidt正交化。  证明 1. 实对称矩阵的特征值都是实数
已知$Ax = \lambda x$，左右两边同时取共轭，有
$$ \bar{A}\bar{x}=\bar{\lambda}\bar{x} $$
因为A是实对称矩阵，$\bar{A}=A$，因此有 $$ A\bar{x}=\bar{\lambda}\bar{x} $$
左右两边同时取转置，有
$$ \bar{x}^TA=\bar{x}^T\bar{\lambda} $$
左右两边同时右乘x，得 $$ \bar{x}^TAx=\bar{x}^T\bar{\lambda}x $$
对$Ax = \lambda x$，左右两边同时左乘$\bar{x}^T$，得 $$ \bar{x}^TAx=\bar{x}^T\lambda x $$
比较两个式子，可以得到
$$ \bar{\lambda} = \lambda $$
一个数的共轭等于其本身，这个数是实数。
2. 对称矩阵的特征向量是正交的
  正定矩阵 #   正定矩阵是对称矩阵的一种特殊情况，因此它也是对称的。
定义 #  正定矩阵有各种各样的定义，它们互相之间是等价的。下面是几种常见定义/判定方法：
 所有特征值大于0。 所有顺序主子式都大于0。 所有Pivots都大于0。 $x^TAx&amp;gt;0$ ： $x=[x_1,x_2, &amp;hellip;, x_n]$, 对于所有的非零x恒大于0  类似的可以定义半正定(大于等于0)，负定（小于0），半负定（小于等于0）。</description>
    </item>
    
    <item>
      <title>奇异值分解</title>
      <link>https://zeqiang-lai.github.io/blog/docs/matrix/svd/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/docs/matrix/svd/</guid>
      <description>&lt;h5&gt;Created: Decemenber, 1, 2020&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;所有矩阵&lt;/strong&gt;都可以分解成：&lt;strong&gt;正交矩阵 * 对角矩阵 * 正交矩阵&lt;/strong&gt;，这个分解叫&lt;strong&gt;奇异值分解&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;$$
A = U\Sigma V^T
$$&lt;/p&gt;
&lt;p&gt;其中A是一个m*n的矩阵，V是一个n*n的矩阵，U是一个m*m的矩阵，$\Sigma$是一个m*n的矩阵。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>如何将各个知识点串起来？</title>
      <link>https://zeqiang-lai.github.io/blog/docs/matrix/road/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/docs/matrix/road/</guid>
      <description>Created: Decemenber, 3, 2020 引入 特征值与特征向量之后，我们可以很容易的推导出 矩阵对角化的公式。
矩阵对角化是针对一般方阵的，对于特殊方阵，如 对称矩阵，矩阵对角化可以进一步特化。
对称矩阵有很多很好的性质，它是它的进一步特例， 正定矩阵有着更好的性质。
#  </description>
    </item>
    
    <item>
      <title>杂七杂八</title>
      <link>https://zeqiang-lai.github.io/blog/docs/matrix/misc/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/docs/matrix/misc/</guid>
      <description>Created: Decemenber, 1, 2020 Quick Look #   酉矩阵: $A^HA=E$ 正规矩阵: $A^HA=AA^H$, 包括对称矩阵，反对称矩阵，Hermite矩阵，反Hermite矩阵，正交矩阵，酉矩阵等。 酉对角化： $A=Q\Lambda Q^H$, 普通对角化: $A=Q\Lambda Q^{-1}$ 单纯矩阵：可以对角化的矩阵，即有n个线性无关的特征向量。  线性代数中常见的等价关系 #    singular matrix = 奇异矩阵 = 不可逆矩阵
  A不可逆 &amp;lt;-&amp;gt;1 Ax = 0 有非零解 &amp;lt;-&amp;gt;2 特征值=0
  Spectrum #  矩阵中有谱（spectrum）这个概念，例如谱分解，谱范数等等。
这个谱其实说的就是特征值，特征向量，它是从光学里借过来的说法。光学中光是由各种pure light构成的，光谱就是各个成分的占比。而在矩阵中，矩阵由各个pure的component，特征值特征向量构成。
进一步来说，我们看矩阵对角化，我们知道任何一个对称矩阵A都可以对角化成$Q\Lambda Q^{T}$，其中Q为特征向量组成的矩阵。
我们进一步把这个式子拆开，我们设A的特征向量为$q_i$, 则
$$ A = Q\Lambda Q^{T} = \lambda_1 q_1 q_1^T + \lambda_2 q_2 q_2^T + &amp;hellip; + \lambda_n q_n q_n^T $$</description>
    </item>
    
    <item>
      <title>特征值&amp;&amp;特征向量</title>
      <link>https://zeqiang-lai.github.io/blog/docs/matrix/eigen/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/docs/matrix/eigen/</guid>
      <description>Created: Decemenber, 1, 2020 首先明确一点，特征值和特征向量是针对方阵来说的，我们说某个矩阵A有什么特征值和特征向量时，我们实际上暗示了矩阵A是一个方阵。
定义 #  任何满足下列条件的标量和向量分别为矩阵A的特征值和特征向量。1
$$ Ax = \lambda x $$
Intuition #  将一个矩阵A与一个向量x相乘，我们实际上在对向量x做一个 线性变换，特征向量实际上就是经过这个变换与原向量仍然平行的那些向量，特征值就是前后两个向量长度的一个比值。
 显然，零向量满足条件，那它是任何矩阵的特征向量吗？
不是，我们显示将特征向量定义为非零向量。
 求解 #  根据定义，有
$$ (A-\lambda I)x = 0 $$
这个等式要有非零解，$(A-\lambda I)$必须是singular（不可逆）的，特征值要等于0：
$$ Det(A-\lambda I) = 0 $$
于是：
 求行列式并解方程即可求出特征值。 对于特征向量，我们回代特征值，解$(A-\lambda I)x=0$这个方程。  因为$(A-\lambda I)$不可逆，所以解有无穷多个，即特征向量有无穷多个，这时候我们只需要给出一个就行了。    性质 #   $\sum \lambda = trace(A)$ : 矩阵A的所有特征值之和等于矩阵A的 trace（对角线元素之和）。 $\prod \lambda = det(A)$ : 矩阵A的所有特征值的乘积等于矩阵A的行列式。 三角矩阵的特征值就是对角线上的元素。 对称矩阵的特征向量是正交的。  证明：对称矩阵的特征向量是正交的 To be done     由特征向量的定义，显然A必须要个方阵，若不是，A与x相乘，x维数就变了。&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description>
    </item>
    
    <item>
      <title>相似矩阵</title>
      <link>https://zeqiang-lai.github.io/blog/docs/matrix/similar/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/docs/matrix/similar/</guid>
      <description>&lt;h5&gt;Created: Decemenber, 7, 2020&lt;/h5&gt;
&lt;p&gt;满足以下条件的两个矩阵，我们称它们是&lt;strong&gt;相似&lt;/strong&gt;的。&lt;/p&gt;
&lt;p&gt;$$
B = M^{-1}AM
$$&lt;/p&gt;
&lt;p&gt;换句话说，如果某个矩阵可以由另一个矩阵左乘一个矩阵再右乘这个矩阵的逆，则称它们是相似的。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>矩阵对角化</title>
      <link>https://zeqiang-lai.github.io/blog/docs/matrix/diagonalization/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/docs/matrix/diagonalization/</guid>
      <description>Created: Decemenber, 1, 2020  To be continue.  Keypoint: 一些矩阵可以对角化 $S^{-1}AS = \Lambda$。其中S为特征向量(列向量)构成的矩阵，$\Lambda$为特征值构成的对角矩阵。
 什么样的矩阵可以？ 因为定义里S要可逆，所以A必须拥有n个线性无关的特征向量。   关于矩阵对角化，我们其实可以从两个角度理解：
 一些矩阵可以对角化$S^{-1}AS = \Lambda$。 或一些矩阵可以化成三个矩阵的乘积：$A = S\Lambda S^{-1}$  推导 #   $$ \begin{equation} \begin{aligned} AS &amp;= A[x_1, x_2, ..., x_n] = [Ax_1, Ax_2, ..., Ax_n] = [\lambda_1 x_1, \lambda_1 x_2, ..., \lambda_1 x_n] \\\\\\ &amp;= [x_1, x_2, ..., x_n] \begin{bmatrix} \lambda_1 &amp; 0 &amp; \cdots &amp; 0\\ 0 &amp; \lambda_2 &amp; \cdots &amp; 0\\ \vdots &amp; \vdots &amp; \ddots &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; \lambda_n\\ \end{bmatrix} = S\Lambda \end{aligned} \end{equation} $$  左右两边同时乘S的逆，即可得到：</description>
    </item>
    
    <item>
      <title>线性空间和线性变换</title>
      <link>https://zeqiang-lai.github.io/blog/docs/matrix/space/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/docs/matrix/space/</guid>
      <description>&lt;h5&gt;Created: Decemenber, 9, 2020&lt;/h5&gt;
&lt;p&gt;抽象来说，线性空间就是里面元素满足一定运算规律的一个空间。&lt;/p&gt;
&lt;p&gt;具体来说，空间的概念在数学上就是一个集合，空间里的元素就是集合里的元素，线性空间就是里面元素满足一定运算规律的一个集合。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>贪心生成最优编码的思路分析</title>
      <link>https://zeqiang-lai.github.io/blog/posts/algorithms/%E8%B4%AA%E5%BF%83%E7%94%9F%E6%88%90%E6%9C%80%E4%BC%98%E7%BC%96%E7%A0%81%E7%9A%84%E6%80%9D%E8%B7%AF%E5%88%86%E6%9E%90/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://zeqiang-lai.github.io/blog/posts/algorithms/%E8%B4%AA%E5%BF%83%E7%94%9F%E6%88%90%E6%9C%80%E4%BC%98%E7%BC%96%E7%A0%81%E7%9A%84%E6%80%9D%E8%B7%AF%E5%88%86%E6%9E%90/</guid>
      <description>&lt;h2 id=&#34;贪心生成最优编码的思路分析&#34;&gt;
  贪心生成最优编码的思路分析
  &lt;a class=&#34;anchor&#34; href=&#34;#%e8%b4%aa%e5%bf%83%e7%94%9f%e6%88%90%e6%9c%80%e4%bc%98%e7%bc%96%e7%a0%81%e7%9a%84%e6%80%9d%e8%b7%af%e5%88%86%e6%9e%90&#34;&gt;#&lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;目标&lt;/strong&gt;：求字符编码&lt;/p&gt;
&lt;p&gt;首先得先想到用二叉树表示编码，节点即为字符，边为编码。&lt;/p&gt;
&lt;p&gt;然后优化目标（目标函数）即为： &lt;code&gt;f(x) = w(x)*l(x)&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;w(x) 为 字符x的频率&lt;/li&gt;
&lt;li&gt;l(x) 为 字符编码的长度&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
  </channel>
</rss>
